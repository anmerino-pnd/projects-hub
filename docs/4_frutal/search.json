[
  {
    "objectID": "2_solucion.html",
    "href": "2_solucion.html",
    "title": "Arquitectura y Soluci√≥n T√©cnica",
    "section": "",
    "text": "Para resolver la migraci√≥n de datos desde un entorno hostil (drivers legacy inestables), dise√±√© una arquitectura desacoplada basada en contenedores.\n\n\n\n\n\nflowchart TB\n    A[üóÑÔ∏è Legacy HFSQL Server] --&gt;|ODBC| B(üêç Python Wrapper / Subproceso)\n    B --&gt;|Raw Data| C{üê≥ Docker/Podman&lt;br&gt;Container}\n    C --&gt;|Pandas Transformation| D[üì¶ Parquet Data Lake]\n    D --&gt;|Consumo| E[üìä Dashboard / Analytics]\n\n    style A fill:#2b4c7e,stroke:#2b4c7e,color:#fff,stroke-width:2px\n    style B fill:#3a7ca5,stroke:#3a7ca5,color:#fff,stroke-width:2px\n    style C fill:#f7b2c4,stroke:#d4819a,color:#333,stroke-width:2px\n    style D fill:#88c9a1,stroke:#5fa87a,color:#333,stroke-width:2px\n    style E fill:#2b4c7e,stroke:#2b4c7e,color:#fff,stroke-width:2px\n\n\n\n\n\n\nEl pipeline de datos sigue un flujo de extracci√≥n robusto que prioriza la integridad de la memoria y la portabilidad."
  },
  {
    "objectID": "2_solucion.html#arquitectura",
    "href": "2_solucion.html#arquitectura",
    "title": "Arquitectura y Soluci√≥n T√©cnica",
    "section": "",
    "text": "Para resolver la migraci√≥n de datos desde un entorno hostil (drivers legacy inestables), dise√±√© una arquitectura desacoplada basada en contenedores.\n\n\n\n\n\nflowchart TB\n    A[üóÑÔ∏è Legacy HFSQL Server] --&gt;|ODBC| B(üêç Python Wrapper / Subproceso)\n    B --&gt;|Raw Data| C{üê≥ Docker/Podman&lt;br&gt;Container}\n    C --&gt;|Pandas Transformation| D[üì¶ Parquet Data Lake]\n    D --&gt;|Consumo| E[üìä Dashboard / Analytics]\n\n    style A fill:#2b4c7e,stroke:#2b4c7e,color:#fff,stroke-width:2px\n    style B fill:#3a7ca5,stroke:#3a7ca5,color:#fff,stroke-width:2px\n    style C fill:#f7b2c4,stroke:#d4819a,color:#333,stroke-width:2px\n    style D fill:#88c9a1,stroke:#5fa87a,color:#333,stroke-width:2px\n    style E fill:#2b4c7e,stroke:#2b4c7e,color:#fff,stroke-width:2px\n\n\n\n\n\n\nEl pipeline de datos sigue un flujo de extracci√≥n robusto que prioriza la integridad de la memoria y la portabilidad."
  },
  {
    "objectID": "2_solucion.html#desaf√≠os-cr√≠ticos-y-soluciones",
    "href": "2_solucion.html#desaf√≠os-cr√≠ticos-y-soluciones",
    "title": "Arquitectura y Soluci√≥n T√©cnica",
    "section": "Desaf√≠os Cr√≠ticos y Soluciones",
    "text": "Desaf√≠os Cr√≠ticos y Soluciones\n\n1. El Problema del ‚ÄúStack Smashing‚Äù\nUno de los mayores obst√°culos t√©cnicos fue la interacci√≥n entre el driver ODBC propietario de HFSQL y las librer√≠as modernas de Linux (unixODBC). Al intentar conexiones directas, el driver provocaba corrupciones de memoria (stack smashing) que ‚Äúmataban‚Äù el proceso principal de extracci√≥n.\nLa Soluci√≥n:\nImplement√© un patr√≥n de aislamiento de procesos. En lugar de ejecutar la conexi√≥n ODBC en el hilo principal de la aplicaci√≥n:\n\nDesarroll√© un wrapper en Python que a√≠sla la conexi√≥n inestable en un subproceso independiente.\nSi el driver falla, el proceso principal detecta el error, limpia la memoria y reintenta sin detener todo el pipeline.\n\n\n\n2. Contenerizaci√≥n con Podman\nDado que el entorno de desarrollo era Windows y el de producci√≥n un servidor Linux ‚Äúheadless‚Äù, las discrepancias en las librer√≠as din√°micas (DLLs vs .so) eran constantes.\nLa Implementaci√≥n:\nUtilic√© Podman (una alternativa a Docker sin daemon) para encapsular no solo el c√≥digo Python, sino todo el entorno del sistema operativo necesario para el driver legacy.\n\nImagen Personalizada: Cre√© una imagen de Linux que incluye versiones espec√≠ficas de librer√≠as antiguas requeridas por el driver HFSQL.\nCross-Platform: Esto garantiz√≥ que el c√≥digo funcionara id√©ntico en mi m√°quina local y en el servidor del cliente.\n\n\n\n3. Optimizaci√≥n con Parquet\nEn lugar de volcar los datos a CSV (lento y pesado), utilic√© Apache Parquet.\n\nCompresi√≥n: Reducci√≥n del 60% en el tama√±o de almacenamiento.\nTipado: Preservaci√≥n de los tipos de datos (fechas, flotantes) que sol√≠an perderse en exportaciones de texto plano."
  },
  {
    "objectID": "2_solucion.html#stack-tecnol√≥gico",
    "href": "2_solucion.html#stack-tecnol√≥gico",
    "title": "Arquitectura y Soluci√≥n T√©cnica",
    "section": "Stack Tecnol√≥gico",
    "text": "Stack Tecnol√≥gico\n\nLenguaje: Python 3.10\nContenedores: Podman & Docker\nDrivers: pyodbc, unixODBC, HFSQL ODBC\nData Lake: Pandas, PyArrow, Parquet"
  },
  {
    "objectID": "0_home.html",
    "href": "0_home.html",
    "title": "Arquitectura de datos: HFSQL a Data Lake",
    "section": "",
    "text": "Este proyecto aborda uno de los desaf√≠os m√°s cr√≠ticos en la industria actual: la liberaci√≥n de datos atrapados en sistemas heredados (Legacy Systems).\nEl objetivo principal fue dise√±ar e implementar una arquitectura de datos capaz de extraer informaci√≥n transaccional masiva desde bases de datos HFSQL (HyperFileSQL), transformar estos datos y cargarlos en un Data Lake moderno.\n\n\nLa infraestructura existente depend√≠a de controladores ODBC obsoletos que presentaban graves problemas de estabilidad (errores de segmentaci√≥n y stack smashing) al ejecutarse en entornos de producci√≥n Linux modernos, impidiendo la automatizaci√≥n del an√°lisis de datos.\n\n\n\nComo ingeniero de datos, dise√±√© la soluci√≥n de bajo nivel, enfoc√°ndome en: 1. Estabilidad: Aislar los procesos inestables mediante wrappers de Python. 2. Portabilidad: Contenerizar la soluci√≥n con Podman para garantizar la ejecuci√≥n id√©ntica en desarrollo (Windows) y producci√≥n (Linux). 3. Rendimiento: Optimizar la escritura de datos usando formatos columnares (Parquet)."
  },
  {
    "objectID": "0_home.html#el-desaf√≠o",
    "href": "0_home.html#el-desaf√≠o",
    "title": "Arquitectura de datos: HFSQL a Data Lake",
    "section": "",
    "text": "La infraestructura existente depend√≠a de controladores ODBC obsoletos que presentaban graves problemas de estabilidad (errores de segmentaci√≥n y stack smashing) al ejecutarse en entornos de producci√≥n Linux modernos, impidiendo la automatizaci√≥n del an√°lisis de datos."
  },
  {
    "objectID": "0_home.html#mi-rol",
    "href": "0_home.html#mi-rol",
    "title": "Arquitectura de datos: HFSQL a Data Lake",
    "section": "",
    "text": "Como ingeniero de datos, dise√±√© la soluci√≥n de bajo nivel, enfoc√°ndome en: 1. Estabilidad: Aislar los procesos inestables mediante wrappers de Python. 2. Portabilidad: Contenerizar la soluci√≥n con Podman para garantizar la ejecuci√≥n id√©ntica en desarrollo (Windows) y producci√≥n (Linux). 3. Rendimiento: Optimizar la escritura de datos usando formatos columnares (Parquet)."
  },
  {
    "objectID": "1_comprension.html",
    "href": "1_comprension.html",
    "title": "Contexto del Negocio: Frutal",
    "section": "",
    "text": "Frutal¬Æ es una empresa sonorense dedicada a llevar frescura y sabor a sus clientes a trav√©s de raspados, bebidas y productos elaborados con frutas naturales.\nFundada el 15 de marzo de 1992 en San Luis R√≠o Colorado, Sonora, la empresa naci√≥ con el prop√≥sito de ofrecer opciones refrescantes para la convivencia familiar. Gracias a su compromiso con la calidad, en 2014 expandieron operaciones hacia Mexicali, Baja California, consolid√°ndose como un referente en la regi√≥n.\n\n\nLa filosof√≠a de Frutal se centra en crear experiencias memorables:\n\nMisi√≥n: Nutrir emociones a trav√©s de sabores aut√©nticos, fusionando ingredientes naturales para brindar experiencias √∫nicas.\nVisi√≥n: Convertir cada visita en una tradici√≥n familiar que trascienda generaciones, fomentando la sana convivencia.\n\n\n\n\nCon m√°s de 30 a√±os de historia y m√∫ltiples sucursales, Frutal ha escalado sus operaciones significativamente. Este crecimiento trajo consigo un volumen masivo de transacciones diarias y la necesidad de estandarizar la informaci√≥n entre las distintas plazas (Sonora y Baja California)."
  },
  {
    "objectID": "1_comprension.html#sobre-la-empresa",
    "href": "1_comprension.html#sobre-la-empresa",
    "title": "Contexto del Negocio: Frutal",
    "section": "",
    "text": "Frutal¬Æ es una empresa sonorense dedicada a llevar frescura y sabor a sus clientes a trav√©s de raspados, bebidas y productos elaborados con frutas naturales.\nFundada el 15 de marzo de 1992 en San Luis R√≠o Colorado, Sonora, la empresa naci√≥ con el prop√≥sito de ofrecer opciones refrescantes para la convivencia familiar. Gracias a su compromiso con la calidad, en 2014 expandieron operaciones hacia Mexicali, Baja California, consolid√°ndose como un referente en la regi√≥n.\n\n\nLa filosof√≠a de Frutal se centra en crear experiencias memorables:\n\nMisi√≥n: Nutrir emociones a trav√©s de sabores aut√©nticos, fusionando ingredientes naturales para brindar experiencias √∫nicas.\nVisi√≥n: Convertir cada visita en una tradici√≥n familiar que trascienda generaciones, fomentando la sana convivencia.\n\n\n\n\nCon m√°s de 30 a√±os de historia y m√∫ltiples sucursales, Frutal ha escalado sus operaciones significativamente. Este crecimiento trajo consigo un volumen masivo de transacciones diarias y la necesidad de estandarizar la informaci√≥n entre las distintas plazas (Sonora y Baja California)."
  },
  {
    "objectID": "1_comprension.html#la-necesidad-t√©cnica",
    "href": "1_comprension.html#la-necesidad-t√©cnica",
    "title": "Contexto del Negocio: Frutal",
    "section": "La Necesidad T√©cnica",
    "text": "La Necesidad T√©cnica\nAqu√≠ es donde entra el desaf√≠o de Ingenier√≠a de Datos. Para mantener su promesa de calidad e innovaci√≥n, la administraci√≥n requer√≠a visibilidad total de sus operaciones en tiempo real.\n\nEl Problema de los ‚ÄúSilos de Datos‚Äù\nHist√≥ricamente, la operaci√≥n de Frutal ha sido gestionada mediante sistemas ERP basados en HFSQL (PC SOFT). Aunque este sistema es robusto para la operaci√≥n diaria (captura de ventas e inventarios en punto de venta), presenta barreras significativas para la inteligencia de negocios moderna:\n\nAcceso Limitado: Los datos residen en formatos propietarios dif√≠ciles de consultar con herramientas de Ciencia de Datos (Python, Pandas).\nRendimiento: Las consultas anal√≠ticas pesadas impactaban el rendimiento del sistema transaccional, afectando la velocidad de atenci√≥n al cliente.\nIncompatibilidad: Falta de drivers nativos estables para conectar estos sistemas legacy con entornos de nube o servidores Linux modernos.\n\n\n\nEl Objetivo del Proyecto\nLa organizaci√≥n requer√≠a construir una ‚ÄúFuente de la Verdad‚Äù √∫nica y accesible: un Data Lake.\nEsto permitir√≠a a los analistas y cient√≠ficos de datos generar reportes de ventas, proyecciones de inventario y an√°lisis de KPIs sin depender del departamento de TI para extracciones manuales, democratizando el acceso a la informaci√≥n para la toma de decisiones estrat√©gicas."
  }
]