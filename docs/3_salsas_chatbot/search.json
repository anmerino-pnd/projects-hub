[
  {
    "objectID": "5_documentacion.html",
    "href": "5_documentacion.html",
    "title": "Documentación",
    "section": "",
    "text": "Este proyecto se centra en el desarrollo de un chatbot inteligente para Salsas Castillo, diseñado para optimizar el acceso a información de ventas y finanzas, y mejorar la comunicación interna. El chatbot utiliza un sistema de recuperación aumentada con generación (RAG) y herramientas dinámicas para proporcionar respuestas precisas y relevantes, así como la capacidad de generar reportes financieros.\n\n\n\nAutomatizar consultas: Permitir a los usuarios (operativos y no operativos) obtener información sobre ventas, productos y finanzas de manera rápida y eficiente a través de una interfaz conversacional en Telegram.\nMejorar la toma de decisiones: Proporcionar análisis de datos financieros y de ventas en tiempo real, incluyendo la generación de reportes en PDF.\nOptimizar la gestión de información: Centralizar el acceso a datos transaccionales y consolidados, reduciendo la dependencia de consultas manuales.\nAdaptación a nuevas tecnologías: Implementar un sistema basado en LLMs y bases de datos vectoriales para un enfoque moderno y escalable.\n\n\n\n\n\nIncremento en la eficiencia operativa al reducir el tiempo dedicado a la búsqueda manual de información.\nMejora en la precisión de los datos y análisis disponibles para el personal.\nFacilitación de la toma de decisiones estratégicas basadas en información actualizada."
  },
  {
    "objectID": "5_documentacion.html#introducción-al-proyecto",
    "href": "5_documentacion.html#introducción-al-proyecto",
    "title": "Documentación",
    "section": "",
    "text": "Este proyecto se centra en el desarrollo de un chatbot inteligente para Salsas Castillo, diseñado para optimizar el acceso a información de ventas y finanzas, y mejorar la comunicación interna. El chatbot utiliza un sistema de recuperación aumentada con generación (RAG) y herramientas dinámicas para proporcionar respuestas precisas y relevantes, así como la capacidad de generar reportes financieros.\n\n\n\nAutomatizar consultas: Permitir a los usuarios (operativos y no operativos) obtener información sobre ventas, productos y finanzas de manera rápida y eficiente a través de una interfaz conversacional en Telegram.\nMejorar la toma de decisiones: Proporcionar análisis de datos financieros y de ventas en tiempo real, incluyendo la generación de reportes en PDF.\nOptimizar la gestión de información: Centralizar el acceso a datos transaccionales y consolidados, reduciendo la dependencia de consultas manuales.\nAdaptación a nuevas tecnologías: Implementar un sistema basado en LLMs y bases de datos vectoriales para un enfoque moderno y escalable.\n\n\n\n\n\nIncremento en la eficiencia operativa al reducir el tiempo dedicado a la búsqueda manual de información.\nMejora en la precisión de los datos y análisis disponibles para el personal.\nFacilitación de la toma de decisiones estratégicas basadas en información actualizada."
  },
  {
    "objectID": "5_documentacion.html#manual-de-instalación-y-despliegue",
    "href": "5_documentacion.html#manual-de-instalación-y-despliegue",
    "title": "Documentación",
    "section": "2. Manual de instalación y despliegue",
    "text": "2. Manual de instalación y despliegue\nEsta sección detalla los requisitos, dependencias y pasos para la instalación y despliegue del chatbot de Salsas Castillo.\n\n2.1. Configuraciones importantes\n\nEl backend del chatbot está desarrollado con FastAPI y se espera que se ejecute en un entorno con Python 3.12.\nRequiere conectividad a una instancia de MongoDB para la gestión de sesiones e historial, y a una base de datos PostgreSQL para datos financieros y de ventas.\nUtiliza modelos de lenguaje de OpenAI (requiere OPENAI_API_KEY) y potencialmente modelos open-source como gemma3:4b a través de Ollama para la moderación.\nLas credenciales sensibles se gestionan a través de un archivo .env.\nLa integración con Telegram se realiza mediante webhooks y el telegram_token correspondiente.\n\n\n\n2.2. Requisitos del sistema\n\nPython: Versión 3.x (se recomienda la versión utilizada en el desarrollo, ej., 3.12.9).\nPip/UV: Última versión para la gestión de paquetes.\nOllama: Instalado y en ejecución si se utilizan modelos open-source para moderación.\nMongoDB: Acceso remoto configurado para las colecciones de sesiones e historial de mensajes.\nPostgreSQL: Acceso remoto configurado para las bases de datos historial_facturas y financieroii.\nConexión a Internet: Necesaria para interactuar con las APIs de OpenAI y Telegram.\n\n\n\n2.3. Dependencias principales del sistema\n\nfastapi: Framework web para el backend.\nlangchain: Framework principal para la orquestación del LLM y las herramientas.\nopenai: Cliente Python para la API de OpenAI.\npymongo: Driver para la interacción con MongoDB.\npsycopg2-binary: Adaptador PostgreSQL para Python.\nfpdf: Para la generación de PDFs.\nrequests: Para realizar solicitudes HTTP (ej., a Telegram, OpenAI Whisper).\nuvicorn/gunicorn: Servidor WSGI para despliegue.\npydantic: Para la validación de modelos de datos.\nfaiss-cpu: Para la base de datos vectorial (si aplica para documentos internos).\n\n\n\n2.4. Requisitos de configuración del backend\n\n2.4.1. Clonar el repositorio\ngh repo fork Macrodata-Analitica/castilloChatbot\ncd castilloChatbot\n\n\n2.4.2. Crear entorno virtual e instalar dependencias\npip install uv # Si no está instalado\nuv venv\nsource .venv/bin/activate # Linux/macOS\n# o `.venv\\Scripts\\activate` para Windows\nuv pip install -e .\nuv sync # Sincroniza los modulos de src/\n\n\n2.4.3. Configurar variables de entorno (.env)\nAsegúrate de que el archivo .env en la raíz del proyecto contenga las siguientes variables con sus valores correctos:\nOPENAI_API_KEY=\"\"\n\nVERIFY_TOKEN=\"\"\nTELEGRAM_BOT_TOKEN=\"\"\nPHONE_NUMBER_ID=\"\"\n\nHOST=\"\"\nPORT=\"\"\nUSER=\"\"\nPASS=\"\"\nDBNAME=\"\"\nSCHEMA=\"\"\n\n\n2.4.4. Configurar Webhook de Telegram\nAsegúrate de que Telegram envíe los mensajes a tu endpoint /webhook. Esto se hace una vez a través de la API de Telegram:\ncurl -F \"url=https://TU_DOMINIO/tgbot/webhook\" https://api.telegram.org/botTU_TELEGRAM_TOKEN/setWebhook\nReemplaza TU_DOMINIO y TU_TELEGRAM_TOKEN.\n\n\n\n2.5 Arquitectura de despliegue continuo y sincronización\nEl servidor implementa un mecanismo adicional para mantener el backend del chatbot actualizado y funcionando de forma estable. Este mecanismo se basa en tres componentes:\n\nEl servicio principal del chatbot (rag.service)\nEl servicio de despliegue (rag-deploy.service)\nEl timer que activa el despliegue cada 30 segundos (rag-deploy.timer)\n\nEste sistema garantiza que:\n\nSi el repositorio cambia, el backend se actualiza automáticamente.\nSi el entorno Python necesita sincronizar dependencias, se hace sin intervención manual.\nSi el servicio falla o se detiene por cualquier motivo, systemd lo vuelve a levantar.\n\nA continuación se explica cada pieza.\n\n2.5.1 Definición del servicio backend rag.service\nEste servicio es el que ejecuta el backend de FastAPI mediante Uvicorn.\n[Unit]\nDescription=Telegram Chat API (Uvicorn)\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nType=simple\nUser=ctrlsalsasc\nWorkingDirectory=/home/ctrlsalsasc/rag_v3\nEnvironment=PYTHONUNBUFFERED=1\nExecStart=/bin/bash -lc 'uv sync && exec uv run uvicorn salsasllm.API.telegram_main:app --host 0.0.0.0 --port 8003'\nRestart=always\nRestartSec=5\nStartLimitIntervalSec=60\nStartLimitBurst=5\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n\n\n2.5.2 Especificaciones operativas\n\nUsa uv sync antes de arrancar para garantizar dependencias correctas.\nCorre en el puerto interno 8003, que Apache expone al público mediante reverse proxy.\nSe auto-reinicia si falla, asegurando alta disponibilidad.\nLos logs se consultan con journalctl -u rag.service -f.\n\n\n\n2.5.3 Servicio de actualización rag-deploy.service\nEste servicio no se ejecuta de manera continua, sino que systemd lo invoca bajo demanda (a través del timer).\n[Unit]\nDescription=Pull + uv sync + restart rag.service si hay cambios\n\n[Service]\nType=oneshot\nUser=ctrlsalsasc\nEnvironment=HEALTHCHECK_URL=http://127.0.0.1:8003/healthz\nExecStart=/usr/local/bin/rag_deploy.sh\n\n\n2.5.4. Lógica de ejecución del script\nEl script (rag_deploy.sh) realiza tareas como:\n\ngit fetch → revisar si hay nuevos commits.\nSi hay cambios → git pull y uv sync.\nReiniciar rag.service solo si fue necesario actualizar.\nEjecutar un healthcheck contra /healthz para validar que el servicio levantó correctamente.\n\nEste patrón es más robusto que un simple cron, porque systemd:\n\nControla fallos.\nRegistra logs.\nEvita ejecuciones simultáneas.\nPuede reintentar si algo sale mal.\n\n\n\n\n2.5.5 Programación del timer de sistema rag-deploy.timer\nEl timer configura cada cuánto debe ejecutarse el servicio anterior:\n[Unit]\nDescription=Timer para rag-deploy.service (cada minuto)\n\n[Timer]\nOnUnitActiveSec=30s\nAccuracySec=5s\nPersistent=true\n\n[Install]\nWantedBy=timers.target\nDefiniciones\n\n\n\n\n\n\n\nConfiguración\nFunción\n\n\n\n\nOnUnitActiveSec=30s\nEjecuta el despliegue 30 segundos después de la última ejecución → es decir, cada 30s continuamente.\n\n\nPersistent=true\nSi el servidor estuvo apagado, ejecuta de inmediato lo que quedó pendiente.\n\n\nAccuracySec=5s\nsystemd puede adelantar o atrasar unos segundos para optimizar carga del sistema.\n\n\n\nComandos útiles Ver estado del timer:\nsystemctl status rag-deploy.timer\nVer cuándo se ejecutó la última vez:\nsystemctl list-timers | grep rag\nVer logs del despliegue:\njournalctl -u rag-deploy.service -f\nForzar un despliegue manual:\nsudo systemctl start rag-deploy.service\n\n\n\n2.6 Infraestructura de red: Reverse proxy con Apache\nEl servidor utiliza Apache2 como reverse proxy para exponer los servicios del chatbot hacia Internet de forma segura a través de HTTPS. Esta configuración permite que los procesos internos de FastAPI, que corren localmente en puertos como 8003 o 8006, sean accesibles mediante rutas amigables bajo el dominio oficial de la empresa.\nEl archivo principal de configuración utilizado por el dominio seguro es: /etc/apache2/sites-enabled/default-ssl.conf\nReverse Proxy para el servicio Telegram Bot (Producción)\n# Telegram ChatBot\nProxyPreserveHost On\nProxyPass /tgbot http://127.0.0.1:8003/\nProxyPassReverse /tgbot http://127.0.0.1:8003/\n\nRewriteEngine On\nRewriteRule ^/tgbot(/.*)?$ http://127.0.0.1:8003$1 [P,L]\n\n&lt;Location tgbot&gt;\n    Require all granted\n    AllowOverride None\n&lt;/Location&gt;\nExplicación del funcionamiento\n\n\n\n\n\n\n\nDirectiva\nFunción\n\n\n\n\nProxyPreserveHost On\nMantiene el header Host original enviado por el cliente. Esto permite que FastAPI identifique correctamente el dominio público.\n\n\nProxyPass /tgbot …\nTodo lo que llegue a https://apps.salsascastillo.com/tgbot será enviado internamente al proceso de FastAPI que corre en http://127.0.0.1:8003/.\n\n\nProxyPassReverse\nAjusta los encabezados de respuesta para que FastAPI no devuelva rutas internas.\n\n\nRewriteEngine + RewriteRule\nSe asegura de que todas las subrutas, como /tgbot/webhook, /tgbot/logs, etc., se redirijan correctamente al backend.\n\n\nLocation\nPermite acceso público a la ruta (sin autenticación adicional).\n\n\n\nEsta sección expone el servicio de Telegram en producción y es el endpoint donde se configura el webhook de Telegram:\nhttps://apps.salsascastillo.com/tgbot/webhook\nConfiguración SSL En la parte final del archivo se incluyen los certificados emitidos por Let’s Encrypt a través de Certbot:\nSSLCertificateFile /etc/letsencrypt/live/apps.salsascastillo.com/fullchain.pem \nSSLCertificateKeyFile /etc/letsencrypt/live/apps.salsascastillo.com/privkey.pem \nInclude /etc/letsencrypt/options-ssl-apache.conf\nDetalles importantes\n\nfullchain.pem contiene la cadena completa del certificado, incluida la autoridad intermedia.\nprivkey.pem es la llave privada del dominio (solo debe tener permisos 600 y dueño root).\noptions-ssl-apache.conf aplica configuraciones modernas recomendadas por Let’s Encrypt (TLS, Cipher Suites, HSTS, etc.).\nLa renovación ocurre automáticamente con el timer de Certbot (/lib/systemd/system/certbot.timer).\n\nResumen del flujo\n\nEl usuario envía una petición a: https://apps.salsascastillo.com/tgbot/...\nApache la recibe sobre HTTPS.\nApache la redirige internamente al backend FastAPI: http://127.0.0.1:8003/...\nFastAPI procesa el mensaje y responde.\nApache reescribe los encabezados y envía la respuesta al cliente.\n\nEste patrón es robusto, seguro y permite correr múltiples servicios simultáneamente sin exponer puertos internos a Internet."
  },
  {
    "objectID": "5_documentacion.html#documentación-técnica-del-código",
    "href": "5_documentacion.html#documentación-técnica-del-código",
    "title": "Documentación",
    "section": "3. Documentación técnica del código",
    "text": "3. Documentación técnica del código\nEsta sección describe la estructura modular del proyecto y las funciones clave de sus componentes.\n\n3.1. Estructura de carpetas y módulos\nEl proyecto sigue una estructura modular para organizar el código:\n\nsalsasllm/API/telegram_main.py: Archivo principal de la aplicación FastAPI. Configura la aplicación, CORS y registra los endpoints para el chat de Telegram y los logs.\nsalsasllm/API/telegram_chat.py: Contiene la lógica para manejar los webhooks de Telegram, transcribir audio (usando Whisper), enviar mensajes y coordinar con el agente principal.\nsalsasllm/langchain/agent_multitool.py: Implementa la lógica principal del agente conversacional (AgentMultiTools). Gestiona la interacción con herramientas externas (SQL, PDF, búsqueda de información), el historial de conversación en MongoDB y la conexión con el LLM.\nsalsasllm/langchain/vectorstore.py: Implementa la lógica para la creación, carga y consulta de la base de datos vectorial FAISS.\nsalsasllm/tools/search_information.py: Define la herramienta search_information para buscar información relevante en documentos internos (a través del vector store).\nsalsasllm/tools/pdf_tool.py: Define la herramienta generate_financial_report_pdf para crear reportes en PDF a partir de datos tabulares y enviarlos por Telegram.\nsalsasllm/langchain/prompts.py: Contiene las definiciones de los prompts del sistema (prompt_v1, prompt_v2) que guían el comportamiento del LLM.\nsalsasllm/settings/clientes.py: Archivo para la configuración de credenciales (API keys, datos de conexión a DBs, tokens).\nsalsasllm/settings/config.py: Archivo para configuraciones generales del proyecto (ej., rutas de índices FAISS, whitelist de Telegram).\n\n\n\n3.2. Modelos LLM utilizados\nEl sistema de Salsas Castillo utiliza una combinación de modelos de lenguaje para diferentes propósitos:\n\nGeneración de respuestas y razonamiento (OpenAI - gpt-5):\n\nFunción: Es el LLM principal utilizado por AgentMultiTools para interpretar las consultas del usuario, decidir qué herramientas invocar (SQL, búsqueda de información, PDF) y generar las respuestas detalladas.\nVentaja: Ofrece alta capacidad de razonamiento y comprensión contextual para manejar consultas complejas sobre datos financieros y de ventas.\n\nTranscripción de audio (OpenAI Whisper - whisper-1):\n\nFunción: Utilizado en telegram_chat.py para transcribir mensajes de voz de los usuarios de Telegram a texto, permitiendo que el chatbot procese entradas de audio.\nVentaja: Alta precisión en la transcripción de voz a texto.\n\nGeneración de análisis para PDF (OpenAI - gpt-5):\n\nFunción: En pdf_tool.py, este modelo se utiliza para generar un párrafo de análisis conciso a partir de los datos tabulares que se incluirán en el reporte PDF.\nVentaja: Proporciona resúmenes inteligentes y profesionales de los datos.\n\n\n\n\n3.3. Puntos de entrada y funciones clave\nEstos son los principales puntos de inicio para interactuar con las funcionalidades del chatbot:\nAPI/telegram_main.py::telegram_webhook_handler:\n@app.post(\"/webhook\")\nasync def telegram_webhook_handler(\n    request: Request, \n    background_tasks: BackgroundTasks):\n\nPropósito: Es el endpoint de FastAPI que recibe todos los mensajes y actualizaciones de Telegram. Actúa como el punto de entrada principal para las interacciones del usuario.\nComportamiento: Recibe el payload de Telegram, extrae el chat_id y el mensaje (texto o voz), verifica si el usuario está en la whitelist y delega el procesamiento a handle_message en segundo plano.\n\nAPI/telegram_chat.py::handle_message:\ndef answer(self, \n    question: str = None, \n    session_id: str = None, \n    name: str = None) -&gt; str:\n\nPropósito: Es la función central que orquesta la respuesta del chatbot. Recibe la pregunta del usuario, gestiona el historial de la sesión, invoca el AgentExecutor de LangChain y maneja la salida.\nComportamiento:\n\nAsegura la existencia de la sesión en MongoDB (ensure_session).\nRecupera y trunca el historial de la sesión (get_session_history, trim_history).\nInvoca al AgentExecutor con la pregunta y el historial, permitiendo que el LLM decida qué herramientas usar (SQL, search_information, pdf_report_tool).\nRegistra la interacción completa en MongoDB (add_message, add_message_backup).\nSi la respuesta es un PDF, coordina su envío a Telegram.\n\n\ntools/pdf_tool.py::generate_financial_report_pdf:\ndef generate_financial_report_pdf(\n    table_data: str, \n    title: str, \n    chat_id: int) -&gt; dict:\n\nPropósito: Genera un reporte en formato PDF a partir de datos tabulares proporcionados y un análisis generado por un LLM, y lo envía al usuario de Telegram.\nComportamiento: Utiliza fpdf para crear el PDF, get_llm_analysis para obtener un resumen del LLM y enviar_pdf_por_telegram para enviar el archivo.\n\nlangchain/vectorstore.py::LangchainVectorStore.create_index:\ndef create_index(self, docs):\n\nPropósito: Crea un nuevo índice FAISS a partir de una lista de documentos.\nComportamiento: Utiliza FAISS.from_documents para generar el índice y lo guarda localmente."
  },
  {
    "objectID": "5_documentacion.html#guía-de-entrenamiento-y-mejora",
    "href": "5_documentacion.html#guía-de-entrenamiento-y-mejora",
    "title": "Documentación",
    "section": "4. Guía de entrenamiento y mejora",
    "text": "4. Guía de entrenamiento y mejora\nEsta sección aborda cómo se mantiene y mejora la base de conocimientos del chatbot, así como recomendaciones para futuras optimizaciones.\n\n4.1. Generación y actualización de la base de datos vectorial\nLa herramienta search_information se basa en un vector store FAISS. Este vector store almacena representaciones vectoriales de documentos internos (manuales, reglamentos, etc.) para permitir búsquedas semánticas.\nProceso de Creación: Los documentos internos se convierten en objetos langchain.schema.Document, se generan embeddings utilizando OpenAIEmbeddings, y luego se construye un índice FAISS que se guarda localmente.\nActualización: Para mantener la información actualizada, se debe ejecutar periódicamente el script que reconstruye o actualiza este vector store con cualquier nuevo documento o modificación.\n\n\n4.2. Recomendaciones para mejora futura\n\nMonitoreo avanzado: Implementar un monitoreo más detallado de las interacciones del chatbot, incluyendo el rendimiento de las consultas SQL, el tiempo de respuesta de las herramientas y la calidad de las respuestas generadas por el LLM. Esto puede hacerse analizando los datos en la colección message_backup de MongoDB.\nOptimización de prompts: Continuar iterando y refinando los prompts (prompts.py) para mejorar la precisión y coherencia de las respuestas, especialmente en casos complejos o ambiguos.\nManejo de errores robustos: Mejorar el manejo de errores en las llamadas a APIs externas (OpenAI, Telegram) y a las bases de datos (PostgreSQL, MongoDB) para proporcionar mensajes más informativos al usuario y facilitar la depuración.\nExpansión de herramientas: Considerar la adición de nuevas herramientas para el agente, como la capacidad de crear gráficos a partir de datos financieros, o interactuar con otros sistemas internos de Salsas Castillo.\nEvaluación cuantitativa: Si es posible, definir métricas cuantitativas para evaluar la calidad de las respuestas del chatbot (ej., ROUGE, BLEU, o métricas basadas en la satisfacción del usuario) para complementar la evaluación cualitativa.\nEmbeddings locales (Opcional): Investigar el uso de modelos de embeddings open-source (ej., a través de Ollama) para reducir la dependencia de OpenAI y potencialmente los costos, si la precisión es aceptable para los casos de uso de Salsas Castillo."
  },
  {
    "objectID": "5_documentacion.html#arquitectura",
    "href": "5_documentacion.html#arquitectura",
    "title": "Documentación",
    "section": "5. Arquitectura",
    "text": "5. Arquitectura\n\n5.1. Componentes clave:\n\nUsuario de Telegram: El usuario final que interactúa con el chatbot a través de la aplicación de mensajería.\nBackend del Chatbot (FastAPI): El servicio principal que procesa las consultas de los usuarios.\n\ntelegram_main.py: Punto de entrada de los webhooks de Telegram.\ntelegram_chat.py: Maneja la lógica de Telegram (transcripción de voz, envío de mensajes) y coordina preguntas y respuestas con el agente.\nagent_multitool.py: Contiene el AgentMultiTools que orquesta el LLM y las herramientas.\n\nModelo agéntico: El cerebro principal que utiliza un LLM para generar respuestas, razonar y decidir el uso de herramientas.\nBase de Datos NoSQL (MongoDB): Almacena el historial de sesiones (sessions) y un respaldo completo de mensajes (message_backup) para análisis.\nBase de Datos Relacional (PostgreSQL): Contiene los datos transaccionales de ventas (historial_facturas) y datos financieros consolidados (financieroii).\nBase de Datos Vectorial (FAISS): Almacena los embeddings de documentos internos para búsquedas semánticas (utilizado por search_information).\nHerramientas: Funciones específicas que el LLM puede invocar:\n\nsql_db_query, sql_db_schema, etc. (de SQLDatabaseToolkit): Para interactuar con PostgreSQL.\nsearch_information: Para buscar en el vector store de documentos internos.\npdf_report_tool: Para generar y enviar reportes PDF.\n\n\n\n\n5.2. Flujo de Interacción Principal:\n\nEl Usuario de Telegram envía un mensaje (texto o voz) al chatbot.\nEl mensaje es recibido por la API y enviado al endpoint /webhook del Backend del Chatbot.\ntelegram_chat.py procesa el mensaje. Si es voz, lo envía a OpenAI Whisper API para transcripción.\nEl texto del mensaje se pasa a AgentMultiTools (agent_multitool.py).\nAgentMultiTools gestiona la sesión en MongoDB y consulta el historial.\nEl LLM, guiado por los prompts (prompts.py), analiza la consulta y decide qué Herramientas utilizar:\n\nSi necesita datos de ventas, finanzas, facturas, u otras tablas, invoca herramientas SQL para consultar la base de datos de PostgreSQL.\nSi necesita información de documentos internos, invoca search_information para buscar en la Base de Datos Vectorial (FAISS).\nSi se solicita un reporte, invoca pdf_report_tool, que a su vez puede usar el LLM para análisis y luego envía el PDF a Telegram.\nSi la consulta se trata sobre una visualización de datos, se invoca table_tool, toma los datos devueltos por la consulta SQL, los convierte a tabla, lo guarda temporalmente como imagen y lo envía al usuario.\n\nLa información recuperada por las herramientas se contextualiza y se envía de nuevo al LLM para generar la respuesta final al usuario.\nLa respuesta es enviada de vuelta al Usuario de Telegram a través de la API.\nTodas las interacciones (consultas y respuestas) se registran en las colecciones sessions y message_backup en MongoDB para análisis y auditoría.\n\n\n\n5.3. Diagrama de la Arquitectura\nEl siguiente diagrama ilustra la arquitectura general del sistema del chatbot para Salsas Castillo, mostrando los componentes principales y el flujo de datos.\n\n\n\nArquitectura del sistema"
  },
  {
    "objectID": "3_modelado.html",
    "href": "3_modelado.html",
    "title": "Modelado y Evaluación",
    "section": "",
    "text": "El objetivo de esta fase es desarrollar la arquitectura del sistema del chatbot, integrando modelos de lenguaje, herramientas de acceso a datos y mecanismos de interacción.\n\n\nLa implementación del sistema se basa en una estructura modular orientada a clases, facilitando el mantenimiento y la escalabilidad. La librería principal utilizada es LangChain, que permite orquestar la interacción entre el LLM y diversas herramientas.\nLa arquitectura se centra en un modelo agéntico (AgentMultiTools) que actúa como el cerebro del chatbot.\n\n\nEl agente tiene acceso a un conjunto de herramientas dinámicas que le permiten consultar datos actualizados en tiempo real o realizar acciones específicas:\n\nHerramienta RAG: search_info_tool: Realiza búsquedas semánticas en el vector store de documentos internos.\n\n@tool(description=\"Busca información de documentos, manuales, reglamentos, etc. Devuelve un resumen de la información relevante.\")\ndef search_information(query: str) -&gt; str:\n    # ... lógica de búsqueda en vector store ...\n\nHerramientas SQL: Permiten al agente interactuar directamente con la base de datos PostgreSQL. Estas incluyen:\nsql_db_query: Para ejecutar consultas SQL y obtener resultados.\nsql_db_schema: Para obtener el esquema de las tablas y entender su estructura.\nsql_db_list_tables: Para listar las tablas disponibles.\n\n@tool(description=\"Cuando te pidan generar un reporte financiero en PDF a partir de datos generados previamente.\")\ndef generate_financial_report_pdf(table_data: str, title: str, chat_id: int) -&gt; dict:\n    # ... lógica de generación de PDF y envío a Telegram ...\nHerramientas de Generación*\n\npdf_report_tool: Genera reportes financieros en PDF a partir de datos tabulares y los envía al usuario.\ntable_tool: Cuando se trate simplemente de una visualización de datos, estos se presentan mediante una tabla convertida en imagen. Facilitando la comprensión y visualización de la información.\n\nEstas herramientas son invocadas automáticamente por el agente cuando el LLM determina que son necesarias para responder a la consulta del usuario.\n\n\n\nEl sistema se alimenta de información de la siguiente manera:\n\nConsultas de Usuario: La pregunta del usuario es el punto de entrada.\nHistorial de Conversación: El historial se gestiona en MongoDB (sessions collection) y se trunca para ajustarse a la ventana de contexto del LLM.\nLLM: Interpreta la consulta y decide qué herramientas usar.\nHerramientas SQL: Si la consulta requiere datos de la base de datos, el LLM genera una consulta SQL que se ejecuta en PostgreSQL. Los resultados se devuelven al LLM.\nHerramienta de Búsqueda de Información: Si la consulta es sobre documentos internos, se busca en el vector store (FAISS) y la información relevante se devuelve al LLM para generar la respuesta.\nHerramienta de PDF: Si se solicita un reporte, se genera el PDF con el análisis del LLM y se envía. Estos análisis pueden incluir gráficas o no.\nGeneración de Respuesta: El LLM sintetiza la información que devuelven las herramientas y genera la respuesta final al usuario.\n\n\n\n\n\nEl LLM opera con los siguientes atributos y contexto:\n\nquestion: La consulta directa del usuario.\nchat_id | session_id: ID de Telegram del usuario, necesario para enviar mensajes y PDFs directamente a Telegram. También es el identificador único de la sesión del usuario, crucial para mantener el historial de conversación.\nname: Nombre del usuario de Telegram, utilizado para personalizar la interacción.\nchat_history: Historial de mensajes previos de la sesión, truncado para optimizar el contexto.\n\n\n\n\nEl sistema de Salsas Castillo utiliza estratégicamente varios modelos de lenguaje:\n\nGPT (OpenAI):\n\nFunción principal: Es el modelo central para el razonamiento del agente, la interpretación de consultas complejas y la generación de respuestas detalladas. Decide cuándo y cómo usar las herramientas SQL, de búsqueda de información y de PDF. También se utiliza para generar el análisis textual en los reportes PDF.\nVentaja: Alta capacidad de comprensión, razonamiento y generación de texto coherente y preciso, fundamental para análisis financiero y de ventas. Actualmente usamos el modelo GPT-5 como modelo central pero también usamos el modelo GPT-4.1 en ciertas herramientas por su gran ventana de contexto que permite manejar mayor cantidad de información.\n\nWhisper-1 (OpenAI):\n\nFunción: Utilizado para la transcripción de mensajes de voz de los usuarios de Telegram a texto.\nVentaja: Excelente precisión en la conversión de audio a texto, lo que permite una interacción más flexible con el chatbot."
  },
  {
    "objectID": "3_modelado.html#modelado",
    "href": "3_modelado.html#modelado",
    "title": "Modelado y Evaluación",
    "section": "",
    "text": "El objetivo de esta fase es desarrollar la arquitectura del sistema del chatbot, integrando modelos de lenguaje, herramientas de acceso a datos y mecanismos de interacción.\n\n\nLa implementación del sistema se basa en una estructura modular orientada a clases, facilitando el mantenimiento y la escalabilidad. La librería principal utilizada es LangChain, que permite orquestar la interacción entre el LLM y diversas herramientas.\nLa arquitectura se centra en un modelo agéntico (AgentMultiTools) que actúa como el cerebro del chatbot.\n\n\nEl agente tiene acceso a un conjunto de herramientas dinámicas que le permiten consultar datos actualizados en tiempo real o realizar acciones específicas:\n\nHerramienta RAG: search_info_tool: Realiza búsquedas semánticas en el vector store de documentos internos.\n\n@tool(description=\"Busca información de documentos, manuales, reglamentos, etc. Devuelve un resumen de la información relevante.\")\ndef search_information(query: str) -&gt; str:\n    # ... lógica de búsqueda en vector store ...\n\nHerramientas SQL: Permiten al agente interactuar directamente con la base de datos PostgreSQL. Estas incluyen:\nsql_db_query: Para ejecutar consultas SQL y obtener resultados.\nsql_db_schema: Para obtener el esquema de las tablas y entender su estructura.\nsql_db_list_tables: Para listar las tablas disponibles.\n\n@tool(description=\"Cuando te pidan generar un reporte financiero en PDF a partir de datos generados previamente.\")\ndef generate_financial_report_pdf(table_data: str, title: str, chat_id: int) -&gt; dict:\n    # ... lógica de generación de PDF y envío a Telegram ...\nHerramientas de Generación*\n\npdf_report_tool: Genera reportes financieros en PDF a partir de datos tabulares y los envía al usuario.\ntable_tool: Cuando se trate simplemente de una visualización de datos, estos se presentan mediante una tabla convertida en imagen. Facilitando la comprensión y visualización de la información.\n\nEstas herramientas son invocadas automáticamente por el agente cuando el LLM determina que son necesarias para responder a la consulta del usuario.\n\n\n\nEl sistema se alimenta de información de la siguiente manera:\n\nConsultas de Usuario: La pregunta del usuario es el punto de entrada.\nHistorial de Conversación: El historial se gestiona en MongoDB (sessions collection) y se trunca para ajustarse a la ventana de contexto del LLM.\nLLM: Interpreta la consulta y decide qué herramientas usar.\nHerramientas SQL: Si la consulta requiere datos de la base de datos, el LLM genera una consulta SQL que se ejecuta en PostgreSQL. Los resultados se devuelven al LLM.\nHerramienta de Búsqueda de Información: Si la consulta es sobre documentos internos, se busca en el vector store (FAISS) y la información relevante se devuelve al LLM para generar la respuesta.\nHerramienta de PDF: Si se solicita un reporte, se genera el PDF con el análisis del LLM y se envía. Estos análisis pueden incluir gráficas o no.\nGeneración de Respuesta: El LLM sintetiza la información que devuelven las herramientas y genera la respuesta final al usuario.\n\n\n\n\n\nEl LLM opera con los siguientes atributos y contexto:\n\nquestion: La consulta directa del usuario.\nchat_id | session_id: ID de Telegram del usuario, necesario para enviar mensajes y PDFs directamente a Telegram. También es el identificador único de la sesión del usuario, crucial para mantener el historial de conversación.\nname: Nombre del usuario de Telegram, utilizado para personalizar la interacción.\nchat_history: Historial de mensajes previos de la sesión, truncado para optimizar el contexto.\n\n\n\n\nEl sistema de Salsas Castillo utiliza estratégicamente varios modelos de lenguaje:\n\nGPT (OpenAI):\n\nFunción principal: Es el modelo central para el razonamiento del agente, la interpretación de consultas complejas y la generación de respuestas detalladas. Decide cuándo y cómo usar las herramientas SQL, de búsqueda de información y de PDF. También se utiliza para generar el análisis textual en los reportes PDF.\nVentaja: Alta capacidad de comprensión, razonamiento y generación de texto coherente y preciso, fundamental para análisis financiero y de ventas. Actualmente usamos el modelo GPT-5 como modelo central pero también usamos el modelo GPT-4.1 en ciertas herramientas por su gran ventana de contexto que permite manejar mayor cantidad de información.\n\nWhisper-1 (OpenAI):\n\nFunción: Utilizado para la transcripción de mensajes de voz de los usuarios de Telegram a texto.\nVentaja: Excelente precisión en la conversión de audio a texto, lo que permite una interacción más flexible con el chatbot."
  },
  {
    "objectID": "3_modelado.html#evaluación",
    "href": "3_modelado.html#evaluación",
    "title": "Modelado y Evaluación",
    "section": "2. Evaluación",
    "text": "2. Evaluación\nLa evaluación del chatbot de Salsas Castillo se centra en la calidad y precisión de sus respuestas, dada la naturaleza de las consultas financieras y de ventas.\n\n2.1. Criterios de Evaluación\nLa evaluación se realiza mediante un análisis cualitativo, considerando los siguientes criterios:\n\nPrecisión de los Datos: La información proporcionada (cifras de ventas, costos, nombres de productos) debe coincidir exactamente con los datos de las bases de datos SQL.\nCoherencia y Relevancia: Las respuestas deben ser lógicas, directas y pertinentes a la pregunta del usuario, evitando “alucinaciones” o información incorrecta.\nCapacidad de Análisis: Para consultas que requieren análisis (ej., tendencias de ventas, márgenes), la respuesta debe ser comprensible y destacar las conclusiones clave.\nGeneración de Reportes: Los PDFs generados deben ser comprensibles, contener los datos solicitados y el análisis del LLM debe ser claro y profesional.\nManejo de Ambigüedad: La capacidad del chatbot para pedir aclaraciones o proponer interpretaciones cuando la consulta no es clara. También debe ser capaz de generar respuestas generales aún cuando falte especificación de la información.\n\n\n\n2.2. Proceso de Evaluación (Simulación)\nSe simulan una serie de consultas típicas que un usuario de Salsas Castillo podría realizar, cubriendo distintos escenarios:\n\nConsultas de Ventas: “Muéstrame las ventas del producto ‘AMOR 12 / 1000 ML’ en el último mes.”\nConsultas Financieras: “¿Cuál fue el margen de ganancia del segundo trimestre de 2025?”\nGeneración de Reportes: “Genera un reporte de ventas por presentación para el mes de mayo.”\nBúsqueda de Documentos: “Necesito el reglamento de uso de las bodegas.” (Si aplica y se ha cargado un documento de ejemplo)\nConsultas Ambiguas: “Quiero saber sobre las salsas vendidas ayer” (El chatbot debería pedir más detalles o sugerir opciones o debería generar una respuestas general).\n\nLos resultados de estas simulaciones son revisados por expertos con conocimiento del negocio para validar la calidad de las respuestas y el comportamiento general del sistema.\nLos resultados obtenidos hasta ahora sugieren un desempeño prometedor del sistema, con respuestas coherentes y alineadas con las bases de datos. Esto valida la viabilidad de continuar con el despliegue y la iteración en un entorno de pruebas real."
  },
  {
    "objectID": "1_comprension.html",
    "href": "1_comprension.html",
    "title": "Comprensión del negocio",
    "section": "",
    "text": "Salsas Castillo es una empresa dedicada a la producción y comercialización de salsas picantes, soya, chamoy y otros productos. Su portafolio se distribuye a una amplia red de tiendas, restaurantes y mayoristas en todo México. Con un catálogo en constante crecimiento y una operación comercial dinámica, la empresa enfrenta el reto de gestionar grandes volúmenes de información interna de forma ágil y eficiente.\nActualmente, el acceso a datos específicos —como ventas, finanzas o documentación interna— suele ser un proceso manual y demandante, lo que dificulta responder con rapidez a consultas y limita la generación de análisis oportunos para la toma de decisiones. Esto ha impulsado la necesidad de una solución que centralice y automatice el acceso a la información.\nObjetivo del proyecto:\nDesarrollar un chatbot inteligente que funcione como asistente virtual para el personal de Salsas Castillo, permitiendo realizar consultas rápidas y precisas sobre datos de ventas, finanzas, facturas y documentos internos. El propósito es mejorar la eficiencia operativa, elevar la calidad de la toma de decisiones y fortalecer la comunicación interna.\nImpacto:\nLa implementación de este chatbot permitirá a Salsas Castillo:\n\nAgilizar el acceso a la información: Reducir el tiempo que el personal dedica a buscar datos específicos en bases de datos o documentos.\nMejorar la precisión de los datos: Proporcionar respuestas consistentes y actualizadas directamente de las fuentes de datos en tiempo real.\nFomentar la autonomía: Empoderar a los empleados para obtener la información que necesitan sin depender de intermediarios y al alcance de su mano.\nOptimizar la toma de decisiones: Facilitar análisis rápidos y la generación de reportes para una gestión más proactiva."
  },
  {
    "objectID": "1_comprension.html#objetivos-de-la-línea-de-investigación",
    "href": "1_comprension.html#objetivos-de-la-línea-de-investigación",
    "title": "Comprensión del negocio",
    "section": "0.1 Objetivos de la línea de investigación",
    "text": "0.1 Objetivos de la línea de investigación\nEsta iniciativa se enfoca en aprovechar la información existente de Salsas Castillo para crear un sistema de consulta inteligente.\nEl objetivo principal es desarrollar un chatbot en Telegram que funcione como un asistente virtual para la generación de análisis complejos, capaz de:\n\nInterpretar consultas en lenguaje natural: Permitir a los usuarios hacer preguntas complejas sin necesidad de conocimientos técnicos de bases de datos.\nAcceder a datos dinámicos: Conectarse directamente a las bases de datos transaccionales (PostgreSQL) para obtener información actualizada dentro de la base de datos.\nBuscar en documentos internos: Utilizar una base de datos vectorial para recuperar información de documentos como manuales, reglamentos, contratos, etc.\nGenerar reportes: Crear y enviar reportes financieros en formato PDF a través de Telegram.\n\nObjetivos específicos:\n\nIntegrar fuentes de datos: Establecer conexiones robustas con las bases de datos en PostgreSQL.\nDesarrollar herramientas de consulta: Implementar funciones que permitan al LLM interactuar con SQL para extraer y procesar datos.\nConstruir una base de conocimiento vectorial: Procesar documentos internos para crear embeddings y un vector store para búsquedas semánticas.\nImplementar un agente conversacional: Configurar un agente basado en LangChain que orqueste el uso del LLM y las herramientas.\nHabilitar la generación de reportes PDF: Desarrollar la capacidad de crear reportes dinámicos a partir de los datos consultados.\nDesplegar el chatbot en Telegram: Asegurar la funcionalidad completa del chatbot en la plataforma de Telegram, incluyendo la transcripción de audio.\n\nCriterios de éxito:\n\nPrecisión de las respuestas: El chatbot debe proporcionar información precisa, exacta y relevante en al menos el 90% de las consultas cuando se trate de cálculos y uso de formulas.\nFidelidad: Debe ser fiel a la información extraída de las bases de datos sin presentar alucionaciones en al menos el 90% de las consultas.\nCapacidad de análisis: Debe ser capaz de realizar análisis tanto básicos como complejos de datos y generar reportes comprensibles.\nUsabilidad: La interacción a través de Telegram debe ser intuitiva y accesible para usuarios con diferentes niveles de conocimientos técnicos."
  },
  {
    "objectID": "1_comprension.html#evaluación-de-la-situación-actual",
    "href": "1_comprension.html#evaluación-de-la-situación-actual",
    "title": "Comprensión del negocio",
    "section": "0.2 Evaluación de la Situación Actual",
    "text": "0.2 Evaluación de la Situación Actual\nLos recursos disponibles para este proyecto incluyen:\n\nDatos: Acceso a bases de datos PostgreSQL con información de ventas transaccionales y datos financieros consolidados.\nHerramientas: Python, FastAPI, LangChain, OpenAI API, PyMongo, Reportlab, y PostgreSQL.\nEquipo humano: El equipo de Salsas Castillo que provee la información y el contexto necesario para alinear el conocimiento del sistma, y el equipo de desarrollo del proyecto.\n\n\n0.2.1 Requisitos, Supuestos y Restricciones\nRequisitos:\n\nAcceso continuo y estable a las bases de datos PostgreSQL y MongoDB.\nServidor donde se desplegará la API del sistema desarrollado.\nCredenciales válidas para las APIs de OpenAI y el token de Telegram.\nComunicación fluida para la retroalimentación y validación de funcionalidades.\n\nSupuestos:\n\nLas bases de datos de la empresa contienen la información necesaria y están estructuradas de manera que permitan las consultas requeridas sin complicaciones.\nLa API de OpenAI y Telegram mantendrán su disponibilidad y rendimiento.\nEl servidor proveído por la empresa estará siempre disponible para el equipo de desarrollo sin restricciones.\n\nRestricciones:\n\nPosibles limitaciones en la tasa de llamadas a las APIs externas.\nLa complejidad de las consultas SQL puede requerir optimización.\nLa seguridad de la información debe ser una prioridad en todo momento."
  },
  {
    "objectID": "1_comprension.html#terminología",
    "href": "1_comprension.html#terminología",
    "title": "Comprensión del negocio",
    "section": "0.3 Terminología",
    "text": "0.3 Terminología\nAlgunas de las terminologías clave para este proyecto son:\n\nPython: Lenguaje de programación de alto nivel, fundamental para el desarrollo del backend del chatbot.\nFastAPI: Framework de desarrollo web en Python para construir APIs de forma rápida y eficiente.\nLangChain: Herramienta para construir aplicaciones que combinan modelos de lenguaje con fuentes de datos externas y lógica personalizada.\nInteligencia Artificial (IA): Campo de la informática que desarrolla sistemas capaces de realizar tareas que requieren inteligencia humana.\nModelos de Lenguaje Grande (LLM): Modelos de IA entrenados con vastos volúmenes de texto para comprender y generar lenguaje natural. En este proyecto, se utiliza GPT-4.1 de OpenAI.\nSistema de Recuperación Aumentada con Generación (RAG): Técnica que combina LLMs con bases de datos externas para recuperar información relevante y generar respuestas más precisas y contextualizadas.\nRepresentación Vectorial: Proceso de convertir datos textuales en representaciones numéricas (vectores) para facilitar su análisis y búsqueda.\nModelo de Embeddings: Algoritmo que transforma palabras o frases en vectores. Se utilizan OpenAI Embeddings para documentos internos.\nBase de Datos Vectorial (FAISS): Sistema de almacenamiento optimizado para buscar y recuperar información midiendo la similitud entre vectores. Se utiliza para documentos internos.\nBase de Datos SQL (Structured Query Language): Sistema de almacenamiento relacional que organiza los datos en tablas. En este proyecto, PostgreSQL es la fuente de datos transaccionales y financieros.\nAPI (Interfaz de Programación de Aplicaciones): Conjunto de reglas que permite que diferentes sistemas de software se comuniquen entre sí.\nAPI Key: Clave de autenticación utilizada para acceder a servicios protegidos por una API.\nEndpoint (API): Dirección específica dentro de una API donde se accede a una funcionalidad concreta.\nPayload (HTTP): Contenido de los datos enviados en una solicitud HTTP.\nChatbot: Programa que interactúa con los usuarios mediante lenguaje natural.\nTelegram Bot API: La interfaz de programación que permite a los desarrolladores crear bots que interactúan con los usuarios de Telegram.\nWebhook: Un mecanismo que permite a una aplicación recibir información en tiempo real de otra aplicación cuando ocurre un evento específico.\nMongoDB: Base de datos NoSQL utilizada para almacenar el historial de sesiones y los respaldos de mensajes.\nOpenAI Whisper: Modelo de IA para la transcripción de audio a texto.\nReportlab: Librería de Python para la generación de documentos PDF. `"
  },
  {
    "objectID": "1_comprension.html#beneficios",
    "href": "1_comprension.html#beneficios",
    "title": "Comprensión del negocio",
    "section": "0.4 Beneficios",
    "text": "0.4 Beneficios\n\nAcceso Instantáneo a la Información: El personal puede obtener datos clave de ventas y finanzas en segundos, directamente desde Telegram.\nAnálisis de Datos Simplificado: La capacidad de generar reportes en PDF con un análisis generado por el LLM democratiza el acceso a distintas perspectivas del negocio.\nReducción de Carga de Trabajo: Disminuye la necesidad de consultas manuales a las bases de datos y/o la preparación de reportes rutinarios.\nMejora en la Productividad: Permite a los equipos enfocarse en tareas de mayor valor al tener la información al alcance de la mano.\nInnovación Tecnológica: Salsas Castillo se posiciona a la vanguardia en el uso de IA para la gestión empresarial."
  },
  {
    "objectID": "1_comprension.html#costos",
    "href": "1_comprension.html#costos",
    "title": "Comprensión del negocio",
    "section": "0.5 Costos",
    "text": "0.5 Costos\n\nTiempo: El desarrollo y la implementación del chatbot requieren una inversión de tiempo significativa del equipo de desarrollo.\nFinancieros: Costos asociados a las suscripciones de APIs (OpenAI) y, potencialmente, a la infraestructura de servidores para el despliegue."
  },
  {
    "objectID": "0_home.html",
    "href": "0_home.html",
    "title": "GlorIA: Análisis empresarial desde un enfoque con IA",
    "section": "",
    "text": "Este proyecto se enfoca en el desarrollo de un chatbot inteligente para Salsas Castillo, diseñado para optimizar el acceso a información crítica de ventas, finanzas, facturas y más. A través de este asistente conversacional, se busca empoderar al personal de toma de decisiones, proporcionando respuestas rápidas y precisas a sus consultas, y facilitando la toma de decisiones basadas en datos actualizados que cambian en tiempo real.\nEl chatbot se basa en un modelo agéntico MCP (Protocolo de Contexto del Modelo), que combina modelos de lenguaje avanzados con acceso directo a bases de datos relacionales (PostgreSQL) y vectoriales (FAISS). Además de la capacidad de generar reportes en PDF y generación de tablas para una visualización más amigable. La interacción principal se realiza a través de la plataforma de mensajería Telegram.\nEl proyecto se divide en las siguientes fases clave:\n\nComprensión del Negocio: Definición de los objetivos estratégicos y el contexto operativo de Salsas Castillo, enfocados en mejorar la eficiencia en el acceso a la información, el correcto manejo y manipulación de los datos para una generación eficiente de respuestas, y la comunicación interna.\nPreparación: Diseño e implementación de la arquitectura del chatbot, incluyendo la integración de bases de datos relacionales y vectoriales, el desarrollo de herramientas personalizadas, y su flujo de trabajo.\nModelado y Evaluación: La configuración de modelos de lenguaje y la validación de su desempeño a través de consultas controladas.\nDespliegue: Integración del chatbot en el entorno de producción de Telegram y la infraestructura de Salsas Castillo, asegurando su operatividad y accesibilidad.\n\nA través de estas fases, buscamos proporcionar una solución innovadora que transforme la manera en que Salsas Castillo accede y utiliza su información de negocio, impulsando la eficiencia y la agilidad en sus operaciones diarias."
  },
  {
    "objectID": "0_home.html#introducción",
    "href": "0_home.html#introducción",
    "title": "GlorIA: Análisis empresarial desde un enfoque con IA",
    "section": "",
    "text": "Este proyecto se enfoca en el desarrollo de un chatbot inteligente para Salsas Castillo, diseñado para optimizar el acceso a información crítica de ventas, finanzas, facturas y más. A través de este asistente conversacional, se busca empoderar al personal de toma de decisiones, proporcionando respuestas rápidas y precisas a sus consultas, y facilitando la toma de decisiones basadas en datos actualizados que cambian en tiempo real.\nEl chatbot se basa en un modelo agéntico MCP (Protocolo de Contexto del Modelo), que combina modelos de lenguaje avanzados con acceso directo a bases de datos relacionales (PostgreSQL) y vectoriales (FAISS). Además de la capacidad de generar reportes en PDF y generación de tablas para una visualización más amigable. La interacción principal se realiza a través de la plataforma de mensajería Telegram.\nEl proyecto se divide en las siguientes fases clave:\n\nComprensión del Negocio: Definición de los objetivos estratégicos y el contexto operativo de Salsas Castillo, enfocados en mejorar la eficiencia en el acceso a la información, el correcto manejo y manipulación de los datos para una generación eficiente de respuestas, y la comunicación interna.\nPreparación: Diseño e implementación de la arquitectura del chatbot, incluyendo la integración de bases de datos relacionales y vectoriales, el desarrollo de herramientas personalizadas, y su flujo de trabajo.\nModelado y Evaluación: La configuración de modelos de lenguaje y la validación de su desempeño a través de consultas controladas.\nDespliegue: Integración del chatbot en el entorno de producción de Telegram y la infraestructura de Salsas Castillo, asegurando su operatividad y accesibilidad.\n\nA través de estas fases, buscamos proporcionar una solución innovadora que transforme la manera en que Salsas Castillo accede y utiliza su información de negocio, impulsando la eficiencia y la agilidad en sus operaciones diarias."
  },
  {
    "objectID": "2_preparacion.html",
    "href": "2_preparacion.html",
    "title": "Preparación",
    "section": "",
    "text": "A diferencia de un proceso ETL tradicional con extracción y transformación masiva de datos a un destino intermedio, el proyecto con Salsas Castillo se enfoca en la conexión de datos en tiempo real a través de herramientas SQL, y la preparación de un vector store para documentos internos.\n\n\nLas fuentes de información principales para el chatbot son:\n\nBase de Datos PostgreSQL: Contiene la información transaccional de ventas, facturas, datos financieros consolidados, entra otras tablas. Estos datos se acceden directamente mediante consultas SQL generadas por el LLM.\nDocumentos Internos (Vector Store): Archivos como manuales, reglamentos o cualquier otra información textual estática que se haya procesado para búsquedas semánticas.\n\n\n\n\n\n\nLos datos de ventas y finanzas se acceden directamente desde PostgreSQL en tiempo real. La preparación aquí, se centra en cómo el sistema interactúa con la base de datos:\n\nConexión: Se utiliza psycopg2 para establecer la conexión con la base de datos empresarial. Las credenciales se gestionan de forma segura mediante variables de entorno.\nGeneración de Consultas: El LLM es capaz de generar consultas SQL dinámicamente, basándose en la pregunta del usuario y el esquema de la base de datos. Se han definido reglas específicas en el prompt del sistema (settings/prompts.py) para asegurar la sintaxis correcta.\nManejo de Columnas: El LLM está instruido para inferir el significado de las columnas y, si es necesario, consultar el esquema de la base de datos (sql_db_schema tool) antes de generar una consulta. Esto minimiza errores por nombres de columnas desconocidos.\nMapeo de Productos: Se incluye una lista de nombres de productos (dicts.py) para ayudar al LLM a hacer matches precisos con las presentaciones de productos en la base de datos, mejorando la relevancia de las respuestas.\n\n\n\n\nPara la información estática contenida en documentos internos (que no están en las bases de datos SQL), se construye un vector store para permitir búsquedas semánticas:\n\nDocumentos: Los documentos textuales se cargan y se convierten en objetos langchain.schema.Document.\nEmbeddings: Se utilizan OpenAIEmbeddings para transformar el contenido textual de cada documento en representaciones vectoriales numéricas.\nÍndice FAISS: Se crea un índice FAISS (LangchainVectorStore en langchain/vectorstore.py) a partir de estos embeddings. Este índice se guarda localmente para su uso eficiente.\nActualización: Aunque no se describe un ETL formal, la actualización de este vector store implicaría volver a procesar los documentos modificados o nuevos para regenerar el índice."
  },
  {
    "objectID": "2_preparacion.html#preparación-de-los-datos",
    "href": "2_preparacion.html#preparación-de-los-datos",
    "title": "Preparación",
    "section": "",
    "text": "A diferencia de un proceso ETL tradicional con extracción y transformación masiva de datos a un destino intermedio, el proyecto con Salsas Castillo se enfoca en la conexión de datos en tiempo real a través de herramientas SQL, y la preparación de un vector store para documentos internos.\n\n\nLas fuentes de información principales para el chatbot son:\n\nBase de Datos PostgreSQL: Contiene la información transaccional de ventas, facturas, datos financieros consolidados, entra otras tablas. Estos datos se acceden directamente mediante consultas SQL generadas por el LLM.\nDocumentos Internos (Vector Store): Archivos como manuales, reglamentos o cualquier otra información textual estática que se haya procesado para búsquedas semánticas.\n\n\n\n\n\n\nLos datos de ventas y finanzas se acceden directamente desde PostgreSQL en tiempo real. La preparación aquí, se centra en cómo el sistema interactúa con la base de datos:\n\nConexión: Se utiliza psycopg2 para establecer la conexión con la base de datos empresarial. Las credenciales se gestionan de forma segura mediante variables de entorno.\nGeneración de Consultas: El LLM es capaz de generar consultas SQL dinámicamente, basándose en la pregunta del usuario y el esquema de la base de datos. Se han definido reglas específicas en el prompt del sistema (settings/prompts.py) para asegurar la sintaxis correcta.\nManejo de Columnas: El LLM está instruido para inferir el significado de las columnas y, si es necesario, consultar el esquema de la base de datos (sql_db_schema tool) antes de generar una consulta. Esto minimiza errores por nombres de columnas desconocidos.\nMapeo de Productos: Se incluye una lista de nombres de productos (dicts.py) para ayudar al LLM a hacer matches precisos con las presentaciones de productos en la base de datos, mejorando la relevancia de las respuestas.\n\n\n\n\nPara la información estática contenida en documentos internos (que no están en las bases de datos SQL), se construye un vector store para permitir búsquedas semánticas:\n\nDocumentos: Los documentos textuales se cargan y se convierten en objetos langchain.schema.Document.\nEmbeddings: Se utilizan OpenAIEmbeddings para transformar el contenido textual de cada documento en representaciones vectoriales numéricas.\nÍndice FAISS: Se crea un índice FAISS (LangchainVectorStore en langchain/vectorstore.py) a partir de estos embeddings. Este índice se guarda localmente para su uso eficiente.\nActualización: Aunque no se describe un ETL formal, la actualización de este vector store implicaría volver a procesar los documentos modificados o nuevos para regenerar el índice."
  },
  {
    "objectID": "4_despliegue.html",
    "href": "4_despliegue.html",
    "title": "Despliegue",
    "section": "",
    "text": "El desarrollo del chatbot para Salsas Castillo ha seguido un enfoque iterativo, centrado en la integración de modelos de lenguaje con las bases de datos existentes y la plataforma de Telegram. Los principales retos se concentraron en asegurar la interacción fluida y precisa del LLM con las bases de datos SQL para consultas dinámicas, así como la correcta gestión del historial de conversación y la generación de reportes en PDF.\nEl objetivo principal de optimizar el acceso a la información de productos y finanzas se ha mantenido constante a lo largo del proyecto, adaptándose a las particularidades de Salsas Castillo.\n\n\nConsiderando los avances en el desarrollo y las pruebas internas, se ha decidido priorizar el despliegue en un entorno de pruebas real para validar el comportamiento del chatbot en condiciones operativas y recopilar feedback directo de los usuarios.\n\n\n\nLa decisión es proceder con la implementación del chatbot en un entorno de pruebas de Telegram. Esto permitirá:\n\nValidar la integración completa con la API de Telegram.\nProbar la conectividad y el rendimiento con las bases de datos PostgreSQL y MongoDB en un entorno real.\nRecopilar feedback de usuarios internos para identificar mejoras en la experiencia de usuario y la precisión de las respuestas.\nAsegurar la robustez y estabilidad del sistema antes de una posible implementación a mayor escala."
  },
  {
    "objectID": "4_despliegue.html#revisión-del-proceso",
    "href": "4_despliegue.html#revisión-del-proceso",
    "title": "Despliegue",
    "section": "",
    "text": "El desarrollo del chatbot para Salsas Castillo ha seguido un enfoque iterativo, centrado en la integración de modelos de lenguaje con las bases de datos existentes y la plataforma de Telegram. Los principales retos se concentraron en asegurar la interacción fluida y precisa del LLM con las bases de datos SQL para consultas dinámicas, así como la correcta gestión del historial de conversación y la generación de reportes en PDF.\nEl objetivo principal de optimizar el acceso a la información de productos y finanzas se ha mantenido constante a lo largo del proyecto, adaptándose a las particularidades de Salsas Castillo.\n\n\nConsiderando los avances en el desarrollo y las pruebas internas, se ha decidido priorizar el despliegue en un entorno de pruebas real para validar el comportamiento del chatbot en condiciones operativas y recopilar feedback directo de los usuarios.\n\n\n\nLa decisión es proceder con la implementación del chatbot en un entorno de pruebas de Telegram. Esto permitirá:\n\nValidar la integración completa con la API de Telegram.\nProbar la conectividad y el rendimiento con las bases de datos PostgreSQL y MongoDB en un entorno real.\nRecopilar feedback de usuarios internos para identificar mejoras en la experiencia de usuario y la precisión de las respuestas.\nAsegurar la robustez y estabilidad del sistema antes de una posible implementación a mayor escala."
  },
  {
    "objectID": "4_despliegue.html#plan-de-implementación",
    "href": "4_despliegue.html#plan-de-implementación",
    "title": "Despliegue",
    "section": "2. Plan de Implementación",
    "text": "2. Plan de Implementación\nLa fase de implementación implica el despliegue del backend del chatbot y su integración con la plataforma de Telegram.\n\n2.1. Arquitectura de Despliegue y Conexión\nEl chatbot de Salsas Castillo se despliega como un servicio de backend basado en FastAPI, que interactúa con la API de Telegram mediante webhooks. La persistencia de datos se maneja con MongoDB y las consultas a datos transaccionales se realizan en PostgreSQL.\n\nBackend del Chatbot (FastAPI): La aplicación principal se despliega en un servidor (o ambiente virtual Linux) utilizando Gunicorn para producción o Uvicorn para desarrollo.\nConexión con Telegram: La comunicación se establece a través de webhooks. Telegram envía las actualizaciones de mensajes al endpoint /webhook de la API de FastAPI. El chatbot, a su vez, utiliza la API de Telegram para enviar respuestas y documentos (PDFs).\nBases de Datos:\n\nPostgreSQL: Se establece una conexión directa desde el backend del chatbot para las consultas SQL.\nMongoDB: Se utiliza para almacenar el historial de sesiones (sessions) y un respaldo completo de mensajes (message_backup).\n\n\n\n\n2.2. Gestión de Persistencia de Datos con MongoDB\nLa gestión del historial de conversaciones es crucial para un chatbot. En Salsas Castillo, se utiliza MongoDB con dos colecciones principales:\n\nsessions: Almacena los últimos mensajes de cada sesión de usuario para mantener el contexto de la conversación. Se configura para mantener un tamaño fijo (ej., los últimos 24 mensajes) para optimizar el rendimiento.\nmessage_backup: Actúa como un histórico completo de todas las interacciones (preguntas del usuario, respuestas del chatbot, metadatos). Es fundamental para el análisis de datos, auditorías y futuras mejoras del modelo.\n\n\n\n2.3. Plan de Monitoreo\nDurante la fase de pruebas, se implementará un plan de monitoreo para evaluar el rendimiento y comportamiento del sistema:\n\nTiempo de Respuesta: Latencia de las respuestas del chatbot, incluyendo el tiempo de ejecución de las consultas SQL y las llamadas a la API de OpenAI.\nTasa de Éxito/Error: Monitoreo de las peticiones a la API del chatbot y a las bases de datos.\nCalidad de las Respuestas: Evaluación manual de la precisión, coherencia y relevancia de las respuestas, especialmente en escenarios complejos o con datos numéricos.\nUso del Chatbot: Frecuencia de interacciones por usuario, tipos de consultas más comunes.\nErrores en Logs: Revisión de los logs del servidor para identificar excepciones o problemas en el backend.\n\n\n\n2.4. Plan de Mantenimiento\nSe establecerá un plan de mantenimiento periódico para asegurar la estabilidad y el buen funcionamiento del sistema:\n\nActualización de Dependencias: Revisión y actualización regular de las librerías de Python (FastAPI, LangChain, PyMongo, etc.).\nRevisión de Logs: Monitoreo activo de los logs del servidor y de las bases de datos para identificar y solucionar problemas.\nAuditoría de Datos y Respuestas: Evaluación periódica de la calidad de los datos en PostgreSQL y MongoDB, y verificación de la precisión de las respuestas del chatbot a lo largo del tiempo.\nOptimización de Consultas: Refinamiento continuo de las consultas SQL generadas por el LLM para mejorar el rendimiento.\nActualización del Vector Store: Si se añaden nuevos documentos internos, se programará la actualización del vector store FAISS.\n\n\n\n2.5. Experiencia de Desarrollo\nEl proyecto ha permitido consolidar la experiencia en el desarrollo de un chatbot completo, desde la integración con plataformas de mensajería (Telegram) hasta la orquestación de LLMs con bases de datos relacionales y vectoriales. Los aprendizajes clave incluyen:\n\nManejo de la interacción entre LLMs y bases de datos SQL para consultas dinámicas.\nImplementación de la persistencia de sesiones y el historial de mensajes en MongoDB.\nDesarrollo de herramientas personalizadas (ej., generación de PDFs) y su integración en el flujo del agente.\nGestión de la transcripción de audio para una experiencia de usuario más inclusiva.\nAdherencia a buenas prácticas de desarrollo modular y escalable.\n\n\n\n2.6. Despliegue del Chatbot en el Sistema de Pruebas\nEl chatbot será desplegado en un entorno de pruebas de Telegram, accesible para un grupo controlado de usuarios internos de Salsas Castillo. Este despliegue permitirá validar el sistema en condiciones casi reales.\nEl proceso de despliegue consistirá en:\n\nMontaje del Entorno de la API: Despliegue de la API de FastAPI en un servidor dedicado, asegurando la conectividad con PostgreSQL y MongoDB.\nConfiguración del Webhook de Telegram: Establecer el webhook para que Telegram envíe las actualizaciones de mensajes al endpoint de la API.\nVerificación Funcional: Realizar pruebas exhaustivas para verificar el flujo de conversación, la precisión de las respuestas, la generación de PDFs y el manejo de la transcripción de audio.\nConsideraciones de Seguridad: Asegurar la autenticación de usuarios (mediante whitelist de Telegram IDs), el manejo seguro de credenciales y la protección de datos.\n\nEste hito marca un avance significativo hacia la validación en entorno real del sistema conversacional, permitiendo recopilar feedback de usuarios internos antes de considerar un despliegue completo en producción."
  }
]