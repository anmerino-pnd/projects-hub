[
  {
    "objectID": "5_documentacion.html",
    "href": "5_documentacion.html",
    "title": "Documentación",
    "section": "",
    "text": "Este proyecto se centra en el desarrollo de un chatbot inteligente para Salsas Castillo, diseñado para optimizar el acceso a información de ventas y finanzas, y mejorar la comunicación interna. El chatbot utiliza un sistema de recuperación aumentada con generación (RAG) y herramientas dinámicas para proporcionar respuestas precisas y relevantes, así como la capacidad de generar reportes financieros.\n\n\n\nAutomatizar consultas: Permitir a los usuarios (operativos y no operativos) obtener información sobre ventas, productos y finanzas de manera rápida y eficiente a través de una interfaz conversacional en Telegram.\nMejorar la toma de decisiones: Proporcionar análisis de datos financieros y de ventas en tiempo real, incluyendo la generación de reportes en PDF.\nOptimizar la gestión de información: Centralizar el acceso a datos transaccionales y consolidados, reduciendo la dependencia de consultas manuales.\nAdaptación a nuevas tecnologías: Implementar un sistema basado en LLMs y bases de datos vectoriales para un enfoque moderno y escalable.\n\n\n\n\n\nIncremento en la eficiencia operativa al reducir el tiempo dedicado a la búsqueda manual de información.\nMejora en la precisión de los datos y análisis disponibles para el personal.\nFacilitación de la toma de decisiones estratégicas basadas en información actualizada."
  },
  {
    "objectID": "5_documentacion.html#introducción-al-proyecto",
    "href": "5_documentacion.html#introducción-al-proyecto",
    "title": "Documentación",
    "section": "",
    "text": "Este proyecto se centra en el desarrollo de un chatbot inteligente para Salsas Castillo, diseñado para optimizar el acceso a información de ventas y finanzas, y mejorar la comunicación interna. El chatbot utiliza un sistema de recuperación aumentada con generación (RAG) y herramientas dinámicas para proporcionar respuestas precisas y relevantes, así como la capacidad de generar reportes financieros.\n\n\n\nAutomatizar consultas: Permitir a los usuarios (operativos y no operativos) obtener información sobre ventas, productos y finanzas de manera rápida y eficiente a través de una interfaz conversacional en Telegram.\nMejorar la toma de decisiones: Proporcionar análisis de datos financieros y de ventas en tiempo real, incluyendo la generación de reportes en PDF.\nOptimizar la gestión de información: Centralizar el acceso a datos transaccionales y consolidados, reduciendo la dependencia de consultas manuales.\nAdaptación a nuevas tecnologías: Implementar un sistema basado en LLMs y bases de datos vectoriales para un enfoque moderno y escalable.\n\n\n\n\n\nIncremento en la eficiencia operativa al reducir el tiempo dedicado a la búsqueda manual de información.\nMejora en la precisión de los datos y análisis disponibles para el personal.\nFacilitación de la toma de decisiones estratégicas basadas en información actualizada."
  },
  {
    "objectID": "5_documentacion.html#manual-de-instalación-y-despliegue",
    "href": "5_documentacion.html#manual-de-instalación-y-despliegue",
    "title": "Documentación",
    "section": "2. Manual de instalación y despliegue",
    "text": "2. Manual de instalación y despliegue\nEsta sección detalla los requisitos, dependencias y pasos para la instalación y despliegue del chatbot de Salsas Castillo.\n\n2.1. Configuraciones importantes\n\nEl backend del chatbot está desarrollado con FastAPI y se espera que se ejecute en un entorno con Python 3.12.\nRequiere conectividad a una instancia de MongoDB para la gestión de sesiones e historial, y a una base de datos PostgreSQL para datos financieros y de ventas.\nUtiliza modelos de lenguaje de OpenAI (requiere OPENAI_API_KEY) y potencialmente modelos open-source como gemma3:4b a través de Ollama para la moderación.\nLas credenciales sensibles se gestionan a través de un archivo .env.\nLa integración con Telegram se realiza mediante webhooks y el telegram_token correspondiente.\n\n\n\n2.2. Requisitos del sistema\n\nPython: Versión 3.x (se recomienda la versión utilizada en el desarrollo, ej., 3.12.9).\nPip/UV: Última versión para la gestión de paquetes.\nOllama: Instalado y en ejecución si se utilizan modelos open-source para moderación.\nMongoDB: Acceso remoto configurado para las colecciones de sesiones e historial de mensajes.\nPostgreSQL: Acceso remoto configurado para las bases de datos historial_facturas y financieroii.\nConexión a Internet: Necesaria para interactuar con las APIs de OpenAI y Telegram.\n\n\n\n2.3. Dependencias principales del sistema\n\nfastapi: Framework web para el backend.\nlangchain: Framework principal para la orquestación del LLM y las herramientas.\nopenai: Cliente Python para la API de OpenAI.\npymongo: Driver para la interacción con MongoDB.\npsycopg2-binary: Adaptador PostgreSQL para Python.\nfpdf: Para la generación de PDFs.\nrequests: Para realizar solicitudes HTTP (ej., a Telegram, OpenAI Whisper).\nuvicorn/gunicorn: Servidor WSGI para despliegue.\npydantic: Para la validación de modelos de datos.\nfaiss-cpu: Para la base de datos vectorial (si aplica para documentos internos).\n\n\n\n2.4. Requisitos de configuración del backend\n\n2.4.1. Clonar el repositorio\ngh repo fork Macrodata-Analitica/castilloChatbot\ncd castilloChatbot\n\n\n2.4.2. Crear entorno virtual e instalar dependencias\npip install uv # Si no está instalado\nuv venv\nsource .venv/bin/activate # Linux/macOS\n# o `.venv\\Scripts\\activate` para Windows\nuv pip install -e .\nuv sync # Sincroniza los modulos de src/\n\n\n2.4.3. Configurar variables de entorno (.env)\nAsegúrate de que el archivo .env en la raíz del proyecto contenga las siguientes variables con sus valores correctos:\nOPENAI_API_KEY=\"\"\n\nVERIFY_TOKEN=\"\"\nTELEGRAM_BOT_TOKEN=\"\"\nPHONE_NUMBER_ID=\"\"\n\nHOST=\"\"\nPORT=\"\"\nUSER=\"\"\nPASS=\"\"\nDBNAME=\"\"\nSCHEMA=\"\"\n\n\n2.4.4. Configurar Webhook de Telegram\nAsegúrate de que Telegram envíe los mensajes a tu endpoint /webhook. Esto se hace una vez a través de la API de Telegram:\nhttps://api.telegram.org/bot&lt;TU_TELEGRAM_TOKEN&gt;/setWebhook?url=https://&lt;TU_DOMINIO&gt;/webhook\nReemplaza TU_DOMINIO y TU_TELEGRAM_TOKEN.\nEn caso de no tener un Token de Telegram. es necesario buscar @FatherBot en Telegram. Después, iniciar conversación con /start. Luego, /newbot, en esta parte el sistema pedirá 2 nombres. Name es el nombre de despliegue del chatbot, se puede cambiar después. Username es el nombre único identificador del chatbot, este no se puede cambiar después.\nEn caso de ser necesario, se recomienda este tutorial en Medium donde se explica explicítamente cada paso.\n\n\n\n2.5 Arquitectura de despliegue continuo y sincronización\nEl servidor implementa un mecanismo adicional para mantener el backend del chatbot actualizado y funcionando de forma estable. Este mecanismo se basa en tres componentes:\n\nEl servicio principal del chatbot (rag.service)\nEl servicio de despliegue (rag-deploy.service)\nEl timer que activa el despliegue cada 30 segundos (rag-deploy.timer)\n\nEste sistema garantiza que:\n\nSi el repositorio cambia, el backend se actualiza automáticamente.\nSi el entorno Python necesita sincronizar dependencias, se hace sin intervención manual.\nSi el servicio falla o se detiene por cualquier motivo, systemd lo vuelve a levantar.\n\nA continuación se explica cada pieza.\n\n2.5.1 Definición del servicio backend rag.service\nEste servicio es el que ejecuta el backend de FastAPI mediante Uvicorn.\n[Unit]\nDescription=Telegram Chat API (Uvicorn)\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nType=simple\nUser=ctrlsalsasc\nWorkingDirectory=/home/ctrlsalsasc/rag_v3\nEnvironment=PYTHONUNBUFFERED=1\nExecStart=/bin/bash -lc 'uv sync && exec uv run uvicorn salsasllm.API.telegram_main:app --host 0.0.0.0 --port 8003'\nRestart=always\nRestartSec=5\nStartLimitIntervalSec=60\nStartLimitBurst=5\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n\n\n2.5.2 Especificaciones operativas\n\nUsa uv sync antes de arrancar para garantizar dependencias correctas.\nCorre en el puerto interno 8003, que Apache expone al público mediante reverse proxy.\nSe auto-reinicia si falla, asegurando alta disponibilidad.\nLos logs se consultan con journalctl -u rag.service -f.\n\n\n\n2.5.3 Servicio de actualización rag-deploy.service\nEste servicio no se ejecuta de manera continua, sino que systemd lo invoca bajo demanda (a través del timer).\n[Unit]\nDescription=Pull + uv sync + restart rag.service si hay cambios\n\n[Service]\nType=oneshot\nUser=ctrlsalsasc\nEnvironment=HEALTHCHECK_URL=http://127.0.0.1:8003/healthz\nExecStart=/usr/local/bin/rag_deploy.sh\n\n\n2.5.4. Lógica de ejecución del script\nEl script (rag_deploy.sh) realiza tareas como:\n\ngit fetch → revisar si hay nuevos commits.\nSi hay cambios → git pull y uv sync.\nReiniciar rag.service solo si fue necesario actualizar.\nEjecutar un healthcheck contra /healthz para validar que el servicio levantó correctamente.\n\nEste patrón es más robusto que un simple cron, porque systemd:\n\nControla fallos.\nRegistra logs.\nEvita ejecuciones simultáneas.\nPuede reintentar si algo sale mal.\n\n\n\n\n2.5.5 Programación del timer de sistema rag-deploy.timer\nEl timer configura cada cuánto debe ejecutarse el servicio anterior:\n[Unit]\nDescription=Timer para rag-deploy.service (cada minuto)\n\n[Timer]\nOnUnitActiveSec=30s\nAccuracySec=5s\nPersistent=true\n\n[Install]\nWantedBy=timers.target\nDefiniciones\n\n\n\n\n\n\n\nConfiguración\nFunción\n\n\n\n\nOnUnitActiveSec=30s\nEjecuta el despliegue 30 segundos después de la última ejecución → es decir, cada 30s continuamente.\n\n\nPersistent=true\nSi el servidor estuvo apagado, ejecuta de inmediato lo que quedó pendiente.\n\n\nAccuracySec=5s\nsystemd puede adelantar o atrasar unos segundos para optimizar carga del sistema.\n\n\n\nComandos útiles Ver estado del timer:\nsystemctl status rag-deploy.timer\nVer cuándo se ejecutó la última vez:\nsystemctl list-timers | grep rag\nVer logs del despliegue:\njournalctl -u rag-deploy.service -f\nForzar un despliegue manual:\nsudo systemctl start rag-deploy.service\n\n\n\n2.6 Infraestructura de red: Reverse proxy con Apache\nEl servidor utiliza Apache2 como reverse proxy para exponer los servicios del chatbot hacia Internet de forma segura a través de HTTPS. Esta configuración permite que los procesos internos de FastAPI, que corren localmente en puertos como 8003 o 8006, sean accesibles mediante rutas amigables bajo el dominio oficial de la empresa.\nEl archivo principal de configuración utilizado por el dominio seguro es: /etc/apache2/sites-enabled/default-ssl.conf\nReverse Proxy para el servicio Telegram Bot (Producción)\n# Telegram ChatBot\nProxyPreserveHost On\nProxyPass /tgbot http://127.0.0.1:8003/\nProxyPassReverse /tgbot http://127.0.0.1:8003/\n\nRewriteEngine On\nRewriteRule ^/tgbot(/.*)?$ http://127.0.0.1:8003$1 [P,L]\n\n&lt;Location tgbot&gt;\n    Require all granted\n    AllowOverride None\n&lt;/Location&gt;\nExplicación del funcionamiento\n\n\n\n\n\n\n\nDirectiva\nFunción\n\n\n\n\nProxyPreserveHost On\nMantiene el header Host original enviado por el cliente. Esto permite que FastAPI identifique correctamente el dominio público.\n\n\nProxyPass /tgbot …\nTodo lo que llegue a https://apps.salsascastillo.com/tgbot será enviado internamente al proceso de FastAPI que corre en http://127.0.0.1:8003/.\n\n\nProxyPassReverse\nAjusta los encabezados de respuesta para que FastAPI no devuelva rutas internas.\n\n\nRewriteEngine + RewriteRule\nSe asegura de que todas las subrutas, como /tgbot/webhook, /tgbot/logs, etc., se redirijan correctamente al backend.\n\n\nLocation\nPermite acceso público a la ruta (sin autenticación adicional).\n\n\n\nEsta sección expone el servicio de Telegram en producción y es el endpoint donde se configura el webhook de Telegram:\nhttps://apps.salsascastillo.com/tgbot/webhook\nConfiguración SSL En la parte final del archivo se incluyen los certificados emitidos por Let’s Encrypt a través de Certbot:\nSSLCertificateFile /etc/letsencrypt/live/apps.salsascastillo.com/fullchain.pem \nSSLCertificateKeyFile /etc/letsencrypt/live/apps.salsascastillo.com/privkey.pem \nInclude /etc/letsencrypt/options-ssl-apache.conf\nDetalles importantes\n\nfullchain.pem contiene la cadena completa del certificado, incluida la autoridad intermedia.\nprivkey.pem es la llave privada del dominio (solo debe tener permisos 600 y dueño root).\noptions-ssl-apache.conf aplica configuraciones modernas recomendadas por Let’s Encrypt (TLS, Cipher Suites, HSTS, etc.).\nLa renovación ocurre automáticamente con el timer de Certbot (/lib/systemd/system/certbot.timer).\n\nResumen del flujo\n\nEl usuario envía una petición a: https://apps.salsascastillo.com/tgbot/...\nApache la recibe sobre HTTPS.\nApache la redirige internamente al backend FastAPI: http://127.0.0.1:8003/...\nFastAPI procesa el mensaje y responde.\nApache reescribe los encabezados y envía la respuesta al cliente.\n\nEste patrón es robusto, seguro y permite correr múltiples servicios simultáneamente sin exponer puertos internos a Internet."
  },
  {
    "objectID": "5_documentacion.html#documentación-técnica-del-código",
    "href": "5_documentacion.html#documentación-técnica-del-código",
    "title": "Documentación",
    "section": "3. Documentación técnica del código",
    "text": "3. Documentación técnica del código\nEsta sección describe la estructura modular del proyecto y las funciones clave de sus componentes.\n\n3.1. Estructura de carpetas y módulos\nAquí se encuentran las clases, módulos y funciones claves que permiten la interacción general de todo el sistema construido.\n\n3.1.1. Agente\nEn este módulo se encuentran las funciones claves que permiten al LLM conocer del contexto y generar y enviar respuestas, tablas y reportes.\n\nclass AgentMultiTools:\n\n__init__:\n\nPropósito: Inicializar la clase, configurar el modelo de lenguaje (GPT-5), establecer la conexión con MongoDB para sesiones y backups, y definir la lista de herramientas (tools) disponibles para el agente.\nComportamiento: Instancia el cliente de OpenAI con un limitador de tasa (InMemoryRateLimiter), conecta a las colecciones de base de datos y prepara el ChatPromptTemplate con las instrucciones del sistema.\n\nensure_session() -&gt; dict:\n\nPropósito: Verificar si existe una sesión para el usuario actual y crearla si no existe.\nParámetros:\n\nsession_id: Identificador único del chat.\nname: Nombre del usuario.\n\nComportamiento: Consulta MongoDB; si la sesión no existe, inserta un nuevo documento con created_at y el nombre. Si existe, actualiza last_activity y retorna los datos de la sesión.\n\nget_session_history() -&gt; list:\n\nPropósito: Recuperar el historial reciente de mensajes de una sesión específica para mantener el contexto de la conversación.\nParámetros:\n\nsession_id: Identificador del chat.\n\nComportamiento: Consulta la colección de sesiones en MongoDB, extrae los últimos 10 mensajes y los convierte en objetos HumanMessage o AIMessage de LangChain.\n\nadd_message():\n\nPropósito: Almacenar un nuevo mensaje en el historial de la sesión activa.\nParámetros:\n\nsession_id: Identificador del chat.\nmessage_type (\"human\" o \"assistant\"): Human para las consultas del usuario, assistant para las respuestas del chatbot.\ncontent: El contenido textual, correspondiendo si es consulta del usuario o respuesta del chatbot.\n\nComportamiento: Realiza un update_one en MongoDB usando $push para añadir el mensaje al array last_messages, manteniendo solo los últimos 20 mensajes mediante $slice.\n\nadd_message_backup():\n\nPropósito: Guardar un registro detallado y permanente de la interacción para auditoría y feedback.\nParámetros:\n\nsession_id: Identificador del chat.\nquestion: Consulta del usuario.\nfull_answer: Respuesta del sistema.\nverbose_log: Logs de ejecución interna.\n\nComportamiento: Crea un documento con la pregunta, respuesta, timestamp, modelo utilizado y logs, y lo inserta en la colección message_backup. Retorna el ID del documento insertado.\n\nbuild_executor():\n\nPropósito: Construir el ejecutor del agente de LangChain si aún no ha sido inicializado.\nComportamiento: Crea un create_tool_calling_agent combinando el LLM, las herramientas definidas y el prompt, y luego instancia el AgentExecutor con manejo de errores y verbosidad activada.\n\nanswer():\n\nPropósito: Procesar la consulta del usuario, ejecutar la lógica del agente y generar una respuesta final.\nParámetros:\n\nquestion: Input del usuario.\nsession_id: Identificador del chat.\nname: Nombre del usuario.\nfeedback_context: Información de retroalimentación previa.\n\nComportamiento: Gestiona el flujo completo: asegura la sesión, recupera historial, invoca al executor de forma asíncrona, mide tiempos de ejecución, limpia la respuesta, guarda el backup en la BD y retorna la respuesta procesada junto con el backup_id.\n\nclear_session_history();\n\nPropósito: Borrar el historial de conversación de un usuario específico.\nParámetros:\n\nsession_id: Identificador del chat.\n\nComportamiento: Actualiza el documento de sesión en MongoDB vaciando el array last_messages.\n\n\n\n\n\n3.1.2. Tools\nEn este módulo tenemos las herramientas que utiliza el chatbot para extraer información, construir respuestas, tablas, reportes y buscar en internet.\n\ntools/search_information.py\n\nsearch_information():\n\nPropósito: Buscar información semántica relevante en documentos internos indexados (manuales, reglamentos, etc.).\nParámetros:\n\nquery: Consulta del usuario.\n\nComportamiento: Utiliza un retriever conectado a un LangchainVectorStore para encontrar documentos similares y luego procesa el contenido recuperado para devolver un resumen estructurado.\n\nparse_page_content():\n\nPropósito: Estructurar el texto crudo de los documentos recuperados en un formato clave-valor.\nParámetros:\n\ncontent: Texto del documento.\n\nComportamiento: Divide el contenido por puntos y espacios, e intenta extraer pares clave-valor separados por dos puntos para retornar un diccionario de datos.\n\n\n\n\ntools/pdf_tool.py\n\ngenerate_financial_report_pdf() -&gt; dict:\n\nPropósito: Orquestar la creación de un reporte financiero en PDF y enviarlo por Telegram.\nParámetros:\n\ndata: Datos extraídos crudos en formato Markdown.\nchat_id: Identificador de la conversación, similar a session_id.\nuser_request: Consulta del usuario.\n\nComportamiento: Llama a get_llm_analysis para estructurar el contenido, luego a generate_pdf_with_reportlab para crear el archivo físico, y finalmente usa send_telegram_pdf para enviarlo al usuario.\n\nensure_utf8_string() -&gt; str:\n\nPropósito: Normalizar cualquier cadena de texto para asegurar codificación UTF-8 correcta.\nParámetros:\n\ntext: Texto contenido de la data cruda.\n\nComportamiento: Decodifica bytes si es necesario y normaliza caracteres Unicode (NFC) para evitar errores de codificación en el reporte.\n\nget_llm_analysis() -&gt; tuple[str, str]:\n\nPropósito: Utilizar un LLM para analizar datos financieros y generar el contenido del reporte en formato Markdown.\nParámetros:\n\ndata: Data sanitizada para el análisis.\nuser_request: Petición del usuario.\n\nComportamiento: Envía un prompt especializado a GPT-5 solicitando un JSON con título y contenido Markdown, incluyendo reglas de formato y gráficas.\n\ngenerate_pdf_with_reportlab() -&gt; bytes:\n\nPropósito: Convertir el contenido Markdown y el título en un archivo PDF binario.\nParámetros:\n\ntitle: Título del reporte.\nmarkdown_content: Contenido de la respuesta del análisis formateado a markdown.\n\nComportamiento: Utiliza la librería ReportLab para maquetar el documento, procesando párrafos, listas, tablas y ejecutando código Python incrustado para generar gráficas con matplotlib.\n\n\n\n\ntools/netsearch.py\n\nsearch_web_tool():\n\nPropósito: Buscar información actual o conceptos generales en internet.\nParámetros:\n\nquery: Consulta del usuario o información requerida que necesita ser buscada en internet.\n\nComportamiento: Utiliza DDGS (DuckDuckGo Search) para realizar búsquedas de texto y noticias en la región “mx-es”, limpia los resultados y devuelve una lista de diccionarios con título, enlace y descripción.\n\n\n\n\ntools/context_tool.py\n\ncontext_tool() -&gt; Dict[str, Any]:\n\nPropósito: Proveer acceso a diccionarios estáticos de contexto (fórmulas, nombres de bases de datos, etc.).\nParámetros:\n\ndict_name: Nombre del diccionario solicitad.\n\nComportamiento: Verifica si el nombre solicitado existe en CONTEXT_DICTS y devuelve el diccionario correspondiente; lanza un error si no se encuentra.\n\n\n\n\ntools/make_tables.py\n\ntable_tool() -&gt; str:\n\nPropósito: Convertir una tabla en formato Markdown a una imagen y enviarla por Telegram.\nParámetros:\n\nmarkdown: Datos formateados en markdown.\nchat_id: Identificador del chat.\ntitle: Título de la tabla.\n\nComportamiento: Parsea el markdown a un DataFrame, genera una imagen PNG estilizada y la envía directamente al chat mediante send_telegram_image.\n\nparse_markdown_table() -&gt; DataFrame:\n\nPropósito: Transformar una cadena de texto con formato de tabla Markdown en un objeto DataFrame de Pandas.\nParámetros:\n\nmarkdown: Datos formateados en markdown.\n\nComportamiento: Divide el texto por líneas y tuberías (|), extrae encabezados y filas, y valida que la estructura sea correcta.\n\ncreate_table_image() -&gt; BytesIO:\n\nPropósito: Renderizar visualmente un DataFrame como una imagen PNG.\nParámetros:\n\ndf (DataFrame): Datos en pandas.\ntitle: Título de la tabla.\n\nComportamiento: Usa la librería PIL (Pillow) para dibujar celda por celda, calculando anchos dinámicos de columnas, alturas de filas y aplicando estilos de color y fuentes.\n\n\n\n\ntools/sql_tools.py\n\nsql_db_list_tables() -&gt; List[str]:\n\nPropósito: Listar las tablas disponibles en la base de datos para consulta.\nComportamiento: Retorna una lista literal predefinida o cacheada de las tablas permitidas en el esquema.\n\nsql_db_schema() -&gt; Dict[str, Any]:\n\nPropósito: Obtener la estructura (columnas y tipos de datos) de una tabla específica.\nParámetros:\n\ntable_name: Nombre de la tabla objetivo.\n\nComportamiento: Ejecuta una consulta a information_schema.columns en PostgreSQL y devuelve un diccionario con la definición de la tabla.\n\nsql_db_query_checker() -&gt; Dict[str, Any]:\n\nPropósito: Validar la sintaxis de una consulta SQL antes de su ejecución real.\nParámetros:\n\nquery: SQL query a validar.\n\nComportamiento: Ejecuta la sentencia EXPLAIN en la base de datos para verificar si la query es válida sin ejecutarla, capturando posibles errores de sintaxis.\n\nanalyze_table() -&gt; str:\n\nPropósito: Realizar un análisis profundo de datos utilizando un agente de Pandas sobre resultados SQL.\nParámetros:\n\nuser_query: Consulta o petición del usuario.\nsql_query: SQL query para extraer datos de la tabla objetivo.\nextra_info: Contexto adicional como formulas o nombres de productos.\n\nComportamiento: Ejecuta la query SQL para obtener un DataFrame, verifica su tamaño, y luego instancia un create_pandas_dataframe_agent para realizar cálculos estadísticos o análisis complejos solicitados por el usuario.\n\n\n\n\n\n3.1.3. API\n\nAPI/telegram_def.py\n\nsend_telegram_message():\n\nPropósito: Enviar mensajes de texto simples o con botones a un chat de Telegram.\nParámetros:\n\nchat_id: Identificador del chat.\nmessage: Mensaje para el usuario objetivo.\nreply_markup: Opcional para botones o teclados interactivos in-chat.\n\nComportamiento: Realiza una petición POST al endpoint sendMessage de la API de Telegram con el payload JSON correspondiente.\n\ndownload_file():\n\nPropósito: Descargar un archivo (como audios) desde los servidores de Telegram.\nParámetros:\n\nfile_path: Ubicación del archivo objetivo.\n\nComportamiento: Construye la URL de descarga con el token del bot y realiza un GET para obtener el contenido binario del archivo.\n\nsend_telegram_pdf():\n\nPropósito: Enviar un documento PDF generado al usuario.\nParámetros:\n\nchat_id: Identificador del chat.\npdf_bytes: PDF en bytes.\nfilename: Nombre del archivo PDF.\ncaption: Descripción extra del archivo a enviar.\n\nComportamiento: Envía una petición multipart/form-data al endpoint sendDocument de Telegram adjuntando los bytes del PDF.\n\nsend_telegram_image():\n\nPropósito: Enviar una imagen (como las tablas generadas) al usuario.\nParámetros:\n\nchat_id: Identificador del chat.\nimage_bytes: Imagen en bytes.\ncaption: Descripción extra del archivo a enviar.\n\nComportamiento: Envía una petición al endpoint sendPhoto adjuntando la imagen en memoria.\n\n\n\n\nAPI/telegram_chat.py\n\ndelete_chat_history_endpoint():\n\nPropósito: Endpoint lógico para limpiar el historial de un usuario.\nParámetros:\n\nuser_id: Identificador del chat.\n\nComportamiento: Llama al método clear_session_history del agente y maneja excepciones HTTP.\n\nload_whitelist():\n\nPropósito: Cargar la lista de usuarios autorizados desde un archivo.\nParámetros:\n\nfilepath: Ubicación del archivo.\n\nComportamiento: Lee un archivo de texto línea por línea y retorna un conjunto de IDs de Telegram permitidos.\n\nget_file_path():\n\nPropósito: Obtener la ruta de descarga de un archivo dado su ID de Telegram.\nParámetros:\n\nfile_id: Identificador del audio.\n\nComportamiento: Consulta el método getFile de la API de Telegram para resolver la ruta del archivo en el servidor.\n\ntranscribe_audio():\n\nPropósito: Convertir notas de voz en texto utilizando IA.\nParámetros:\n\naudio_bytes: Audio en bytes.\nfilename: Nombre del audio.\n\nComportamiento: Envía el archivo de audio a la API de OpenAI (Whisper) y retorna el texto transcrito.\n\nadd_feedback():\n\nPropósito: Almacenar feedback cualitativo en la base de conocimientos vectorial.\nParámetros:\n\ncomment: Comentario del usuario.\nmetadata: Incluye el identificador del mensaje en message_backup_collection, la pregunta, la respuesta, y si fue o no útil.\n\nComportamiento: Añade el comentario y sus metadatos al feedback_vectorstore y guarda el índice.\n\nretrieve_feedback():\n\nPropósito: Buscar retroalimentación previa relevante para la consulta actual.\nParámetros:\n\nuser_question: Consulta del usuario.\nk: Número de resultados.\n\nComportamiento: Realiza una búsqueda de similitud en el vectorstore y formatea los resultados como una cadena de texto.\n\nupdate_feedback():\n\nPropósito: Actualizar el registro de una interacción con la evaluación del usuario.\nParámetros:\n\nbackup_id: Identificador del mensaje completo en el message_backup_collection.\nhelpful: Booleano, true si fue útil, false si no.\nreason: Comentario extra de porqué sí o porqué no.\n\nComportamiento: Actualiza el documento en MongoDB marcando si fue útil y, si existe una razón, la indexa en el vectorstore para futuro aprendizaje.\n\nhandle_message():\n\nPropósito: Coordinar la respuesta a un mensaje del usuario.\nParámetros:\n\nchat_id: Identificador del chat.\ntext: Consulta del usuario.\nname: Nombre del usuario.\n\nComportamiento: Recupera contexto de feedback, llama al agente para obtener respuesta, calcula tiempos, guarda el estado temporal y envía la respuesta final a Telegram con botones de feedback.\n\ntelegram_webhook():\n\nPropósito: Punto de entrada principal para recibir actualizaciones de Telegram (Webhook).\nParámetros:\n\nrequest: Petición del usuario.\nbackground_tasks: Tareas que se deben ejecutar en segundo plano.\n\nComportamiento: Procesa el payload JSON, maneja callbacks de botones (feedback sí/no), verifica autorización (whitelist), gestiona mensajes de texto y voz, y delega el procesamiento pesado a tareas en segundo plano (handle_message).\n\n\n\n\nAPI/telegram_main.py\n\ntelegram_webhook_handler():\n\nPropósito: Ruta de FastAPI expuesta para recibir el webhook.\nParámetros:\n\nrequest: Petición del usuario.\nbackground_tasks: Tareas que se deben ejecutar en segundo plano.\n\nComportamiento: Envuelve la llamada a telegram_webhook en un bloque try-except para manejo de errores HTTP y registro de logs.\n\nhandle_delete_history():\n\nPropósito: Ruta API DELETE para borrar historial.\nParámetros:\n\nuser_id: Identificador del chat.\n\nComportamiento: Invoca delete_chat_history_endpoint pasando el ID del usuario proporcionado en la URL.\n\n\n\n\n\n\n3.2. Modelos LLM utilizados\nEl sistema de Salsas Castillo utiliza una combinación de modelos de lenguaje para diferentes propósitos:\n\nGeneración de respuestas y razonamiento (OpenAI - gpt-5):\n\nFunción: Es el LLM principal utilizado por AgentMultiTools para interpretar las consultas del usuario, decidir qué herramientas invocar (SQL, búsqueda de información, PDF) y generar las respuestas detalladas.\nVentaja: Ofrece alta capacidad de razonamiento y comprensión contextual para manejar consultas complejas sobre datos financieros y de ventas.\n\nTranscripción de audio (OpenAI Whisper - whisper-1):\n\nFunción: Utilizado en telegram_chat.py para transcribir mensajes de voz de los usuarios de Telegram a texto, permitiendo que el chatbot procese entradas de audio.\nVentaja: Alta precisión en la transcripción de voz a texto.\n\nGeneración de análisis para PDF (OpenAI - gpt-5):\n\nFunción: En pdf_tool.py, este modelo se utiliza para generar un párrafo de análisis conciso a partir de los datos tabulares que se incluirán en el reporte PDF.\nVentaja: Proporciona resúmenes inteligentes y profesionales de los datos."
  },
  {
    "objectID": "5_documentacion.html#guía-de-entrenamiento-y-mejora",
    "href": "5_documentacion.html#guía-de-entrenamiento-y-mejora",
    "title": "Documentación",
    "section": "4. Guía de entrenamiento y mejora",
    "text": "4. Guía de entrenamiento y mejora\nEsta sección aborda cómo se mantiene y mejora la base de conocimientos del chatbot, así como recomendaciones para futuras optimizaciones.\n\n4.1. Generación y actualización de la base de datos vectorial\nLa herramienta search_information se basa en un vector store FAISS. Este vector store almacena representaciones vectoriales de documentos internos (manuales, reglamentos, etc.) para permitir búsquedas semánticas.\nProceso de Creación: Los documentos internos se convierten en objetos langchain.schema.Document, se generan embeddings utilizando OpenAIEmbeddings, y luego se construye un índice FAISS que se guarda localmente.\nActualización: Para mantener la información actualizada, se debe ejecutar periódicamente el script que reconstruye o actualiza este vector store con cualquier nuevo documento o modificación.\n\n\n4.2. Recomendaciones para mejora futura\n\nMonitoreo avanzado: Implementar un monitoreo más detallado de las interacciones del chatbot, incluyendo el rendimiento de las consultas SQL, el tiempo de respuesta de las herramientas y la calidad de las respuestas generadas por el LLM. Esto puede hacerse analizando los datos en la colección message_backup de MongoDB.\nOptimización de prompts: Continuar iterando y refinando los prompts (prompts.py) para mejorar la precisión y coherencia de las respuestas, especialmente en casos complejos o ambiguos.\nManejo de errores robustos: Mejorar el manejo de errores en las llamadas a APIs externas (OpenAI, Telegram) y a las bases de datos (PostgreSQL, MongoDB) para proporcionar mensajes más informativos al usuario y facilitar la depuración.\nExpansión de herramientas: Considerar la adición de nuevas herramientas para el agente, como la capacidad de crear gráficos a partir de datos financieros, o interactuar con otros sistemas internos de Salsas Castillo.\nEvaluación cuantitativa: Si es posible, definir métricas cuantitativas para evaluar la calidad de las respuestas del chatbot (ej., ROUGE, BLEU, o métricas basadas en la satisfacción del usuario) para complementar la evaluación cualitativa.\nEmbeddings locales (Opcional): Investigar el uso de modelos de embeddings open-source (ej., a través de Ollama) para reducir la dependencia de OpenAI y potencialmente los costos, si la precisión es aceptable para los casos de uso de Salsas Castillo."
  },
  {
    "objectID": "5_documentacion.html#arquitectura",
    "href": "5_documentacion.html#arquitectura",
    "title": "Documentación",
    "section": "5. Arquitectura",
    "text": "5. Arquitectura\n\n5.1. Componentes clave:\n\nUsuario de Telegram: El usuario final que interactúa con el chatbot a través de la aplicación de mensajería.\nBackend del Chatbot (FastAPI): El servicio principal que procesa las consultas de los usuarios.\n\ntelegram_main.py: Punto de entrada de los webhooks de Telegram.\ntelegram_chat.py: Maneja la lógica de Telegram (transcripción de voz, envío de mensajes) y coordina preguntas y respuestas con el agente.\nagent_multitool.py: Contiene el AgentMultiTools que orquesta el LLM y las herramientas.\n\nModelo agéntico: El cerebro principal que utiliza un LLM para generar respuestas, razonar y decidir el uso de herramientas.\nBase de Datos NoSQL (MongoDB): Almacena el historial de sesiones (sessions) y un respaldo completo de mensajes (message_backup) para análisis.\nBase de Datos Relacional (PostgreSQL): Contiene los datos transaccionales de ventas (historial_facturas) y datos financieros consolidados (financieroii).\nBase de Datos Vectorial (FAISS): Almacena los embeddings de documentos internos para búsquedas semánticas (utilizado por search_information).\nHerramientas: Funciones específicas que el LLM puede invocar:\n\nsql_db_query, sql_db_schema, etc. (de SQLDatabaseToolkit): Para interactuar con PostgreSQL.\nsearch_information: Para buscar en el vector store de documentos internos.\npdf_report_tool: Para generar y enviar reportes PDF.\n\n\n\n\n5.2. Flujo de Interacción Principal:\n\nEl Usuario de Telegram envía un mensaje (texto o voz) al chatbot.\nEl mensaje es recibido por la API y enviado al endpoint /webhook del Backend del Chatbot.\ntelegram_chat.py procesa el mensaje. Si es voz, lo envía a OpenAI Whisper API para transcripción.\nEl texto del mensaje se pasa a AgentMultiTools (agent_multitool.py).\nAgentMultiTools gestiona la sesión en MongoDB y consulta el historial.\nEl LLM, guiado por los prompts (prompts.py), analiza la consulta y decide qué Herramientas utilizar:\n\nSi necesita datos de ventas, finanzas, facturas, u otras tablas, invoca herramientas SQL para consultar la base de datos de PostgreSQL.\nSi necesita información de documentos internos, invoca search_information para buscar en la Base de Datos Vectorial (FAISS).\nSi se solicita un reporte, invoca pdf_report_tool, que a su vez puede usar el LLM para análisis y luego envía el PDF a Telegram.\nSi la consulta se trata sobre una visualización de datos, se invoca table_tool, toma los datos devueltos por la consulta SQL, los convierte a tabla, lo guarda temporalmente como imagen y lo envía al usuario.\n\nLa información recuperada por las herramientas se contextualiza y se envía de nuevo al LLM para generar la respuesta final al usuario.\nLa respuesta es enviada de vuelta al Usuario de Telegram a través de la API.\nTodas las interacciones (consultas y respuestas) se registran en las colecciones sessions y message_backup en MongoDB para análisis y auditoría.\n\n\n\n5.3. Diagrama de la Arquitectura\nEl siguiente diagrama ilustra la arquitectura general del sistema del chatbot para Salsas Castillo, mostrando los componentes principales y el flujo de datos.\n\n\n\nArquitectura del sistema"
  },
  {
    "objectID": "3_modelado.html",
    "href": "3_modelado.html",
    "title": "Modelado y Evaluación",
    "section": "",
    "text": "El objetivo de esta fase es desarrollar la arquitectura del sistema del chatbot, integrando modelos de lenguaje, herramientas de acceso a datos y mecanismos de interacción.\n\n\nLa implementación del sistema se basa en una estructura modular orientada a clases, facilitando el mantenimiento y la escalabilidad. La librería principal utilizada es LangChain, que permite orquestar la interacción entre el LLM y diversas herramientas.\nLa arquitectura se centra en un modelo agéntico (AgentMultiTools) que actúa como el cerebro del chatbot.\n\n\nEl agente tiene acceso a un conjunto de herramientas dinámicas que le permiten consultar datos actualizados en tiempo real o realizar acciones específicas:\n\nHerramienta RAG: search_info_tool: Realiza búsquedas semánticas en el vector store de documentos internos.\n\n@tool(description=\"Busca información de documentos, manuales, reglamentos, etc. Devuelve un resumen de la información relevante.\")\ndef search_information(query: str) -&gt; str:\n    # ... lógica de búsqueda en vector store ...\n\nHerramientas SQL: Permiten al agente interactuar directamente con la base de datos PostgreSQL. Estas incluyen:\nsql_db_query: Para ejecutar consultas SQL y obtener resultados.\nsql_db_schema: Para obtener el esquema de las tablas y entender su estructura.\nsql_db_list_tables: Para listar las tablas disponibles.\n\n@tool(description=\"Cuando te pidan generar un reporte financiero en PDF a partir de datos generados previamente.\")\ndef generate_financial_report_pdf(table_data: str, title: str, chat_id: int) -&gt; dict:\n    # ... lógica de generación de PDF y envío a Telegram ...\nHerramientas de Generación*\n\npdf_report_tool: Genera reportes financieros en PDF a partir de datos tabulares y los envía al usuario.\ntable_tool: Cuando se trate simplemente de una visualización de datos, estos se presentan mediante una tabla convertida en imagen. Facilitando la comprensión y visualización de la información.\n\nEstas herramientas son invocadas automáticamente por el agente cuando el LLM determina que son necesarias para responder a la consulta del usuario.\n\n\n\nEl sistema se alimenta de información de la siguiente manera:\n\nConsultas de Usuario: La pregunta del usuario es el punto de entrada.\nHistorial de Conversación: El historial se gestiona en MongoDB (sessions collection) y se trunca para ajustarse a la ventana de contexto del LLM.\nLLM: Interpreta la consulta y decide qué herramientas usar.\nHerramientas SQL: Si la consulta requiere datos de la base de datos, el LLM genera una consulta SQL que se ejecuta en PostgreSQL. Los resultados se devuelven al LLM.\nHerramienta de Búsqueda de Información: Si la consulta es sobre documentos internos, se busca en el vector store (FAISS) y la información relevante se devuelve al LLM para generar la respuesta.\nHerramienta de PDF: Si se solicita un reporte, se genera el PDF con el análisis del LLM y se envía. Estos análisis pueden incluir gráficas o no.\nGeneración de Respuesta: El LLM sintetiza la información que devuelven las herramientas y genera la respuesta final al usuario.\n\n\n\n\n\nEl LLM opera con los siguientes atributos y contexto:\n\nquestion: La consulta directa del usuario.\nchat_id | session_id: ID de Telegram del usuario, necesario para enviar mensajes y PDFs directamente a Telegram. También es el identificador único de la sesión del usuario, crucial para mantener el historial de conversación.\nname: Nombre del usuario de Telegram, utilizado para personalizar la interacción.\nchat_history: Historial de mensajes previos de la sesión, truncado para optimizar el contexto.\n\n\n\n\nEl sistema de Salsas Castillo utiliza estratégicamente varios modelos de lenguaje:\n\nGPT (OpenAI):\n\nFunción principal: Es el modelo central para el razonamiento del agente, la interpretación de consultas complejas y la generación de respuestas detalladas. Decide cuándo y cómo usar las herramientas SQL, de búsqueda de información y de PDF. También se utiliza para generar el análisis textual en los reportes PDF.\nVentaja: Alta capacidad de comprensión, razonamiento y generación de texto coherente y preciso, fundamental para análisis financiero y de ventas. Actualmente usamos el modelo GPT-5 como modelo central pero también usamos el modelo GPT-4.1 en ciertas herramientas por su gran ventana de contexto que permite manejar mayor cantidad de información.\n\nWhisper-1 (OpenAI):\n\nFunción: Utilizado para la transcripción de mensajes de voz de los usuarios de Telegram a texto.\nVentaja: Excelente precisión en la conversión de audio a texto, lo que permite una interacción más flexible con el chatbot."
  },
  {
    "objectID": "3_modelado.html#modelado",
    "href": "3_modelado.html#modelado",
    "title": "Modelado y Evaluación",
    "section": "",
    "text": "El objetivo de esta fase es desarrollar la arquitectura del sistema del chatbot, integrando modelos de lenguaje, herramientas de acceso a datos y mecanismos de interacción.\n\n\nLa implementación del sistema se basa en una estructura modular orientada a clases, facilitando el mantenimiento y la escalabilidad. La librería principal utilizada es LangChain, que permite orquestar la interacción entre el LLM y diversas herramientas.\nLa arquitectura se centra en un modelo agéntico (AgentMultiTools) que actúa como el cerebro del chatbot.\n\n\nEl agente tiene acceso a un conjunto de herramientas dinámicas que le permiten consultar datos actualizados en tiempo real o realizar acciones específicas:\n\nHerramienta RAG: search_info_tool: Realiza búsquedas semánticas en el vector store de documentos internos.\n\n@tool(description=\"Busca información de documentos, manuales, reglamentos, etc. Devuelve un resumen de la información relevante.\")\ndef search_information(query: str) -&gt; str:\n    # ... lógica de búsqueda en vector store ...\n\nHerramientas SQL: Permiten al agente interactuar directamente con la base de datos PostgreSQL. Estas incluyen:\nsql_db_query: Para ejecutar consultas SQL y obtener resultados.\nsql_db_schema: Para obtener el esquema de las tablas y entender su estructura.\nsql_db_list_tables: Para listar las tablas disponibles.\n\n@tool(description=\"Cuando te pidan generar un reporte financiero en PDF a partir de datos generados previamente.\")\ndef generate_financial_report_pdf(table_data: str, title: str, chat_id: int) -&gt; dict:\n    # ... lógica de generación de PDF y envío a Telegram ...\nHerramientas de Generación*\n\npdf_report_tool: Genera reportes financieros en PDF a partir de datos tabulares y los envía al usuario.\ntable_tool: Cuando se trate simplemente de una visualización de datos, estos se presentan mediante una tabla convertida en imagen. Facilitando la comprensión y visualización de la información.\n\nEstas herramientas son invocadas automáticamente por el agente cuando el LLM determina que son necesarias para responder a la consulta del usuario.\n\n\n\nEl sistema se alimenta de información de la siguiente manera:\n\nConsultas de Usuario: La pregunta del usuario es el punto de entrada.\nHistorial de Conversación: El historial se gestiona en MongoDB (sessions collection) y se trunca para ajustarse a la ventana de contexto del LLM.\nLLM: Interpreta la consulta y decide qué herramientas usar.\nHerramientas SQL: Si la consulta requiere datos de la base de datos, el LLM genera una consulta SQL que se ejecuta en PostgreSQL. Los resultados se devuelven al LLM.\nHerramienta de Búsqueda de Información: Si la consulta es sobre documentos internos, se busca en el vector store (FAISS) y la información relevante se devuelve al LLM para generar la respuesta.\nHerramienta de PDF: Si se solicita un reporte, se genera el PDF con el análisis del LLM y se envía. Estos análisis pueden incluir gráficas o no.\nGeneración de Respuesta: El LLM sintetiza la información que devuelven las herramientas y genera la respuesta final al usuario.\n\n\n\n\n\nEl LLM opera con los siguientes atributos y contexto:\n\nquestion: La consulta directa del usuario.\nchat_id | session_id: ID de Telegram del usuario, necesario para enviar mensajes y PDFs directamente a Telegram. También es el identificador único de la sesión del usuario, crucial para mantener el historial de conversación.\nname: Nombre del usuario de Telegram, utilizado para personalizar la interacción.\nchat_history: Historial de mensajes previos de la sesión, truncado para optimizar el contexto.\n\n\n\n\nEl sistema de Salsas Castillo utiliza estratégicamente varios modelos de lenguaje:\n\nGPT (OpenAI):\n\nFunción principal: Es el modelo central para el razonamiento del agente, la interpretación de consultas complejas y la generación de respuestas detalladas. Decide cuándo y cómo usar las herramientas SQL, de búsqueda de información y de PDF. También se utiliza para generar el análisis textual en los reportes PDF.\nVentaja: Alta capacidad de comprensión, razonamiento y generación de texto coherente y preciso, fundamental para análisis financiero y de ventas. Actualmente usamos el modelo GPT-5 como modelo central pero también usamos el modelo GPT-4.1 en ciertas herramientas por su gran ventana de contexto que permite manejar mayor cantidad de información.\n\nWhisper-1 (OpenAI):\n\nFunción: Utilizado para la transcripción de mensajes de voz de los usuarios de Telegram a texto.\nVentaja: Excelente precisión en la conversión de audio a texto, lo que permite una interacción más flexible con el chatbot."
  },
  {
    "objectID": "3_modelado.html#evaluación",
    "href": "3_modelado.html#evaluación",
    "title": "Modelado y Evaluación",
    "section": "2. Evaluación",
    "text": "2. Evaluación\nLa evaluación del chatbot de Salsas Castillo se centra en la calidad y precisión de sus respuestas, dada la naturaleza de las consultas financieras y de ventas.\n\n2.1. Criterios de Evaluación\nLa evaluación se realiza mediante un análisis cualitativo, considerando los siguientes criterios:\n\nPrecisión de los Datos: La información proporcionada (cifras de ventas, costos, nombres de productos) debe coincidir exactamente con los datos de las bases de datos SQL.\nCoherencia y Relevancia: Las respuestas deben ser lógicas, directas y pertinentes a la pregunta del usuario, evitando “alucinaciones” o información incorrecta.\nCapacidad de Análisis: Para consultas que requieren análisis (ej., tendencias de ventas, márgenes), la respuesta debe ser comprensible y destacar las conclusiones clave.\nGeneración de Reportes: Los PDFs generados deben ser comprensibles, contener los datos solicitados y el análisis del LLM debe ser claro y profesional.\nManejo de Ambigüedad: La capacidad del chatbot para pedir aclaraciones o proponer interpretaciones cuando la consulta no es clara. También debe ser capaz de generar respuestas generales aún cuando falte especificación de la información.\n\n\n\n2.2. Proceso de Evaluación (Simulación)\nSe simulan una serie de consultas típicas que un usuario de Salsas Castillo podría realizar, cubriendo distintos escenarios:\n\nConsultas de Ventas: “Muéstrame las ventas del producto ‘AMOR 12 / 1000 ML’ en el último mes.”\nConsultas Financieras: “¿Cuál fue el margen de ganancia del segundo trimestre de 2025?”\nGeneración de Reportes: “Genera un reporte de ventas por presentación para el mes de mayo.”\nBúsqueda de Documentos: “Necesito el reglamento de uso de las bodegas.” (Si aplica y se ha cargado un documento de ejemplo)\nConsultas Ambiguas: “Quiero saber sobre las salsas vendidas ayer” (El chatbot debería pedir más detalles o sugerir opciones o debería generar una respuestas general).\n\nLos resultados de estas simulaciones son revisados por expertos con conocimiento del negocio para validar la calidad de las respuestas y el comportamiento general del sistema.\nLos resultados obtenidos hasta ahora sugieren un desempeño prometedor del sistema, con respuestas coherentes y alineadas con las bases de datos. Esto valida la viabilidad de continuar con el despliegue y la iteración en un entorno de pruebas real."
  },
  {
    "objectID": "1_comprension.html",
    "href": "1_comprension.html",
    "title": "Comprensión del negocio",
    "section": "",
    "text": "Salsas Castillo es una empresa dedicada a la producción y comercialización de salsas picantes, soya, chamoy y otros productos. Su portafolio se distribuye a una amplia red de tiendas, restaurantes y mayoristas en todo México. Con un catálogo en constante crecimiento y una operación comercial dinámica, la empresa enfrenta el reto de gestionar grandes volúmenes de información interna de forma ágil y eficiente.\nActualmente, el acceso a datos específicos —como ventas, finanzas o documentación interna— suele ser un proceso manual y demandante, lo que dificulta responder con rapidez a consultas y limita la generación de análisis oportunos para la toma de decisiones. Esto ha impulsado la necesidad de una solución que centralice y automatice el acceso a la información.\nObjetivo del proyecto:\nDesarrollar un chatbot inteligente que funcione como asistente virtual para el personal de Salsas Castillo, permitiendo realizar consultas rápidas y precisas sobre datos de ventas, finanzas, facturas y documentos internos. El propósito es mejorar la eficiencia operativa, elevar la calidad de la toma de decisiones y fortalecer la comunicación interna.\nImpacto:\nLa implementación de este chatbot permitirá a Salsas Castillo:\n\nAgilizar el acceso a la información: Reducir el tiempo que el personal dedica a buscar datos específicos en bases de datos o documentos.\nMejorar la precisión de los datos: Proporcionar respuestas consistentes y actualizadas directamente de las fuentes de datos en tiempo real.\nFomentar la autonomía: Empoderar a los empleados para obtener la información que necesitan sin depender de intermediarios y al alcance de su mano.\nOptimizar la toma de decisiones: Facilitar análisis rápidos y la generación de reportes para una gestión más proactiva."
  },
  {
    "objectID": "1_comprension.html#objetivos-de-la-línea-de-investigación",
    "href": "1_comprension.html#objetivos-de-la-línea-de-investigación",
    "title": "Comprensión del negocio",
    "section": "0.1 Objetivos de la línea de investigación",
    "text": "0.1 Objetivos de la línea de investigación\nEsta iniciativa se enfoca en aprovechar la información existente de Salsas Castillo para crear un sistema de consulta inteligente.\nEl objetivo principal es desarrollar un chatbot en Telegram que funcione como un asistente virtual para la generación de análisis complejos, capaz de:\n\nInterpretar consultas en lenguaje natural: Permitir a los usuarios hacer preguntas complejas sin necesidad de conocimientos técnicos de bases de datos.\nAcceder a datos dinámicos: Conectarse directamente a las bases de datos transaccionales (PostgreSQL) para obtener información actualizada dentro de la base de datos.\nBuscar en documentos internos: Utilizar una base de datos vectorial para recuperar información de documentos como manuales, reglamentos, contratos, etc.\nGenerar reportes: Crear y enviar reportes financieros en formato PDF a través de Telegram.\n\nObjetivos específicos:\n\nIntegrar fuentes de datos: Establecer conexiones robustas con las bases de datos en PostgreSQL.\nDesarrollar herramientas de consulta: Implementar funciones que permitan al LLM interactuar con SQL para extraer y procesar datos.\nConstruir una base de conocimiento vectorial: Procesar documentos internos para crear embeddings y un vector store para búsquedas semánticas.\nImplementar un agente conversacional: Configurar un agente basado en LangChain que orqueste el uso del LLM y las herramientas.\nHabilitar la generación de reportes PDF: Desarrollar la capacidad de crear reportes dinámicos a partir de los datos consultados.\nDesplegar el chatbot en Telegram: Asegurar la funcionalidad completa del chatbot en la plataforma de Telegram, incluyendo la transcripción de audio.\n\nCriterios de éxito:\n\nPrecisión de las respuestas: El chatbot debe proporcionar información precisa, exacta y relevante en al menos el 90% de las consultas cuando se trate de cálculos y uso de formulas.\nFidelidad: Debe ser fiel a la información extraída de las bases de datos sin presentar alucionaciones en al menos el 90% de las consultas.\nCapacidad de análisis: Debe ser capaz de realizar análisis tanto básicos como complejos de datos y generar reportes comprensibles.\nUsabilidad: La interacción a través de Telegram debe ser intuitiva y accesible para usuarios con diferentes niveles de conocimientos técnicos."
  },
  {
    "objectID": "1_comprension.html#evaluación-de-la-situación-actual",
    "href": "1_comprension.html#evaluación-de-la-situación-actual",
    "title": "Comprensión del negocio",
    "section": "0.2 Evaluación de la Situación Actual",
    "text": "0.2 Evaluación de la Situación Actual\nLos recursos disponibles para este proyecto incluyen:\n\nDatos: Acceso a bases de datos PostgreSQL con información de ventas transaccionales y datos financieros consolidados.\nHerramientas: Python, FastAPI, LangChain, OpenAI API, PyMongo, Reportlab, y PostgreSQL.\nEquipo humano: El equipo de Salsas Castillo que provee la información y el contexto necesario para alinear el conocimiento del sistma, y el equipo de desarrollo del proyecto.\n\n\n0.2.1 Requisitos, Supuestos y Restricciones\nRequisitos:\n\nAcceso continuo y estable a las bases de datos PostgreSQL y MongoDB.\nServidor donde se desplegará la API del sistema desarrollado.\nCredenciales válidas para las APIs de OpenAI y el token de Telegram.\nComunicación fluida para la retroalimentación y validación de funcionalidades.\n\nSupuestos:\n\nLas bases de datos de la empresa contienen la información necesaria y están estructuradas de manera que permitan las consultas requeridas sin complicaciones.\nLa API de OpenAI y Telegram mantendrán su disponibilidad y rendimiento.\nEl servidor proveído por la empresa estará siempre disponible para el equipo de desarrollo sin restricciones.\n\nRestricciones:\n\nPosibles limitaciones en la tasa de llamadas a las APIs externas.\nLa complejidad de las consultas SQL puede requerir optimización.\nLa seguridad de la información debe ser una prioridad en todo momento."
  },
  {
    "objectID": "1_comprension.html#terminología",
    "href": "1_comprension.html#terminología",
    "title": "Comprensión del negocio",
    "section": "0.3 Terminología",
    "text": "0.3 Terminología\nAlgunas de las terminologías clave para este proyecto son:\n\nPython: Lenguaje de programación de alto nivel, fundamental para el desarrollo del backend del chatbot.\nFastAPI: Framework de desarrollo web en Python para construir APIs de forma rápida y eficiente.\nLangChain: Herramienta para construir aplicaciones que combinan modelos de lenguaje con fuentes de datos externas y lógica personalizada.\nInteligencia Artificial (IA): Campo de la informática que desarrolla sistemas capaces de realizar tareas que requieren inteligencia humana.\nModelos de Lenguaje Grande (LLM): Modelos de IA entrenados con vastos volúmenes de texto para comprender y generar lenguaje natural. En este proyecto, se utiliza GPT-4.1 de OpenAI.\nSistema de Recuperación Aumentada con Generación (RAG): Técnica que combina LLMs con bases de datos externas para recuperar información relevante y generar respuestas más precisas y contextualizadas.\nRepresentación Vectorial: Proceso de convertir datos textuales en representaciones numéricas (vectores) para facilitar su análisis y búsqueda.\nModelo de Embeddings: Algoritmo que transforma palabras o frases en vectores. Se utilizan OpenAI Embeddings para documentos internos.\nBase de Datos Vectorial (FAISS): Sistema de almacenamiento optimizado para buscar y recuperar información midiendo la similitud entre vectores. Se utiliza para documentos internos.\nBase de Datos SQL (Structured Query Language): Sistema de almacenamiento relacional que organiza los datos en tablas. En este proyecto, PostgreSQL es la fuente de datos transaccionales y financieros.\nAPI (Interfaz de Programación de Aplicaciones): Conjunto de reglas que permite que diferentes sistemas de software se comuniquen entre sí.\nAPI Key: Clave de autenticación utilizada para acceder a servicios protegidos por una API.\nEndpoint (API): Dirección específica dentro de una API donde se accede a una funcionalidad concreta.\nPayload (HTTP): Contenido de los datos enviados en una solicitud HTTP.\nChatbot: Programa que interactúa con los usuarios mediante lenguaje natural.\nTelegram Bot API: La interfaz de programación que permite a los desarrolladores crear bots que interactúan con los usuarios de Telegram.\nWebhook: Un mecanismo que permite a una aplicación recibir información en tiempo real de otra aplicación cuando ocurre un evento específico.\nMongoDB: Base de datos NoSQL utilizada para almacenar el historial de sesiones y los respaldos de mensajes.\nOpenAI Whisper: Modelo de IA para la transcripción de audio a texto.\nReportlab: Librería de Python para la generación de documentos PDF. `"
  },
  {
    "objectID": "1_comprension.html#beneficios",
    "href": "1_comprension.html#beneficios",
    "title": "Comprensión del negocio",
    "section": "0.4 Beneficios",
    "text": "0.4 Beneficios\n\nAcceso Instantáneo a la Información: El personal puede obtener datos clave de ventas y finanzas en segundos, directamente desde Telegram.\nAnálisis de Datos Simplificado: La capacidad de generar reportes en PDF con un análisis generado por el LLM democratiza el acceso a distintas perspectivas del negocio.\nReducción de Carga de Trabajo: Disminuye la necesidad de consultas manuales a las bases de datos y/o la preparación de reportes rutinarios.\nMejora en la Productividad: Permite a los equipos enfocarse en tareas de mayor valor al tener la información al alcance de la mano.\nInnovación Tecnológica: Salsas Castillo se posiciona a la vanguardia en el uso de IA para la gestión empresarial."
  },
  {
    "objectID": "1_comprension.html#costos",
    "href": "1_comprension.html#costos",
    "title": "Comprensión del negocio",
    "section": "0.5 Costos",
    "text": "0.5 Costos\n\nTiempo: El desarrollo y la implementación del chatbot requieren una inversión de tiempo significativa del equipo de desarrollo.\nFinancieros: Costos asociados a las suscripciones de APIs (OpenAI) y, potencialmente, a la infraestructura de servidores para el despliegue."
  },
  {
    "objectID": "0_home.html",
    "href": "0_home.html",
    "title": "GlorIA: Análisis empresarial desde un enfoque con IA",
    "section": "",
    "text": "Este proyecto se enfoca en el desarrollo de un chatbot inteligente para Salsas Castillo, diseñado para optimizar el acceso a información crítica de ventas, finanzas, facturas y más. A través de este asistente conversacional, se busca empoderar al personal de toma de decisiones, proporcionando respuestas rápidas y precisas a sus consultas, y facilitando la toma de decisiones basadas en datos actualizados que cambian en tiempo real.\nEl chatbot se basa en un modelo agéntico MCP (Protocolo de Contexto del Modelo), que combina modelos de lenguaje avanzados con acceso directo a bases de datos relacionales (PostgreSQL) y vectoriales (FAISS). Además de la capacidad de generar reportes en PDF y generación de tablas para una visualización más amigable. La interacción principal se realiza a través de la plataforma de mensajería Telegram.\nEl proyecto se divide en las siguientes fases clave:\n\nComprensión del Negocio: Definición de los objetivos estratégicos y el contexto operativo de Salsas Castillo, enfocados en mejorar la eficiencia en el acceso a la información, el correcto manejo y manipulación de los datos para una generación eficiente de respuestas, y la comunicación interna.\nPreparación: Diseño e implementación de la arquitectura del chatbot, incluyendo la integración de bases de datos relacionales y vectoriales, el desarrollo de herramientas personalizadas, y su flujo de trabajo.\nModelado y Evaluación: La configuración de modelos de lenguaje y la validación de su desempeño a través de consultas controladas.\nDespliegue: Integración del chatbot en el entorno de producción de Telegram y la infraestructura de Salsas Castillo, asegurando su operatividad y accesibilidad.\n\nA través de estas fases, buscamos proporcionar una solución innovadora que transforme la manera en que Salsas Castillo accede y utiliza su información de negocio, impulsando la eficiencia y la agilidad en sus operaciones diarias."
  },
  {
    "objectID": "0_home.html#introducción",
    "href": "0_home.html#introducción",
    "title": "GlorIA: Análisis empresarial desde un enfoque con IA",
    "section": "",
    "text": "Este proyecto se enfoca en el desarrollo de un chatbot inteligente para Salsas Castillo, diseñado para optimizar el acceso a información crítica de ventas, finanzas, facturas y más. A través de este asistente conversacional, se busca empoderar al personal de toma de decisiones, proporcionando respuestas rápidas y precisas a sus consultas, y facilitando la toma de decisiones basadas en datos actualizados que cambian en tiempo real.\nEl chatbot se basa en un modelo agéntico MCP (Protocolo de Contexto del Modelo), que combina modelos de lenguaje avanzados con acceso directo a bases de datos relacionales (PostgreSQL) y vectoriales (FAISS). Además de la capacidad de generar reportes en PDF y generación de tablas para una visualización más amigable. La interacción principal se realiza a través de la plataforma de mensajería Telegram.\nEl proyecto se divide en las siguientes fases clave:\n\nComprensión del Negocio: Definición de los objetivos estratégicos y el contexto operativo de Salsas Castillo, enfocados en mejorar la eficiencia en el acceso a la información, el correcto manejo y manipulación de los datos para una generación eficiente de respuestas, y la comunicación interna.\nPreparación: Diseño e implementación de la arquitectura del chatbot, incluyendo la integración de bases de datos relacionales y vectoriales, el desarrollo de herramientas personalizadas, y su flujo de trabajo.\nModelado y Evaluación: La configuración de modelos de lenguaje y la validación de su desempeño a través de consultas controladas.\nDespliegue: Integración del chatbot en el entorno de producción de Telegram y la infraestructura de Salsas Castillo, asegurando su operatividad y accesibilidad.\n\nA través de estas fases, buscamos proporcionar una solución innovadora que transforme la manera en que Salsas Castillo accede y utiliza su información de negocio, impulsando la eficiencia y la agilidad en sus operaciones diarias."
  },
  {
    "objectID": "2_preparacion.html",
    "href": "2_preparacion.html",
    "title": "Preparación",
    "section": "",
    "text": "A diferencia de un proceso ETL tradicional con extracción y transformación masiva de datos a un destino intermedio, el proyecto con Salsas Castillo se enfoca en la conexión de datos en tiempo real a través de herramientas SQL, y la preparación de un vector store para documentos internos.\n\n\nLas fuentes de información principales para el chatbot son:\n\nBase de Datos PostgreSQL: Contiene la información transaccional de ventas, facturas, datos financieros consolidados, entra otras tablas. Estos datos se acceden directamente mediante consultas SQL generadas por el LLM.\nDocumentos Internos (Vector Store): Archivos como manuales, reglamentos o cualquier otra información textual estática que se haya procesado para búsquedas semánticas.\n\n\n\n\n\n\nLos datos de ventas y finanzas se acceden directamente desde PostgreSQL en tiempo real. La preparación aquí, se centra en cómo el sistema interactúa con la base de datos:\n\nConexión: Se utiliza psycopg2 para establecer la conexión con la base de datos empresarial. Las credenciales se gestionan de forma segura mediante variables de entorno.\nGeneración de Consultas: El LLM es capaz de generar consultas SQL dinámicamente, basándose en la pregunta del usuario y el esquema de la base de datos. Se han definido reglas específicas en el prompt del sistema (settings/prompts.py) para asegurar la sintaxis correcta.\nManejo de Columnas: El LLM está instruido para inferir el significado de las columnas y, si es necesario, consultar el esquema de la base de datos (sql_db_schema tool) antes de generar una consulta. Esto minimiza errores por nombres de columnas desconocidos.\nMapeo de Productos: Se incluye una lista de nombres de productos (dicts.py) para ayudar al LLM a hacer matches precisos con las presentaciones de productos en la base de datos, mejorando la relevancia de las respuestas.\n\n\n\n\nPara la información estática contenida en documentos internos (que no están en las bases de datos SQL), se construye un vector store para permitir búsquedas semánticas:\n\nDocumentos: Los documentos textuales se cargan y se convierten en objetos langchain.schema.Document.\nEmbeddings: Se utilizan OpenAIEmbeddings para transformar el contenido textual de cada documento en representaciones vectoriales numéricas.\nÍndice FAISS: Se crea un índice FAISS (LangchainVectorStore en langchain/vectorstore.py) a partir de estos embeddings. Este índice se guarda localmente para su uso eficiente.\nActualización: Aunque no se describe un ETL formal, la actualización de este vector store implicaría volver a procesar los documentos modificados o nuevos para regenerar el índice."
  },
  {
    "objectID": "2_preparacion.html#preparación-de-los-datos",
    "href": "2_preparacion.html#preparación-de-los-datos",
    "title": "Preparación",
    "section": "",
    "text": "A diferencia de un proceso ETL tradicional con extracción y transformación masiva de datos a un destino intermedio, el proyecto con Salsas Castillo se enfoca en la conexión de datos en tiempo real a través de herramientas SQL, y la preparación de un vector store para documentos internos.\n\n\nLas fuentes de información principales para el chatbot son:\n\nBase de Datos PostgreSQL: Contiene la información transaccional de ventas, facturas, datos financieros consolidados, entra otras tablas. Estos datos se acceden directamente mediante consultas SQL generadas por el LLM.\nDocumentos Internos (Vector Store): Archivos como manuales, reglamentos o cualquier otra información textual estática que se haya procesado para búsquedas semánticas.\n\n\n\n\n\n\nLos datos de ventas y finanzas se acceden directamente desde PostgreSQL en tiempo real. La preparación aquí, se centra en cómo el sistema interactúa con la base de datos:\n\nConexión: Se utiliza psycopg2 para establecer la conexión con la base de datos empresarial. Las credenciales se gestionan de forma segura mediante variables de entorno.\nGeneración de Consultas: El LLM es capaz de generar consultas SQL dinámicamente, basándose en la pregunta del usuario y el esquema de la base de datos. Se han definido reglas específicas en el prompt del sistema (settings/prompts.py) para asegurar la sintaxis correcta.\nManejo de Columnas: El LLM está instruido para inferir el significado de las columnas y, si es necesario, consultar el esquema de la base de datos (sql_db_schema tool) antes de generar una consulta. Esto minimiza errores por nombres de columnas desconocidos.\nMapeo de Productos: Se incluye una lista de nombres de productos (dicts.py) para ayudar al LLM a hacer matches precisos con las presentaciones de productos en la base de datos, mejorando la relevancia de las respuestas.\n\n\n\n\nPara la información estática contenida en documentos internos (que no están en las bases de datos SQL), se construye un vector store para permitir búsquedas semánticas:\n\nDocumentos: Los documentos textuales se cargan y se convierten en objetos langchain.schema.Document.\nEmbeddings: Se utilizan OpenAIEmbeddings para transformar el contenido textual de cada documento en representaciones vectoriales numéricas.\nÍndice FAISS: Se crea un índice FAISS (LangchainVectorStore en langchain/vectorstore.py) a partir de estos embeddings. Este índice se guarda localmente para su uso eficiente.\nActualización: Aunque no se describe un ETL formal, la actualización de este vector store implicaría volver a procesar los documentos modificados o nuevos para regenerar el índice."
  },
  {
    "objectID": "4_despliegue.html",
    "href": "4_despliegue.html",
    "title": "Despliegue",
    "section": "",
    "text": "El desarrollo del chatbot para Salsas Castillo ha seguido un enfoque iterativo, centrado en la integración de modelos de lenguaje con las bases de datos existentes y la plataforma de Telegram. Los principales retos se concentraron en asegurar la interacción fluida y precisa del LLM con las bases de datos SQL para consultas dinámicas, así como la correcta gestión del historial de conversación y la generación de reportes en PDF.\nEl objetivo principal de optimizar el acceso a la información de productos y finanzas se ha mantenido constante a lo largo del proyecto, adaptándose a las particularidades de Salsas Castillo.\n\n\nConsiderando los avances en el desarrollo y las pruebas internas, se ha decidido priorizar el despliegue en un entorno de pruebas real para validar el comportamiento del chatbot en condiciones operativas y recopilar feedback directo de los usuarios.\n\n\n\nLa decisión es proceder con la implementación del chatbot en un entorno de pruebas de Telegram. Esto permitirá:\n\nValidar la integración completa con la API de Telegram.\nProbar la conectividad y el rendimiento con las bases de datos PostgreSQL y MongoDB en un entorno real.\nRecopilar feedback de usuarios internos para identificar mejoras en la experiencia de usuario y la precisión de las respuestas.\nAsegurar la robustez y estabilidad del sistema antes de una posible implementación a mayor escala."
  },
  {
    "objectID": "4_despliegue.html#revisión-del-proceso",
    "href": "4_despliegue.html#revisión-del-proceso",
    "title": "Despliegue",
    "section": "",
    "text": "El desarrollo del chatbot para Salsas Castillo ha seguido un enfoque iterativo, centrado en la integración de modelos de lenguaje con las bases de datos existentes y la plataforma de Telegram. Los principales retos se concentraron en asegurar la interacción fluida y precisa del LLM con las bases de datos SQL para consultas dinámicas, así como la correcta gestión del historial de conversación y la generación de reportes en PDF.\nEl objetivo principal de optimizar el acceso a la información de productos y finanzas se ha mantenido constante a lo largo del proyecto, adaptándose a las particularidades de Salsas Castillo.\n\n\nConsiderando los avances en el desarrollo y las pruebas internas, se ha decidido priorizar el despliegue en un entorno de pruebas real para validar el comportamiento del chatbot en condiciones operativas y recopilar feedback directo de los usuarios.\n\n\n\nLa decisión es proceder con la implementación del chatbot en un entorno de pruebas de Telegram. Esto permitirá:\n\nValidar la integración completa con la API de Telegram.\nProbar la conectividad y el rendimiento con las bases de datos PostgreSQL y MongoDB en un entorno real.\nRecopilar feedback de usuarios internos para identificar mejoras en la experiencia de usuario y la precisión de las respuestas.\nAsegurar la robustez y estabilidad del sistema antes de una posible implementación a mayor escala."
  },
  {
    "objectID": "4_despliegue.html#plan-de-implementación",
    "href": "4_despliegue.html#plan-de-implementación",
    "title": "Despliegue",
    "section": "2. Plan de Implementación",
    "text": "2. Plan de Implementación\nLa fase de implementación implica el despliegue del backend del chatbot y su integración con la plataforma de Telegram.\n\n2.1. Arquitectura de Despliegue y Conexión\nEl chatbot de Salsas Castillo se despliega como un servicio de backend basado en FastAPI, que interactúa con la API de Telegram mediante webhooks. La persistencia de datos se maneja con MongoDB y las consultas a datos transaccionales se realizan en PostgreSQL.\n\nBackend del Chatbot (FastAPI): La aplicación principal se despliega en un servidor (o ambiente virtual Linux) utilizando Gunicorn para producción o Uvicorn para desarrollo.\nConexión con Telegram: La comunicación se establece a través de webhooks. Telegram envía las actualizaciones de mensajes al endpoint /webhook de la API de FastAPI. El chatbot, a su vez, utiliza la API de Telegram para enviar respuestas y documentos (PDFs).\nBases de Datos:\n\nPostgreSQL: Se establece una conexión directa desde el backend del chatbot para las consultas SQL.\nMongoDB: Se utiliza para almacenar el historial de sesiones (sessions) y un respaldo completo de mensajes (message_backup).\n\n\n\n\n2.2. Gestión de Persistencia de Datos con MongoDB\nLa gestión del historial de conversaciones es crucial para un chatbot. En Salsas Castillo, se utiliza MongoDB con dos colecciones principales:\n\nsessions: Almacena los últimos mensajes de cada sesión de usuario para mantener el contexto de la conversación. Se configura para mantener un tamaño fijo (ej., los últimos 24 mensajes) para optimizar el rendimiento.\nmessage_backup: Actúa como un histórico completo de todas las interacciones (preguntas del usuario, respuestas del chatbot, metadatos). Es fundamental para el análisis de datos, auditorías y futuras mejoras del modelo.\n\n\n\n2.3. Plan de Monitoreo\nDurante la fase de pruebas, se implementará un plan de monitoreo para evaluar el rendimiento y comportamiento del sistema:\n\nTiempo de Respuesta: Latencia de las respuestas del chatbot, incluyendo el tiempo de ejecución de las consultas SQL y las llamadas a la API de OpenAI.\nTasa de Éxito/Error: Monitoreo de las peticiones a la API del chatbot y a las bases de datos.\nCalidad de las Respuestas: Evaluación manual de la precisión, coherencia y relevancia de las respuestas, especialmente en escenarios complejos o con datos numéricos.\nUso del Chatbot: Frecuencia de interacciones por usuario, tipos de consultas más comunes.\nErrores en Logs: Revisión de los logs del servidor para identificar excepciones o problemas en el backend.\n\n\n\n2.4. Plan de Mantenimiento\nSe establecerá un plan de mantenimiento periódico para asegurar la estabilidad y el buen funcionamiento del sistema:\n\nActualización de Dependencias: Revisión y actualización regular de las librerías de Python (FastAPI, LangChain, PyMongo, etc.).\nRevisión de Logs: Monitoreo activo de los logs del servidor y de las bases de datos para identificar y solucionar problemas.\nAuditoría de Datos y Respuestas: Evaluación periódica de la calidad de los datos en PostgreSQL y MongoDB, y verificación de la precisión de las respuestas del chatbot a lo largo del tiempo.\nOptimización de Consultas: Refinamiento continuo de las consultas SQL generadas por el LLM para mejorar el rendimiento.\nActualización del Vector Store: Si se añaden nuevos documentos internos, se programará la actualización del vector store FAISS.\n\n\n\n2.5. Experiencia de Desarrollo\nEl proyecto ha permitido consolidar la experiencia en el desarrollo de un chatbot completo, desde la integración con plataformas de mensajería (Telegram) hasta la orquestación de LLMs con bases de datos relacionales y vectoriales. Los aprendizajes clave incluyen:\n\nManejo de la interacción entre LLMs y bases de datos SQL para consultas dinámicas.\nImplementación de la persistencia de sesiones y el historial de mensajes en MongoDB.\nDesarrollo de herramientas personalizadas (ej., generación de PDFs) y su integración en el flujo del agente.\nGestión de la transcripción de audio para una experiencia de usuario más inclusiva.\nAdherencia a buenas prácticas de desarrollo modular y escalable.\n\n\n\n2.6. Despliegue del Chatbot en el Sistema de Pruebas\nEl chatbot será desplegado en un entorno de pruebas de Telegram, accesible para un grupo controlado de usuarios internos de Salsas Castillo. Este despliegue permitirá validar el sistema en condiciones casi reales.\nEl proceso de despliegue consistirá en:\n\nMontaje del Entorno de la API: Despliegue de la API de FastAPI en un servidor dedicado, asegurando la conectividad con PostgreSQL y MongoDB.\nConfiguración del Webhook de Telegram: Establecer el webhook para que Telegram envíe las actualizaciones de mensajes al endpoint de la API.\nVerificación Funcional: Realizar pruebas exhaustivas para verificar el flujo de conversación, la precisión de las respuestas, la generación de PDFs y el manejo de la transcripción de audio.\nConsideraciones de Seguridad: Asegurar la autenticación de usuarios (mediante whitelist de Telegram IDs), el manejo seguro de credenciales y la protección de datos.\n\nEste hito marca un avance significativo hacia la validación en entorno real del sistema conversacional, permitiendo recopilar feedback de usuarios internos antes de considerar un despliegue completo en producción."
  }
]