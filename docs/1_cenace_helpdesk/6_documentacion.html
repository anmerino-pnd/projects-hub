<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Documentación</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-8ea72dc5fed832574809a9c94082fbbb.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-ddd961a2510921635943dfbbd19534c4.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-ae2d0dcda2edce4ab590422bb373b64f.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./cenace.png" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Buscar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Navegación de palanca" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./0_home.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./1_comprension.html"> 
<span class="menu-text">Comprensión del negocio</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./2_comprension_datos.html"> 
<span class="menu-text">Comprensión de los datos</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./3_preparacion.html"> 
<span class="menu-text">Preparación</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./4_modelado.html"> 
<span class="menu-text">Modelado y Evaluación</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./5_despliegue.html"> 
<span class="menu-text">Despliegue</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./6_documentacion.html" aria-current="page"> 
<span class="menu-text">Documentación</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="./../proyectos.html"> <i class="bi bi-box-arrow-left" role="img">
</i> 
<span class="menu-text">Ver más proyectos</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Alternar modo oscuro"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de Contenidos</h2>
   
  <ul>
  <li><a href="#manual-de-instalación-y-despliegue" id="toc-manual-de-instalación-y-despliegue" class="nav-link active" data-scroll-target="#manual-de-instalación-y-despliegue">1. Manual de instalación y despliegue</a>
  <ul class="collapse">
  <li><a href="#configuraciones-importantes" id="toc-configuraciones-importantes" class="nav-link" data-scroll-target="#configuraciones-importantes">1.1. Configuraciones importantes</a></li>
  <li><a href="#requisitos-del-sistema" id="toc-requisitos-del-sistema" class="nav-link" data-scroll-target="#requisitos-del-sistema">1.2. Requisitos del sistema</a></li>
  <li><a href="#dependencias-principales-del-sistema" id="toc-dependencias-principales-del-sistema" class="nav-link" data-scroll-target="#dependencias-principales-del-sistema">1.3. Dependencias principales del sistema</a></li>
  <li><a href="#instalación-del-sistema" id="toc-instalación-del-sistema" class="nav-link" data-scroll-target="#instalación-del-sistema">1.4. Instalación del sistema</a></li>
  </ul></li>
  <li><a href="#documentación-técnica-del-código" id="toc-documentación-técnica-del-código" class="nav-link" data-scroll-target="#documentación-técnica-del-código">2. Documentación técnica del código</a>
  <ul class="collapse">
  <li><a href="#estructura-de-carpetas-y-módulos" id="toc-estructura-de-carpetas-y-módulos" class="nav-link" data-scroll-target="#estructura-de-carpetas-y-módulos">2.1. Estructura de carpetas y módulos</a></li>
  <li><a href="#modelos-llm-utilizados" id="toc-modelos-llm-utilizados" class="nav-link" data-scroll-target="#modelos-llm-utilizados">2.2. Modelos LLM utilizados</a></li>
  <li><a href="#puntos-de-entrada-y-funciones-clave" id="toc-puntos-de-entrada-y-funciones-clave" class="nav-link" data-scroll-target="#puntos-de-entrada-y-funciones-clave">2.3. Puntos de entrada y funciones clave</a></li>
  </ul></li>
  <li><a href="#guía-de-entrenamiento-y-mejora" id="toc-guía-de-entrenamiento-y-mejora" class="nav-link" data-scroll-target="#guía-de-entrenamiento-y-mejora">3. Guía de entrenamiento y mejora</a>
  <ul class="collapse">
  <li><a href="#generación-de-la-base-de-datos-vectorial" id="toc-generación-de-la-base-de-datos-vectorial" class="nav-link" data-scroll-target="#generación-de-la-base-de-datos-vectorial">3.1. Generación de la base de datos vectorial</a></li>
  <li><a href="#flujo-de-la-interacción" id="toc-flujo-de-la-interacción" class="nav-link" data-scroll-target="#flujo-de-la-interacción">3.2. Flujo de la interacción</a></li>
  <li><a href="#recomendaciones-para-futura-mejora" id="toc-recomendaciones-para-futura-mejora" class="nav-link" data-scroll-target="#recomendaciones-para-futura-mejora">3.3. Recomendaciones para futura mejora</a></li>
  </ul></li>
  <li><a href="#arquitectura-del-sistema" id="toc-arquitectura-del-sistema" class="nav-link" data-scroll-target="#arquitectura-del-sistema">4. Arquitectura del sistema</a>
  <ul class="collapse">
  <li><a href="#componentes-clave-de-conversación-y-chat" id="toc-componentes-clave-de-conversación-y-chat" class="nav-link" data-scroll-target="#componentes-clave-de-conversación-y-chat">4.1. Componentes clave de conversación y chat</a></li>
  <li><a href="#componentes-clave-de-documentos-y-soluciones" id="toc-componentes-clave-de-documentos-y-soluciones" class="nav-link" data-scroll-target="#componentes-clave-de-documentos-y-soluciones">4.2. Componentes clave de documentos y soluciones</a></li>
  <li><a href="#componentes-clave-de-tickets" id="toc-componentes-clave-de-tickets" class="nav-link" data-scroll-target="#componentes-clave-de-tickets">4.3. Componentes clave de tickets</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Documentación</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="manual-de-instalación-y-despliegue" class="level2" style="text-align: justify">
<h2 class="anchored" data-anchor-id="manual-de-instalación-y-despliegue">1. Manual de instalación y despliegue</h2>
<section id="configuraciones-importantes" class="level3">
<h3 class="anchored" data-anchor-id="configuraciones-importantes">1.1. Configuraciones importantes</h3>
<ul>
<li>El proyecto está diseñado para ser desplegado en entornos <strong>Linux</strong> o <strong>Windows</strong> con Python <code>3.12.9</code>. Requiere acceso a <strong>Ollama</strong> (para la ejecución de modelos open-source), así como conectividad a una instancia de <strong>MongoDB</strong> para el registro del historial de conversaciones y tickets.</li>
<li>La aplicación backend se expone a través de <strong>FastAPI</strong> en el puerto 8000. Es crucial asegurar que este puerto esté abierto y accesible en el entorno de despliegue.</li>
<li>Todas las credenciales y configuraciones sensibles se gestionan mediante un archivo de variables de entorno (<code>.env</code>), garantizando la seguridad y facilidad de configuración.</li>
</ul>
</section>
<section id="requisitos-del-sistema" class="level3">
<h3 class="anchored" data-anchor-id="requisitos-del-sistema">1.2. Requisitos del sistema</h3>
<ul>
<li><strong>CUDA</strong>: Tarjeta de video y con drivers actualizados en el ambiente.</li>
<li><strong>Python</strong>: Versión 3.12.9.</li>
<li><strong>Pip</strong>: Última versión.</li>
<li><strong>UV</strong>: Última versión (gestor de paquetes y entornos).</li>
<li><strong>Ollama</strong>: Instalado y en ejecución en el servidor para el hosting de modelos open-source.</li>
<li><strong>MongoDB</strong>: Acceso remoto configurado para las colecciones de historial de conversaciones y tickets.</li>
<li><strong>Podman</strong>: Herramienta de virtualización y contenedores sin daemon; utilizado para correr MongoDB.</li>
</ul>
</section>
<section id="dependencias-principales-del-sistema" class="level3">
<h3 class="anchored" data-anchor-id="dependencias-principales-del-sistema">1.3. Dependencias principales del sistema</h3>
<ul>
<li><strong>FastAPI</strong> y <strong>Uvicorn</strong>: Utilizados para construir y servir la <strong>API web</strong> que expone los endpointsmdel <em>chatbot</em> y la gestión de documentos. Permiten crear una interfaz robusta y asíncrona.</li>
<li><strong>Ollama (Python Client)</strong>: Librería cliente para interactuar con el servicio <strong>Ollama</strong>, que hospeda y ejecuta los modelos de lenguaje <em>open-source</em> (<code>gemma:4b</code>) y de <em>embeddings</em> (<code>bge-m3:latest</code>) localmente.</li>
<li><strong>Pymongo</strong>: El controlador oficial de Python para <strong>MongoDB</strong>. Es esencial para interactuar con la base de datos donde se almacena el <strong>historial de conversaciones</strong>, la información de los <strong>tickets</strong> y el registro de <strong>archivos procesados</strong>.</li>
<li><strong>FAISS (faiss-cpu)</strong>: Biblioteca desarrollada por Meta AI para la <strong>búsqueda eficiente de similitud</strong> y agrupamiento de vectores densos. Es el núcleo de la <strong>base de datos vectorial</strong> del sistema.</li>
<li><strong>UV</strong>: Gestor de paquetes y entornos virtuales, asegura la reproducibilidad del entorno.</li>
<li><strong>Otras dependencias</strong>: Todas las demás librerías requeridas se detallan en el archivo <code>pyproject.toml</code>. La instalación de este archivo se detalla más adelante.</li>
</ul>
</section>
<section id="instalación-del-sistema" class="level3">
<h3 class="anchored" data-anchor-id="instalación-del-sistema">1.4. Instalación del sistema</h3>
<ol type="1">
<li>Clonar el repositorio:</li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/anmerino-pnd/proyectoCenace</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> proyectoCenace</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="2" type="1">
<li>Configurar el entorno:</li>
</ol>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install uv</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> venv</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> .venv<span class="dt">\S</span>cripts<span class="dt">\a</span>ctivate</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># o `.venv\Scripts\activate` para Windows</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> pip install <span class="at">-e</span> .</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="3" type="1">
<li><p>Configurar Ollama:</p>
<p>Verifica que el servicio de Ollama esté instalado y activo, y que el modelo <code>gemma3:12b</code> y <code>bge-m3:latest</code> estén disponible.</p></li>
</ol>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">curl</span> <span class="at">-fsSL</span> https://ollama.com/install.sh <span class="kw">|</span> <span class="fu">sh</span> <span class="co"># Para instalar Ollama</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="ex">ollama</span> serve</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="ex">ollama</span> list <span class="co"># Para verificar que el modelo gemma3:12b esté descargado y listo</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="ex">ollama</span> pull gemma3:12b <span class="co"># Correr esta línea en caso que el modelo no aparezca</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="ex">ollama</span> pull bge-m3:latest</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="4" type="1">
<li><p>Configurar variables de entorno:</p>
<p>Antes de levantar el <em>backend</em>, asegurarse de que el archivo <code>.env</code> en la raíz del proyecto contenga las siguientes variables con sus valores correctos.</p></li>
</ol>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Servidor donde está corriendo Ollama</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>OLLAMA_BASE_URL<span class="op">=</span><span class="st">"http://localhost:11434"</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Conexión a MongoDB</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>MONGO_URI <span class="op">=</span> <span class="st">"mongodb://localhost:27017"</span> </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>DB_NAME <span class="op">=</span> <span class="st">"CENACE_LLM"</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="5" type="1">
<li>Preparar el backend:</li>
</ol>
<p>Con la ayuda de este comando arranca el contenedor de Mongo el cual es utilizado para guardar la información de las sesiones, conversaciones, documentos, etc.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">podman</span> run <span class="at">-d</span> <span class="at">--name</span> mongo <span class="dt">\</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">-p</span> 27017:27017 <span class="dt">\</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  docker.io/library/mongo:7.0</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Este comando inicia la API, especificando el número del puerto</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nohup</span> uvicorn cenacellm.API.main:app <span class="at">--reload</span> <span class="kw">&amp;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>El uso de <code>nogup</code> y <code>&amp;</code> asegura que el proceso continúe ejecutándose en segundo plano incluso si la sesión SSH se cierra.</p>
<ol start="7" type="1">
<li>Verificar logs:</li>
</ol>
<p>Al correr la API con <code>nohup</code>, este genera un archivo <code>nohup.out</code>, con el cual podemos ver los logs del sistema, para eso solo hay que ubicarse en donde está dicho archivo y correr lo siguiente:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span> <span class="at">-f</span> nohup.out</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="documentación-técnica-del-código" class="level2" style="text-align: justify">
<h2 class="anchored" data-anchor-id="documentación-técnica-del-código">2. Documentación técnica del código</h2>
<p>La solución se basa en una arquitectura de <strong>Recuperación Aumentada con Generación (RAG)</strong>. La estructura modular del código, organizada en paquetes de Python, permite una clara separación de responsabilidades.</p>
<section id="estructura-de-carpetas-y-módulos" class="level3">
<h3 class="anchored" data-anchor-id="estructura-de-carpetas-y-módulos">2.1. Estructura de carpetas y módulos</h3>
<p>El proyecto sigue una estructura modular para facilitar la gestión y el mantenimiento. A continuación, se detalla el propósito de los módulos y clases principales, además de sus funciones clave.</p>
<section id="documentos" class="level4">
<h4 class="anchored" data-anchor-id="documentos">2.1.1. Documentos</h4>
<section id="cenacellmdoccollection.py" class="level5">
<h5 class="anchored" data-anchor-id="cenacellmdoccollection.py"><strong>cenacellm/doccollection.py</strong></h5>
<ul>
<li><p><strong>Clases y funciones clave</strong></p>
<ul>
<li><code>class DisjointCollection(DocCollection)</code>:
<ul>
<li><code>__init__</code>:
<ul>
<li><strong>Propósito</strong>: Inicializar la configuración predeterminada para la segmentación de textos.</li>
<li><strong>Comportamiento</strong>: Establece el tamaño del fragmento (chunk_size) en 1500 caracteres y el solapamiento máximo (<code>max_overlap</code>) en 200 caracteres para asegurar continuidad entre segmentos.</li>
</ul></li>
<li><code>get_chunks() -&gt; list</code>:
<ul>
<li><strong>Propósito</strong>: Dividir uno o varios objetos de texto en fragmentos más pequeños basados en la configuración semántica definida.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>texts (Union[Text, List[Text]])</code>: Un objeto Text individual o una lista de objetos <code>Text</code> que contienen el contenido a fragmentar.</li>
</ul></li>
<li><strong>Retorna</strong>: Una lista de objetos <code>Text</code> donde cada elemento es un fragmento del contenido original, conservando los metadatos.</li>
<li><strong>Comportamiento</strong>: Utiliza <code>TextSplitter</code> para segmentar el contenido. Si la entrada es un solo texto, lo convierte en lista. Itera sobre los textos, genera los chunks y crea nuevos objetos <code>Text</code> heredando los metadatos del padre.</li>
</ul></li>
<li><code>load_pdf() -&gt; List[Text]</code>:
<ul>
<li><strong>Propósito</strong>: Leer un archivo PDF, extraer su contenido textual página por página y generar metadatos detallados.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>pdf_path (str)</code>: La ruta del archivo PDF a procesar.</li>
<li><code>collection (str)</code>: El nombre opcional de la colección a la que pertenecerá el documento.</li>
</ul></li>
<li><strong>Retorna</strong>: Una lista de objetos <code>Text</code>, donde cada objeto representa el contenido de una página del PDF.</li>
<li><strong>Comportamiento</strong>: Utiliza PdfReader para leer el archivo. Genera un ID de referencia único (<code>uuid4</code>). Extrae metadatos nativos del PDF y crea un diccionario de metadatos enriquecido para cada página (incluyendo número de página, total de páginas, nombre de archivo y referencia). Finalmente, instancia objetos <code>Text</code> con el contenido extraído y estos metadatos.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="embedder" class="level4">
<h4 class="anchored" data-anchor-id="embedder">2.1.2. Embedder</h4>
<section id="cenacellmollamaembedder.py" class="level5">
<h5 class="anchored" data-anchor-id="cenacellmollamaembedder.py"><strong>cenacellm/ollama/embedder.py</strong></h5>
<ul>
<li><p><strong>Clases y funciones clave</strong></p>
<ul>
<li><code>class OllamaEmbedder(Embedder)</code>:
<ul>
<li><code>__init__</code>:
<ul>
<li><strong>Propósito</strong>: Configurar el modelo de embeddings que se utilizará para la vectorización.</li>
<li><strong>Comportamiento</strong>: Define el modelo bge-m3:latest como el motor predeterminado para generar los vectores.</li>
</ul></li>
<li><code>vectorize() -&gt; NDarray</code>:
<ul>
<li><strong>Propósito</strong>: Convertir una cadena de texto en su representación vectorial numérica.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>s (str)</code>: La cadena de texto (prompt) que se desea vectorizar.</li>
</ul></li>
<li><strong>Retorna</strong>: Un arreglo de NumPy (<code>np.array</code>) con tipo de dato <code>float32</code> que representa el embedding del texto.</li>
<li><strong>Comportamiento</strong>: Realiza una llamada a la API de Ollama utilizando el modelo configurado y retorna el vector resultante extraído de la respuesta.</li>
</ul></li>
<li><code>vectorize_batch() -&gt; list[np.ndarray]</code>:
<ul>
<li><strong>Propósito</strong>: Generar embeddings para una lista de textos múltiples en secuencia.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>texts (list[str])</code>: Lista de cadenas de texto a vectorizar.</li>
</ul></li>
<li><strong>Retorna</strong>: Una lista de arreglos de NumPy, correspondientes a los vectores de cada texto de entrada.</li>
<li><strong>Comportamiento</strong>: Itera sobre la lista de textos proporcionada y llama al método <code>vectorize</code> para cada elemento individualmente, acumulando los resultados.</li>
</ul></li>
<li><code>dim() -&gt; int</code>:
<ul>
<li><strong>Propósito</strong>: Obtener la dimensión del espacio vectorial generado por el modelo</li>
<li><strong>Retorna</strong>: Un entero que representa la longitud del vector (número de dimensiones).</li>
<li><strong>Comportamiento</strong>: Vectoriza una palabra de prueba (“Hola”) y calcula la longitud del arreglo resultante para determinar la dimensionalidad del modelo.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="vector-store" class="level4">
<h4 class="anchored" data-anchor-id="vector-store">2.1.3. Vector Store</h4>
<section id="cenacellmvectorstore.py" class="level5">
<h5 class="anchored" data-anchor-id="cenacellmvectorstore.py"><strong>cenacellm/vectorstore.py</strong></h5>
<ul>
<li><p><strong>Clases y funciones clave</strong></p>
<ul>
<li><code>class FAISSVectorStore(VectorStore)</code>:
<ul>
<li><code>__init__</code>:
<ul>
<li><strong>Propósito</strong>: Inicializar el índice de búsqueda vectorial (FAISS) y cargar datos persistentes si existen.</li>
<li><strong>Comportamiento</strong>: Verifica si existe un índice previo en disco. Si existe, lo carga (intentando usar GPU si es posible) junto con el diccionario de textos (<code>pickle</code>). Si no, crea un índice <code>IndexFlatL2</code> nuevo.</li>
</ul></li>
<li><code>get_similar() -&gt; list</code>:
<ul>
<li><strong>Propósito</strong>: Realizar una búsqueda de similitud semántica en el índice vectorial.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>v (np.ndarray)</code>: El vector de consulta (query embedding).</li>
<li><code>k (int)</code>: Número de vecinos más cercanos a recuperar (por defecto 10).</li>
<li><code>filter_metadata (Dict[str, str])</code>: Filtros opcionales para restringir la búsqueda (ej. por colección).</li>
</ul></li>
<li><strong>Retorna</strong>: Una lista de tuplas <code>(vector, texto)</code> con los resultados más relevantes.</li>
<li><strong>Comportamiento</strong>: Ejecuta <code>index.search</code> y filtra los resultados basándose en los metadatos proporcionados y la validez de los índices recuperados.</li>
</ul></li>
<li><code>add_text() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Añadir un único vector y su texto asociado al índice.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>v (np.ndarray)</code>: El vector a añadir.</li>
<li><code>t (Text)</code>: El objeto de texto asociado.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Añade el vector al índice FAISS y almacena el par <code>(vector, texto)</code> en el diccionario en memoria.</li>
</ul></li>
<li><code>add_texts() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Añadir un lote de vectores y textos al índice de manera eficiente.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>vectors (list[np.ndarrar])</code>: Lista de vectores.</li>
<li><code>chunks (list[Text])</code>: Lista de objetos de texto correspondientes.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Apila los vectores en una matriz <code>numpy</code> y los añade al índice en una sola operación, actualizando luego el diccionario secuencialmente.</li>
</ul></li>
<li><code>save_index() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Persistir el estado actual del índice y los textos en disco.</li>
<li><strong>Comportamiento</strong>: Escribe el índice FAISS en un archivo .faiss y serializa el diccionario de textos en un archivo .pkl.</li>
</ul></li>
<li><code>distance() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Calcular la distancia euclidiana entre dos vectores.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>v1 (np.ndarrar)</code>: Primer vector.</li>
<li><code>v2 (np.ndarrar)</code>: Segundo vector.</li>
</ul></li>
<li><strong>Retorna</strong>: Un valor flotante representando la distancia (norma L2).</li>
</ul></li>
<li><code>delete() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Eliminar un elemento específico del índice por su ID interno.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>idx (int)</code>: Índice numérico del elemento a eliminar.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Elimina la entrada del diccionario y remueve el ID del índice FAISS.</li>
</ul></li>
<li><code>update_metadata() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Actualizar los metadatos de un texto ya indexado.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>idx (int)</code>: Índice del elemento.</li>
<li><code>new_metadata (Dict[str, str])</code>: Diccionario con los valores a actualizar.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Crea una copia del objeto <code>Text</code> y <code>TextMetadata</code> con los nuevos valores y actualiza la referencia en el diccionario.</li>
</ul></li>
<li><code>delete_by_reference() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Eliminar todos los vectores asociados a un documento específico.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>reference_id (str)</code>: UUID del documento a eliminar.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Itera sobre el diccionario para encontrar todos los índices que coincidan con la referencia y los elimina tanto del diccionario como del índice FAISS.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="agente" class="level4">
<h4 class="anchored" data-anchor-id="agente">2.1.4. Agente</h4>
<section id="cenacellmollamaassistant.py" class="level5">
<h5 class="anchored" data-anchor-id="cenacellmollamaassistant.py"><strong>cenacellm/ollama/assistant.py</strong></h5>
<ul>
<li><p><strong>Clases y funciones clave</strong></p>
<ul>
<li><code>class OllamaAssistant(Assistant)</code>:
<ul>
<li><code>__init__</code>:
<ul>
<li><strong>Propósito</strong>: Configurar la conexión a MongoDB y definir el modelo LLM (<code>gemma3:4b</code>).</li>
<li><strong>Comportamiento</strong>: Establece la conexión con la base de datos, selecciona las colecciones y crea índices para consultas eficientes.</li>
</ul></li>
<li><code>load_history() -&gt; list</code>:
<ul>
<li><strong>Propósito</strong>: Recuperar el historial de chat de una conversación.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>conversation_id (str)</code>: ID de la conversación.</li>
</ul></li>
<li><strong>Retorna</strong>: Lista de mensajes (diccionarios).</li>
<li><strong>Comportamiento</strong>: Consulta MongoDB filtrando por usuario y conversación.</li>
</ul></li>
<li><code>save_history() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Guardar o actualizar el historial de una conversación.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>conversation_id (str)</code>: ID de la conversación.</li>
<li><code>history (list)</code>: Lista actualizada de mensajes.</li>
<li><code>conversation_title (Optional[str])</code>: Título opcional para la conversación.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Realiza una operación <code>update_one</code> con <code>upsert=True</code> en MongoDB, actualizando mensajes, fecha de modificación y título si se provee.</li>
</ul></li>
<li><code>save_backup() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Guardar un respaldo incremental del historial.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>history_chunk (list)</code>: Fragmento de mensajes a respaldar.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Hace un <code>push</code> de los nuevos mensajes a una colección de respaldo separada.</li>
</ul></li>
<li><code>clear_conversation_history() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Limpiar los mensajes de una conversación sin borrar el registro de la misma.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>conversation_id (str)</code>: ID de la conversación.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Establece el campo <code>messages</code> como una lista vacía en MongoDB.</li>
</ul></li>
<li><code>delete_conversation() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Eliminar completamente una conversación.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>conversation_id (str)</code>: ID de la conversación.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Elimina el documento completo de la colección de conversaciones.</li>
</ul></li>
<li><code>make_metadata() -&gt; CallMetadata</code>:
<ul>
<li><strong>Propósito</strong>: Estructurar los metadatos de una llamada al LLM.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>response (GenerateResponse)</code>: Objeto de respuesta de Ollama.</li>
<li><code>duration (float)</code>: Tiempo de ejecución.</li>
<li><code>references</code>: Chunks utilizados como contexto.</li>
</ul></li>
<li><strong>Retorna</strong>: Objeto <code>CallMetadata</code> estandarizado.</li>
</ul></li>
<li><code>answer() -&gt; Tuple[Generator[str, None, None], str, Dict[str, Any]]</code>:
<ul>
<li><strong>Propósito</strong>: Generar una respuesta del asistente utilizando contexto y streaming.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>question (Question)</code>: Pregunta del usuario.</li>
<li><code>chunks (Chunks)</code>: Contexto recuperado.</li>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>conversation_id (str)</code>: ID de la conversación.</li>
</ul></li>
<li><strong>Retorna</strong>: Un generador de tokens, el ID del mensaje del bot y los metadatos finales.</li>
<li><strong>Comportamiento</strong>: Construye el prompt con historial y contexto, llama a api.generate en modo stream, acumula tokens, y al finalizar guarda el turno en el historial y calcula metadatos.</li>
</ul></li>
<li><code>update_message_metadata() -&gt; bool</code>:
<ul>
<li><strong>Propósito</strong>: Actualizar metadatos de un mensaje específico (ej. “like”).</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>message_id (str)</code>: ID del mensaje completo.</li>
<li><code>new_metadata (Dict[str, Any])</code>: Metadatos nuevos a actualizar.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Busca el mensaje en el historial del usuario y actualiza sus campos de metadatos en MongoDB.</li>
</ul></li>
<li><code>get_liked_solutions() -&gt; List[Dict[str, Any]]</code>:
<ul>
<li><strong>Propósito</strong>: Obtener todas las respuestas marcadas como útiles (“liked”) por el usuario.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
</ul></li>
<li><strong>Retorna</strong>: Lista de pares pregunta-respuesta útiles.</li>
<li><strong>Comportamiento</strong>: Itera sobre todas las conversaciones del usuario buscando mensajes con <code>metadata.disable = True</code>.</li>
</ul></li>
<li><code>get_user_conversations() -&gt; List[Dict[str, Any]]</code>:
<ul>
<li><strong>Propósito</strong>: Listar las conversaciones activas del usuario.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
</ul></li>
<li><strong>Retorna</strong>: Lista con ID, título y fecha de actualización.</li>
<li><strong>Comportamiento</strong>: Consulta MongoDB proyectando solo los campos necesarios y ordenando por fecha. Genera un título por defecto si no existe.</li>
</ul></li>
<li><code>has_liked_solution_in_conversation() -&gt; bool</code>:
<ul>
<li><strong>Propósito</strong>: Verificar si una conversación contiene soluciones validadas.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>conversation_id (str)</code>: ID de la conversación.</li>
</ul></li>
<li><strong>Retorna</strong>: <code>True</code> si existe al menos un mensaje “liked”.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="rag" class="level4">
<h4 class="anchored" data-anchor-id="rag">2.1.5. RAG</h4>
<section id="cenacellmrag.py" class="level5">
<h5 class="anchored" data-anchor-id="cenacellmrag.py"><strong>cenacellm/rag.py</strong></h5>
<ul>
<li><p><strong>Clases y funciones clave</strong></p>
<ul>
<li><code>class RAG</code>:
<ul>
<li><code>__init__</code>:
<ul>
<li><strong>Propósito</strong>: Orquestar todos los componentes del sistema (Assistant, Embedder, VectorStore, DB).</li>
<li><strong>Comportamiento</strong>: Inicializa las instancias, conecta a MongoDB, carga cachés de archivos procesados y configura índices únicos en la base de datos.</li>
</ul></li>
<li><code>_load_processed_files() -&gt; Dict[str, Any]</code>:
<ul>
<li><strong>Propósito</strong>: Cargar en memoria el registro de archivos ya procesados para evitar re-procesamiento.</li>
<li><strong>Retorna</strong>: Diccionario mapeando claves de archivo a sus metadatos.</li>
</ul></li>
<li><code>_save_processed_files() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Persistir el estado de los archivos procesados en MongoDB.</li>
</ul></li>
<li><code>_delete_processed_file() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Eliminar registros de archivos procesados de la base de datos y memoria.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>file_key (List[str])</code>: ID del documento procesado en MongoDB.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Cargar IDs de soluciones ya indexadas para evitar duplicados.</li>
</ul></li>
<li><code>_load_processed_solutions_ids() -&gt; set</code>:
<ul>
<li><strong>Propósito</strong>: Cargar IDs de soluciones ya indexadas para evitar duplicados.</li>
</ul></li>
<li><code>_add_processed_solution_id() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Registrar una nueva solución como procesada en MongoDB.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>message_id (str)</code>: ID del documento del mensaje en MongoDB.</li>
</ul></li>
</ul></li>
<li><code>load_documents() -&gt; list</code>:
<ul>
<li><strong>Propósito</strong>: Procesar una carpeta de PDFs e indexarlos.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>folder_path (str)</code>: Ruta de los archivos.</li>
<li><code>collection_name (str)</code>: Nombre de la colección lógica.</li>
<li><code>force_reload (bool)</code>: Forzar re-procesamiento si ya existen.</li>
</ul></li>
<li><strong>Retorna</strong>: Estadísticas [docs_totales, nuevos_docs, chunks_totales]</li>
<li><strong>Comportamiento</strong>: Lee PDFs, verifica cambios (tamaño/fecha), fragmenta, vectoriza por lotes, guarda en vectorstore y actualiza el registro de archivos procesados.</li>
</ul></li>
<li><code>query() -&gt; Tuple[Generator[str, None, None], List, str, Dict[str, Any]]</code>:
<ul>
<li><strong>Propósito</strong>: Ejecutar la lógica de recuperación y llamada al asistente (núcleo del RAG).</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>conversation_id (str)</code>: ID de la conversación.</li>
<li><code>question (str)</code>: Consulta del usuario.</li>
<li><code>k (int)</code>: Número de chunks a recuperar.</li>
<li><code>filter_metadata (Optional[Dict[str, Any]])</code>: Filtros de búsqueda.</li>
</ul></li>
<li><strong>Retorna</strong>: Generador de tokens, chunks usados, ID del mensaje y metadatos.</li>
<li><strong>Comportamiento</strong>: Vectoriza la pregunta, busca en el vectorstore (balanceando documentos y soluciones si no hay filtro), y delega la generación al <code>assistant</code>.</li>
</ul></li>
<li><code>answer() -&gt; Generator[Union[str, Dict[str, Any]], None, None]</code>:
<ul>
<li><strong>Propósito</strong>: Wrapper sobre <code>query</code> para exponer una interfaz de streaming unificada.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>conversation_id (str)</code>: ID de la conversación.</li>
<li><code>question (str)</code>: Consulta del usuario.</li>
<li><code>k (int)</code>: Número de chunks a recuperar.</li>
<li><code>filter_metadata (Optional[Dict[str, Any]])</code>: Filtros de búsqueda.</li>
</ul></li>
<li><strong>Retorna</strong>: Generador que emite tokens de texto y finalmente un JSON con metadatos.</li>
</ul></li>
<li><code>delete_conversation() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Eliminar una conversación y desvincular tickets asociados</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
<li><code>conversation_id (str)</code>: ID de la conversación.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Llama a <code>assistant.delete_conversation</code> y actualiza tickets en MongoDB poniendo su <code>solucion_id</code> en <code>None</code>.</li>
</ul></li>
<li><code>add_liked_solutions_to_vectorstore() -&gt; int</code>:
<ul>
<li><strong>Propósito</strong>: Convertir interacciones exitosas en nuevo conocimiento vectorial.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>user_id (str)</code>: ID del usuario.</li>
</ul></li>
<li><strong>Retorna</strong>: Cantidad de soluciones añadidas.</li>
<li><strong>Retorna</strong>: Obtiene soluciones “liked”, verifica si ya existen, extrae metadatos, crea nuevos objetos <code>Text</code> y los indexa en el vectorstore.</li>
</ul></li>
<li><code>delete_from_vectorstore() -&gt; None</code>:
<ul>
<li><strong>Propósito</strong>: Eliminar documentos o soluciones del índice vectorial.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>reference_id (str)</code>: ID del vector almacenado en la base de datos vectorial.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Toma un índice del vector objetivo, lo busca en el archivo indexado y lo elimina.</li>
</ul></li>
<li><code>get_tickets() -&gt; List</code>:
<ul>
<li><strong>Propósito</strong>: Obtener todos los tickets con su estado de resolución.</li>
<li><strong>Comportamiento</strong>: Consulta MongoDB y calcula dinámicamente el campo <code>is_solved</code>.</li>
</ul></li>
<li><code>add_ticket() -&gt; Dict</code>:
<ul>
<li><strong>Propósito</strong>: Obtener todos los tickets con su estado de resolución.</li>
<li><strong>Comportamiento</strong>: Consulta MongoDB y calcula dinámicamente el campo <code>is_solved</code>.</li>
</ul></li>
<li><code>update_ticket_metadata() -&gt; bool</code>:
<ul>
<li><strong>Propósito</strong>: Modificar campos de un ticket existente.</li>
<li><strong>Parámetros</strong>:
<ul>
<li><code>ticket_reference (str)</code>: ID del ticket almacenado en MongoDB.</li>
<li><code>new_metadata (Dict[str, Any])</code>: Nuevos metadatos a actualizar.</li>
</ul></li>
<li><strong>Comportamiento</strong>: Actualiza los metadatos de un ticket específico en la base de datos basado en su ‘reference’.</li>
</ul></li>
<li><code>get_ticket_by_conversation() -&gt; Optional[Dict]</code>:
<ul>
<li><strong>Propósito</strong>: Encontrar el ticket asociado a una conversación activa.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="api" class="level4">
<h4 class="anchored" data-anchor-id="api">2.1.6. API</h4>
<section id="cenacellmapichat.py" class="level5">
<h5 class="anchored" data-anchor-id="cenacellmapichat.py"><strong>cenacellm/API/chat.py</strong></h5>
<p>Esta capa actúa como lógica de negocio intermedia entre FastAPI y el sistema RAG.</p>
<ul>
<li><p><strong>Clases y funciones clave</strong></p></li>
<li><p><code>class QueryRequest</code>: Modelo de datos para la solicitud de chat (<code>user_id</code>, <code>query</code>, <code>conversation_id</code>, etc.).</p></li>
<li><p><code>class UpdateMetadataRequest</code>: Modelo para actualizar metadatos (ej. likes).</p></li>
<li><p><code>class CreateConversationRequest</code>: Modelo para iniciar conversaciones (<code>title opcional</code>).</p></li>
<li><p><code>class AddTicketRequest</code>: Modelo para creación de tickets.</p></li>
<li><p><code>async_chat_stream() -&gt; StreamingResponse</code>:</p>
<ul>
<li><strong>Propósito</strong>: Iniciar el flujo de respuesta del chat.</li>
<li><strong>Comportamiento</strong>: Llama a <code>rag.answer</code> y devuelve un <code>StreamingResponse</code> para envío en tiempo real.</li>
</ul></li>
<li><p><code>load_documents(), get_preprocessed_files()</code>: Wrappers para exponer funciones del RAG.</p></li>
<li><p><code>upload_documents() -&gt; Dict</code>:</p>
<ul>
<li><strong>Propósito</strong>: Guardar archivos físicos en el servidor.</li>
<li><strong>Comportamiento</strong>: Recibe <code>UploadFile</code>, escribe en disco y retorna estado.</li>
</ul></li>
<li><p><code>delete_document() -&gt; Dict</code>:</p>
<ul>
<li><strong>Propósito</strong>: Orquestar la eliminación de documentos.</li>
<li><strong>Comportamiento</strong>: Elimina del vectorstore (vía RAG) y borra el archivo físico del disco.</li>
</ul></li>
<li><p><code>process_liked_solutions_to_vectorstore()</code>: Dispara la re-indexación de soluciones útiles.</p></li>
<li><p><code>delete_solution_by_reference()</code>: Elimina soluciones aprendidas del vectorstore.</p></li>
</ul>
</section>
<section id="cenacellmapimain.py" class="level5">
<h5 class="anchored" data-anchor-id="cenacellmapimain.py"><strong>cenacellm/API/main.py</strong></h5>
<p>Aquí se encuentra el main de todo el sistema y las llamadas FastAPI…</p>
<ul>
<li><p><strong>Clases y funciones clave</strong></p>
<ul>
<li><code>POST/chat</code>: Inicia la generación de respuesta en streaming.</li>
<li><code>GET /history/{user_id}/{conversation_id}</code>: Devuelve el historial de mensajes.</li>
<li><code>DELETE /history/{user_id}/{conversation_id}</code>: Borra el historial de una conversación.</li>
<li><code>POST /upload_documents</code>: Sube archivos PDF al servidor.</li>
<li><code>POST /load_documents</code>: Dispara el procesamiento e indexación de los PDFs subidos.</li>
<li><code>POST /delete_document</code>: Elimina documentos procesados.</li>
<li><code>PATCH /history/{user_id}/messages/{message_id}</code>: Actualiza metadatos (usado para dar like).</li>
<li><code>POST /process_liked_solutions/{user_id}</code>: Convierte likes en conocimiento vectorial.</li>
<li><code>GET /conversations/{user_id}</code>: Lista conversaciones del usuario.</li>
<li><code>POST /new_conversation</code>: Crea una nueva sesión de chat.</li>
<li><code>POST /delete_conversation</code>: Elimina una sesión.</li>
<li><code>GET /tickets</code> y <code>POST /tickets</code>: Gestión de tickets de soporte.</li>
<li><code>GET /</code>: Sirve la interfaz de usuario (UI) renderizando index.html.</li>
</ul></li>
</ul>
</section>
</section>
</section>
<section id="modelos-llm-utilizados" class="level3">
<h3 class="anchored" data-anchor-id="modelos-llm-utilizados">2.2. Modelos LLM utilizados</h3>
<p>El flujo de información en el sistema RAG sigue dos rutas principales:</p>
<ol type="1">
<li>Indexación de documentos:</li>
</ol>
<ul>
<li>Los archivos PDF son cargados y procesados por el módulo <code>doccollection.py</code>.</li>
<li><code>doccollection</code> divide cada documento en fragmentos.</li>
<li>Cada fragmento es enviado al que se encuentra en <code>embedder.py</code> y el modelo <code>bge-m3</code> genera su representación vectorial.</li>
<li>Los vectores resultantes se almacenan en la base de datos vectorial de FAISS, implementada en <code>vectorstore.py</code>, junto con sus metadatos.</li>
</ul>
<ol start="2" type="1">
<li>Proceso de consulta (QA):</li>
</ol>
<ul>
<li>Una consulta de usuario llega el <em>endpoint</em> de <code>chat.py</code>.</li>
<li>La consulta es vectorizada por el <code>embedder</code>.</li>
<li>El <code>vectorstore</code> realiza una búsqueda de similitud semántica para recuperar los fragmentos de documento más relevantes.</li>
<li>Estos fragmentos se envían al <code>assistant.py</code>, que los utiliza como contexto.</li>
<li>El <code>assistant</code> utiliza el LLM (<code>gemma3:4b</code>) para generar una respuesta coherente y contextualizada.</li>
<li>La respuesta es devuelta al usuario a través del <code>chat.py</code> y el <code>main.py</code>.</li>
</ul>
</section>
<section id="puntos-de-entrada-y-funciones-clave" class="level3">
<h3 class="anchored" data-anchor-id="puntos-de-entrada-y-funciones-clave">2.3. Puntos de entrada y funciones clave</h3>
<ul>
<li><strong>Gestión de conversaciones:</strong> El módulo <code>assistant.py</code> gestiona el historial de conversación en MongoDB, permitiendo que el chatbot mantenga un contexto limitado con el usuario.</li>
<li><strong>Gestión de tickets:</strong> Las funciones <code>add_ticket</code> y <code>update_ticket_metadata</code> en <code>rag.py</code> y sus respectivos <em>endpoints</em> en <code>chat.py</code> demuestran la capacidad del sistema para interactuar y actualizar una base de datos de tickets.</li>
<li><strong>Bucle de retroalimentación:</strong> La funcionalidad <code>has_liked_solution_in_conversation</code> permite identificar y potencialmente re-indexar soluciones validadas por los usuarios, mejorando continuamente la base de conocimientos.</li>
</ul>
</section>
</section>
<section id="guía-de-entrenamiento-y-mejora" class="level2" style="text-align: justify">
<h2 class="anchored" data-anchor-id="guía-de-entrenamiento-y-mejora">3. Guía de entrenamiento y mejora</h2>
<section id="generación-de-la-base-de-datos-vectorial" class="level3">
<h3 class="anchored" data-anchor-id="generación-de-la-base-de-datos-vectorial">3.1. Generación de la base de datos vectorial</h3>
<p>La base de conocimientos del chatbot se construye a partir de un proceso que comprende la extracción, segmentación y vectorización del contenido textual proveniente de documentos en formato PDF.</p>
<p>Los vectores resultantes son posteriormente indexados y almacenados en una base de datos vectorial, la cual constituye el núcleo de la recuperación de información relevante durante las interacciones con el chatbot.</p>
</section>
<section id="flujo-de-la-interacción" class="level3">
<h3 class="anchored" data-anchor-id="flujo-de-la-interacción">3.2. Flujo de la interacción</h3>
<p>El usuario debe acceder a la pestaña <strong>Documentos</strong>, donde podrá seleccionar los archivos que desea incorporar a la base de conocimientos del sistema. Una vez elegidos, los documentos <strong>se suben a la carpeta</strong> correspondiente dentro del entorno donde se encuentra desplegado el sistema (backend). Posteriormente, estos archivos son procesados siguiendo el flujo descrito en el apartado anterior, dando como resultado la creación de la base vectorial o base de conocimientos del sistema.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./datos/sesion_documentos.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Generación de la base de datos vectorial</figcaption>
</figure>
</div>
</section>
<section id="recomendaciones-para-futura-mejora" class="level3">
<h3 class="anchored" data-anchor-id="recomendaciones-para-futura-mejora">3.3. Recomendaciones para futura mejora</h3>
<ol type="1">
<li><strong>Lectura de documentos escaneados</strong></li>
</ol>
<p>Actualmente, el sistema <strong>no puede extraer información de documentos escaneados</strong>. Sería recomendable integrar un módulo de <strong>Reconocimiento Óptico de Caracteres (OCR)</strong> para ampliar la capacidad de análisis, o de igual manera, <strong>Modelo Multimodales</strong> que pudieran extraer la información y almacenarla en documentos PDF que sean posteriormente vectorizados.</p>
<ol start="2" type="1">
<li><strong>Sistema de seguridad para el inicio de sesión</strong></li>
</ol>
<p>El mecanismo de inicio de sesión actual es básico, pues solo requiere ingresar el nombre del usuario.</p>
<p>Aunque esta simplicidad se ajusta al alcance inicial del proyecto, se sugiere incorporar un sistema de autenticación más robusto, que garantice la seguridad de acceso y manejo de información.</p>
<ol start="3" type="1">
<li><strong>Sistema de corrección de ortografía</strong></li>
</ol>
<p>Durante el desarrollo de los modelos de clasificación, se identificó que la falta de ortografía en los tickets afectaba la calidad del análisis.</p>
<p>Se propuso el desarrollo de un sistema tipo journalist capaz de identificar <a href="https://en.wikipedia.org/wiki/Five_Ws">las 5 W’s</a> y reconstruir el contexto completo del texto, corrigiendo iterativamente los errores ortográficos al momento de cargar los datos.</p>
</section>
</section>
<section id="arquitectura-del-sistema" class="level2" style="text-align: justify">
<h2 class="anchored" data-anchor-id="arquitectura-del-sistema">4. Arquitectura del sistema</h2>
<p>El siguiente diagrama ilustra la arquitectura general del ssitema del chatbot, mostrando los componentes principales y el flujo de datos desde la interacción del usuario hasta la generación de respuestas y el almacenamiento del historial.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./datos/image.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Arquitectura del sistema</figcaption>
</figure>
</div>
<section id="componentes-clave-de-conversación-y-chat" class="level3">
<h3 class="anchored" data-anchor-id="componentes-clave-de-conversación-y-chat">4.1. Componentes clave de conversación y chat</h3>
<ul>
<li><p><code>POST /chat/stream</code>: Endpoint principal para la interacción conversacional. Recibe una consulta y un <code>conversation_id</code>, y devuelve una respuesta generada por el LLM en tiempo real a través de un stream.</p></li>
<li><p><code>GET /chat/history/{user_id}/{conversation_id}</code>: Recupera el historial de mensajes de una conversación específica.</p></li>
<li><p><code>POST /conversations</code>: Crea una nueva conversación, generando un <code>conversation_id</code> único.</p></li>
<li><p><code>GET /conversations/{user_id}</code>: Lista todas las conversaciones de un usuario, incluyendo sus títulos y la fecha de la última actualización.</p></li>
<li><p><code>DELETE /conversations</code>: Elimina una conversación específica y su historial de la base de datos.</p></li>
<li><p><code>PATCH /message-metadata</code>: Permite actualizar los metadatos de un mensaje, utilizado para la funcionalidad de “gustar” una solución.</p></li>
</ul>
</section>
<section id="componentes-clave-de-documentos-y-soluciones" class="level3">
<h3 class="anchored" data-anchor-id="componentes-clave-de-documentos-y-soluciones">4.2. Componentes clave de documentos y soluciones</h3>
<ul>
<li><p><code>POST /documents</code>: Permite cargar nuevos archivos (en formato PDF) a la base de datos vectorial para expandir la base de conocimientos.</p></li>
<li><p><code>GET /documents</code>: Lista todos los documentos que han sido procesados y están disponibles para la consulta.</p></li>
<li><p><code>DELETE /documents</code>: Elimina un documento específico de la base de datos vectorial, eliminando también su referencia y los fragmentos asociados.</p></li>
<li><p><code>POST /solutions</code>: Procesa y re-indexa soluciones “gustadas” por los usuarios, agregándolas como nuevos documentos a la base de datos vectorial para mejorar la precisión del sistema.</p></li>
<li><p><code>DELETE /solutions</code>: Elimina una solución específica de la base de datos vectorial.</p></li>
</ul>
</section>
<section id="componentes-clave-de-tickets" class="level3">
<h3 class="anchored" data-anchor-id="componentes-clave-de-tickets">4.3. Componentes clave de tickets</h3>
<ul>
<li><p><code>GET /tickets</code>: Recupera una lista de todos los tickets almacenados en la base de datos de MongoDB.</p></li>
<li><p><code>POST /tickets</code>: Permite añadir un nuevo ticket a la base de datos, con campos como título, descripción y categoría.</p></li>
<li><p><code>PATCH /tickets/{ticket_reference}</code>: Actualiza los metadatos de un ticket existente, como su estado de solución (<code>is_solved</code>).</p></li>
</ul>
</section>
</section>



<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Volver arriba</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>