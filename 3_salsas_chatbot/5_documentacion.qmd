---
title: "Documentación"
format: 
  html:
    page-layout: article
toc-title: "Tabla de Contenidos"
toc: true
toc-depth: 5
---

::: {style="text-align: justify"}
## 1. Introducción al proyecto

Este proyecto se centra en el desarrollo de un chatbot inteligente para Salsas Castillo, diseñado para optimizar el acceso a información de ventas y finanzas, y mejorar la comunicación interna. El chatbot utiliza un sistema de recuperación aumentada con generación (RAG) y herramientas dinámicas para proporcionar respuestas precisas y relevantes, así como la capacidad de generar reportes financieros.

### Objetivos del proyecto

* **Automatizar consultas**: Permitir a los usuarios (operativos y no operativos) obtener información sobre ventas, productos y finanzas de manera rápida y eficiente a través de una interfaz conversacional en Telegram.
* **Mejorar la toma de decisiones**: Proporcionar análisis de datos financieros y de ventas en tiempo real, incluyendo la generación de reportes en PDF.
* **Optimizar la gestión de información**: Centralizar el acceso a datos transaccionales y consolidados, reduciendo la dependencia de consultas manuales.
* **Adaptación a nuevas tecnologías**: Implementar un sistema basado en LLMs y bases de datos vectoriales para un enfoque moderno y escalable.

### Impacto esperado

* Incremento en la eficiencia operativa al reducir el tiempo dedicado a la búsqueda manual de información.
* Mejora en la precisión de los datos y análisis disponibles para el personal.
* Facilitación de la toma de decisiones estratégicas basadas en información actualizada.

:::

::: {style="text-align: justify"}
## 2. Manual de instalación y despliegue

Esta sección detalla los requisitos, dependencias y pasos para la instalación y despliegue del chatbot de Salsas Castillo.

### 2.1. Configuraciones importantes 

* El backend del chatbot está desarrollado con **FastAPI** y se espera que se ejecute en un entorno con **Python 3.12**.
* Requiere conectividad a una instancia de **MongoDB** para la gestión de sesiones e historial, y a una base de datos **PostgreSQL** para datos financieros y de ventas.
* Utiliza modelos de lenguaje de **OpenAI** (requiere `OPENAI_API_KEY`) y potencialmente modelos *open-source* como `gemma3:4b` a través de **Ollama** para la moderación.
* Las credenciales sensibles se gestionan a través de un archivo `.env`.
* La integración con Telegram se realiza mediante webhooks y el `telegram_token` correspondiente.

### 2.2. Requisitos del sistema

* **Python**: Versión 3.x (se recomienda la versión utilizada en el desarrollo, ej., 3.12.9).
* **Pip/UV**: Última versión para la gestión de paquetes.
* **Ollama**: Instalado y en ejecución si se utilizan modelos open-source para moderación.
* **MongoDB**: Acceso remoto configurado para las colecciones de sesiones e historial de mensajes.
* **PostgreSQL**: Acceso remoto configurado para las bases de datos historial_facturas y financieroii.
* **Conexión a Internet**: Necesaria para interactuar con las APIs de OpenAI y Telegram.

### 2.3. Dependencias principales del sistema

* `fastapi`: Framework web para el backend.
* `langchain`: Framework principal para la orquestación del LLM y las herramientas.
* `openai`: Cliente Python para la API de OpenAI.
* `pymongo`: Driver para la interacción con MongoDB.
* `psycopg2-binary`: Adaptador PostgreSQL para Python.
* `fpdf`: Para la generación de PDFs.
* `requests`: Para realizar solicitudes HTTP (ej., a Telegram, OpenAI Whisper).
* `uvicorn/gunicorn`: Servidor WSGI para despliegue.
* `pydantic`: Para la validación de modelos de datos.
* `faiss-cpu`: Para la base de datos vectorial (si aplica para documentos internos).

### 2.4. Requisitos de configuración del backend

#### 2.4.1. Clonar el repositorio

```bash
git clone Macrodata-Analitica/castilloChatbot
cd castilloChatbot
```

#### 2.4.2. Crear entorno virtual e instalar dependencias

```bash
pip install uv # Si no está instalado
uv venv
source .venv/bin/activate # Linux/macOS
# o `.venv\Scripts\activate` para Windows
uv pip install -e .
uv sync # Sincroniza los modulos de src/
```

#### 2.4.3. Configurar variables de entorno `(.env)`

Asegúrate de que el archivo `.env` en la raíz del proyecto contenga las siguientes variables con sus valores correctos:

```bash
OPENAI_API_KEY=""

VERIFY_TOKEN=""
TELEGRAM_BOT_TOKEN=""
PHONE_NUMBER_ID=""

HOST=""
PORT=""
USER=""
PASS=""
DBNAME=""
SCHEMA=""
```

#### 2.4.4. Configurar Webhook de Telegram

Asegúrate de que Telegram envíe los mensajes a tu endpoint `/webhook`. Esto se hace una vez a través de la API de Telegram:

```
https://api.telegram.org/bot<TU_TELEGRAM_TOKEN>/setWebhook?url=https://<TU_DOMINIO>/webhook
```
Reemplaza TU_DOMINIO y TU_TELEGRAM_TOKEN.

En caso de no tener un Token de Telegram. es necesario buscar @FatherBot en Telegram. Después, iniciar conversación con `/start`. Luego, `/newbot`, en esta parte el sistema pedirá 2 nombres. Name es el nombre de despliegue del chatbot, se puede cambiar después. Username es el nombre único identificador del chatbot, este no se puede cambiar después.

En caso de ser necesario, se recomienda este tutorial en [Medium](https://medium.com/mcd-unison/pocket-ai-telegram-bot-python-ollama-01da2c4d05df
) donde se explica explicítamente cada paso. 

### 2.5 Arquitectura de despliegue continuo y sincronización
El servidor implementa un mecanismo adicional para mantener el backend del chatbot actualizado y funcionando de forma estable. Este mecanismo se basa en tres componentes:

- **El servicio principal del chatbot (`rag.service`)**
- **El servicio de despliegue (`rag-deploy.service`)**
- **El timer que activa el despliegue cada 30 segundos (`rag-deploy.timer`)**

Este sistema garantiza que:

- Si el repositorio cambia, el backend se actualiza automáticamente.
- Si el entorno Python necesita sincronizar dependencias, se hace sin intervención manual.
- Si el servicio falla o se detiene por cualquier motivo, systemd lo vuelve a levantar.

A continuación se explica cada pieza.

#### 2.5.1 Definición del servicio backend `rag.service`

Este servicio es el que ejecuta el backend de FastAPI mediante Uvicorn.
```
[Unit]
Description=Telegram Chat API (Uvicorn)
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
User=ctrlsalsasc
WorkingDirectory=/home/ctrlsalsasc/rag_v3
Environment=PYTHONUNBUFFERED=1
ExecStart=/bin/bash -lc 'uv sync && exec uv run uvicorn salsasllm.API.telegram_main:app --host 0.0.0.0 --port 8003'
Restart=always
RestartSec=5
StartLimitIntervalSec=60
StartLimitBurst=5
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
```
#### 2.5.2 Especificaciones operativas

- Usa `uv sync` antes de arrancar para garantizar dependencias correctas.
- Corre en el puerto interno **8003**, que Apache expone al público mediante reverse proxy.
- Se auto-reinicia si falla, asegurando alta disponibilidad.
- Los logs se consultan con `journalctl -u rag.service -f`.

#### 2.5.3 Servicio de actualización `rag-deploy.service`

Este servicio no se ejecuta de manera continua, sino que systemd lo invoca bajo demanda (a través del timer).

```
[Unit]
Description=Pull + uv sync + restart rag.service si hay cambios

[Service]
Type=oneshot
User=ctrlsalsasc
Environment=HEALTHCHECK_URL=http://127.0.0.1:8003/healthz
ExecStart=/usr/local/bin/rag_deploy.sh
```

#### 2.5.4. Lógica de ejecución del script

El script (`rag_deploy.sh`) realiza tareas como:

- `git fetch` → revisar si hay nuevos commits.
- Si hay cambios → `git pull` y `uv sync`.
- Reiniciar `rag.service` **solo si fue necesario** actualizar.
- Ejecutar un healthcheck contra `/healthz` para validar que el servicio levantó correctamente.

Este patrón es más robusto que un simple cron, porque systemd:

- Controla fallos.
- Registra logs.
- Evita ejecuciones simultáneas.
- Puede reintentar si algo sale mal.

---

#### 2.5.5 Programación del timer de sistema `rag-deploy.timer`

El timer configura cada cuánto debe ejecutarse el servicio anterior:
```
[Unit]
Description=Timer para rag-deploy.service (cada minuto)

[Timer]
OnUnitActiveSec=30s
AccuracySec=5s
Persistent=true

[Install]
WantedBy=timers.target
```

**Definiciones**

| Configuración         | Función                                                                                                  |
| --------------------- | -------------------------------------------------------------------------------------------------------- |
| `OnUnitActiveSec=30s` | Ejecuta el despliegue **30 segundos después** de la última ejecución → es decir, cada 30s continuamente. |
| `Persistent=true`     | Si el servidor estuvo apagado, ejecuta de inmediato lo que quedó pendiente.                              |
| `AccuracySec=5s`      | systemd puede adelantar o atrasar unos segundos para optimizar carga del sistema.                        |

**Comandos útiles**
Ver estado del timer:
```bash
systemctl status rag-deploy.timer
``` 
Ver cuándo se ejecutó la última vez:
```bash
systemctl list-timers | grep rag
``` 
Ver logs del despliegue:
```bash
journalctl -u rag-deploy.service -f
``` 
Forzar un despliegue manual:
```bash
sudo systemctl start rag-deploy.service
``` 
### 2.6 Infraestructura de red: Reverse proxy con Apache

El servidor utiliza Apache2 como reverse proxy para exponer los servicios del chatbot hacia Internet de forma segura a través de HTTPS. Esta configuración permite que los procesos internos de FastAPI, que corren localmente en puertos como 8003 o 8006, sean accesibles mediante rutas amigables bajo el dominio oficial de la empresa.

El archivo principal de configuración utilizado por el dominio seguro es:
`/etc/apache2/sites-enabled/default-ssl.conf`

**Reverse Proxy para el servicio Telegram Bot (Producción)**
```bash
# Telegram ChatBot
ProxyPreserveHost On
ProxyPass /tgbot http://127.0.0.1:8003/
ProxyPassReverse /tgbot http://127.0.0.1:8003/

RewriteEngine On
RewriteRule ^/tgbot(/.*)?$ http://127.0.0.1:8003$1 [P,L]

<Location tgbot>
    Require all granted
    AllowOverride None
</Location>
```

**Explicación del funcionamiento**

| Directiva                 | Función                                                                                                                                 |
|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------------|
| ProxyPreserveHost On      | Mantiene el header `Host` original enviado por el cliente. Esto permite que FastAPI identifique correctamente el dominio público.       |
| ProxyPass /tgbot …        | Todo lo que llegue a `https://apps.salsascastillo.com/tgbot` será enviado internamente al proceso de FastAPI que corre en `http://127.0.0.1:8003/`. |
| ProxyPassReverse          | Ajusta los encabezados de respuesta para que FastAPI no devuelva rutas internas.                                                       |
| RewriteEngine + RewriteRule | Se asegura de que todas las subrutas, como `/tgbot/webhook`, `/tgbot/logs`, etc., se redirijan correctamente al backend.              |
| Location               | Permite acceso público a la ruta (sin autenticación adicional).                                                                         |

Esta sección expone el servicio de Telegram en producción y es el endpoint donde se configura el webhook de Telegram:

`https://apps.salsascastillo.com/tgbot/webhook`

**Configuración SSL**
En la parte final del archivo se incluyen los certificados emitidos por Let’s Encrypt a través de Certbot:
```apache
SSLCertificateFile /etc/letsencrypt/live/apps.salsascastillo.com/fullchain.pem 
SSLCertificateKeyFile /etc/letsencrypt/live/apps.salsascastillo.com/privkey.pem 
Include /etc/letsencrypt/options-ssl-apache.conf
```
**Detalles importantes**

- `fullchain.pem` contiene la cadena completa del certificado, incluida la autoridad intermedia.
- `privkey.pem` es la llave privada del dominio (solo debe tener permisos 600 y dueño root).
- `options-ssl-apache.conf` aplica configuraciones modernas recomendadas por Let’s Encrypt (TLS, Cipher Suites, HSTS, etc.).

- La renovación ocurre automáticamente con el timer de Certbot (`/lib/systemd/system/certbot.timer`).

**Resumen del flujo**

1. El usuario envía una petición a:
`https://apps.salsascastillo.com/tgbot/...`
2. Apache la recibe sobre HTTPS.
3. Apache la redirige internamente al backend FastAPI:
`http://127.0.0.1:8003/...`
4. FastAPI procesa el mensaje y responde.
5. Apache reescribe los encabezados y envía la respuesta al cliente.

Este patrón es robusto, seguro y permite correr múltiples servicios simultáneamente sin exponer puertos internos a Internet.
:::

::: {style="text-align: justify"}
## 3. Documentación técnica del código
Esta sección describe la estructura modular del proyecto y las funciones clave de sus componentes.

### 3.1. Estructura de carpetas y módulos
Aquí se encuentran las clases, módulos y funciones claves que permiten la interacción general de todo el sistema construido.

#### 3.1.1. Agente
En este módulo se encuentran las funciones claves que permiten al LLM conocer del contexto y generar y enviar respuestas, tablas y reportes.

* `class AgentMultiTools`:
  * `__init__`:
    * **Propósito**: Inicializar la clase, configurar el modelo de lenguaje (GPT-5), establecer la conexión con MongoDB para sesiones y backups, y definir la lista de herramientas (tools) disponibles para el agente. 
    * **Comportamiento**: Instancia el cliente de OpenAI con un limitador de tasa (`InMemoryRateLimiter`), conecta a las colecciones de base de datos y prepara el `ChatPromptTemplate` con las instrucciones del sistema.

  * `ensure_session() -> dict`:
    * **Propósito**: Verificar si existe una sesión para el usuario actual y crearla si no existe.
    * **Parámetros**: 
      * `session_id`: Identificador único del chat.
      * `name`: Nombre del usuario.
    * **Comportamiento**: Consulta MongoDB; si la sesión no existe, inserta un nuevo documento con `created_at` y el nombre. Si existe, actualiza last_activity y retorna los datos de la sesión.

  * `get_session_history() -> list`:
    * **Propósito**: Recuperar el historial reciente de mensajes de una sesión específica para mantener el contexto de la conversación. 
    * **Parámetros**: 
      * `session_id`: Identificador del chat.
    * **Comportamiento**: Consulta la colección de sesiones en MongoDB, extrae los últimos 10 mensajes y los convierte en objetos HumanMessage o AIMessage de LangChain.

  * `add_message()`:
    * **Propósito**: Almacenar un nuevo mensaje en el historial de la sesión activa.
    * **Parámetros**: 
      * `session_id`: Identificador del chat.
      * `message_type ("human" o "assistant")`: Human para las consultas del usuario, assistant para las respuestas del chatbot.
      * `content`: El contenido textual, correspondiendo si es consulta del usuario o respuesta del chatbot.
    * **Comportamiento**: Realiza un update_one en MongoDB usando $push para añadir el mensaje al array last_messages, manteniendo solo los últimos 20 mensajes mediante $slice.  

  * `add_message_backup()`:
    * **Propósito**: Guardar un registro detallado y permanente de la interacción para auditoría y feedback.
    * **Parámetros**: 
      * `session_id`: Identificador del chat.
      * `question`: Consulta del usuario.
      * `full_answer`: Respuesta del sistema.
      * `verbose_log`: Logs de ejecución interna.
    * **Comportamiento**: Crea un documento con la pregunta, respuesta, timestamp, modelo utilizado y logs, y lo inserta en la colección `message_backup`. Retorna el ID del documento insertado.

  * `build_executor()`:
    * **Propósito**: Construir el ejecutor del agente de LangChain si aún no ha sido inicializado.
    * **Comportamiento**: Crea un `create_tool_calling_agent` combinando el LLM, las herramientas definidas y el prompt, y luego instancia el `AgentExecutor` con manejo de errores y verbosidad activada.

  * `answer()`:
    * **Propósito**: Procesar la consulta del usuario, ejecutar la lógica del agente y generar una respuesta final.

    * **Parámetros**: 
      * `question `: Input del usuario. 
      * `session_id`: Identificador del chat.
      * `name`: Nombre del usuario.
      * `feedback_context`: Información de retroalimentación previa.

    * **Comportamiento**: Gestiona el flujo completo: asegura la sesión, recupera historial, invoca al executor de forma asíncrona, mide tiempos de ejecución, limpia la respuesta, guarda el backup en la BD y retorna la respuesta procesada junto con el backup_id.

  * `clear_session_history()`;
    * **Propósito**: Borrar el historial de conversación de un usuario específico.
    * **Parámetros**: 
      * `session_id`: Identificador del chat.
    * **Comportamiento**: Actualiza el documento de sesión en MongoDB vaciando el array `last_messages`.


#### 3.1.2. Tools
En este módulo tenemos las herramientas que utiliza el chatbot para extraer información, construir respuestas, tablas, reportes y buscar en internet.
  
##### tools/search_information.py

* `search_information()`:
  * **Propósito**: Buscar información semántica relevante en documentos internos indexados (manuales, reglamentos, etc.).
  * **Parámetros**:
    * `query`: Consulta del usuario.
  * **Comportamiento**: Utiliza un `retriever` conectado a un `LangchainVectorStore` para encontrar documentos similares y luego procesa el contenido recuperado para devolver un resumen estructurado.

* `parse_page_content()`:
  * **Propósito**: Estructurar el texto crudo de los documentos recuperados en un formato clave-valor.
  * **Parámetros**:
    * `content`: Texto del documento.
  * **Comportamiento**: Divide el contenido por puntos y espacios, e intenta extraer pares clave-valor separados por dos puntos para retornar un diccionario de datos.

##### tools/pdf_tool.py

* `generate_financial_report_pdf() -> dict`:
  * **Propósito**: Orquestar la creación de un reporte financiero en PDF y enviarlo por Telegram.
  * **Parámetros**:
    * `data`: Datos extraídos crudos en formato Markdown.
    * `chat_id`: Identificador de la conversación, similar a `session_id`.
    * `user_request`: Consulta del usuario.
  * **Comportamiento**: Llama a `get_llm_analysis` para estructurar el contenido, luego a `generate_pdf_with_reportlab` para crear el archivo físico, y finalmente usa `send_telegram_pdf` para enviarlo al usuario.

* `ensure_utf8_string() -> str`:
  * **Propósito**: Normalizar cualquier cadena de texto para asegurar codificación UTF-8 correcta.
  * **Parámetros**:
    * `text`: Texto contenido de la data cruda.
  * **Comportamiento**: Decodifica bytes si es necesario y normaliza caracteres Unicode (NFC) para evitar errores de codificación en el reporte.
  
* `get_llm_analysis() -> tuple[str, str]`:
  * **Propósito**: Utilizar un LLM para analizar datos financieros y generar el contenido del reporte en formato Markdown.
  * **Parámetros**:
    * `data`: Data sanitizada para el análisis.
    * `user_request`: Petición del usuario.
  * **Comportamiento**: Envía un prompt especializado a GPT-5 solicitando un JSON con título y contenido Markdown, incluyendo reglas de formato y gráficas.

* `generate_pdf_with_reportlab() -> bytes`:
  * **Propósito**: Convertir el contenido Markdown y el título en un archivo PDF binario.
  * **Parámetros**:
    * `title`: Título del reporte.
    * `markdown_content`: Contenido de la respuesta del análisis formateado a markdown.
  * **Comportamiento**: Utiliza la librería `ReportLab` para maquetar el documento, procesando párrafos, listas, tablas y ejecutando código Python incrustado para generar gráficas con `matplotlib`.

##### tools/netsearch.py

* `search_web_tool()`:
  * **Propósito**: Buscar información actual o conceptos generales en internet.
  * **Parámetros**:
    * `query`: Consulta del usuario o información requerida que necesita ser buscada en internet.
  * **Comportamiento**: Utiliza `DDGS` (DuckDuckGo Search) para realizar búsquedas de texto y noticias en la región "mx-es", limpia los resultados y devuelve una lista de diccionarios con título, enlace y descripción.

##### tools/context_tool.py

* `context_tool() -> Dict[str, Any]`:
  * **Propósito**: Proveer acceso a diccionarios estáticos de contexto (fórmulas, nombres de bases de datos, etc.).
  * **Parámetros**:
    * `dict_name`: Nombre del diccionario solicitad.
  * **Comportamiento**: Verifica si el nombre solicitado existe en CONTEXT_DICTS y devuelve el diccionario correspondiente; lanza un error si no se encuentra.

##### tools/make_tables.py

* `table_tool() -> str`:
  * **Propósito**: Convertir una tabla en formato Markdown a una imagen y enviarla por Telegram.
  * **Parámetros**:
    * `markdown`: Datos formateados en markdown.
    * `chat_id`: Identificador del chat.
    * `title`: Título de la tabla.
  * **Comportamiento**: Parsea el markdown a un DataFrame, genera una imagen PNG estilizada y la envía directamente al chat mediante send_telegram_image.

* `parse_markdown_table() -> DataFrame`:
  * **Propósito**: Transformar una cadena de texto con formato de tabla Markdown en un objeto DataFrame de Pandas.
  * **Parámetros**:
    * `markdown`: Datos formateados en markdown.
  * **Comportamiento**: Divide el texto por líneas y tuberías (|), extrae encabezados y filas, y valida que la estructura sea correcta.

* `create_table_image() -> BytesIO`:
  * **Propósito**: Renderizar visualmente un DataFrame como una imagen PNG.
  * **Parámetros**:
    * `df (DataFrame)`: Datos en pandas.
    * `title`: Título de la tabla.
  * **Comportamiento**: Usa la librería `PIL` (Pillow) para dibujar celda por celda, calculando anchos dinámicos de columnas, alturas de filas y aplicando estilos de color y fuentes.

##### tools/sql_tools.py

* `sql_db_list_tables() -> List[str]`:
  * **Propósito**: Listar las tablas disponibles en la base de datos para consulta.
  * **Comportamiento**: Retorna una lista literal predefinida o cacheada de las tablas permitidas en el esquema.

* `sql_db_schema() -> Dict[str, Any]`:
  * **Propósito**: Obtener la estructura (columnas y tipos de datos) de una tabla específica.
  * **Parámetros**:
    * `table_name`: Nombre de la tabla objetivo.
  * **Comportamiento**: Ejecuta una consulta a `information_schema.columns` en PostgreSQL y devuelve un diccionario con la definición de la tabla.

* `sql_db_query_checker() -> Dict[str, Any]`:
  * **Propósito**: Validar la sintaxis de una consulta SQL antes de su ejecución real.
  * **Parámetros**:
    * `query`: SQL query a validar.
  * **Comportamiento**: Ejecuta la sentencia `EXPLAIN` en la base de datos para verificar si la query es válida sin ejecutarla, capturando posibles errores de sintaxis.

* `analyze_table() -> str`:
  * **Propósito**: Realizar un análisis profundo de datos utilizando un agente de Pandas sobre resultados SQL.
  * **Parámetros**:
    * `user_query`: Consulta o petición del usuario.
    * `sql_query`: SQL query para extraer datos de la tabla objetivo.
    * `extra_info`: Contexto adicional como formulas o nombres de productos.
  * **Comportamiento**: Ejecuta la query SQL para obtener un DataFrame, verifica su tamaño, y luego instancia un `create_pandas_dataframe_agent` para realizar cálculos estadísticos o análisis complejos solicitados por el usuario.

#### 3.1.3. API

##### API/telegram_def.py

* `send_telegram_message()`:
  * **Propósito**: Enviar mensajes de texto simples o con botones a un chat de Telegram.
  * **Parámetros**:
    * `chat_id`: Identificador del chat.
    * `message`: Mensaje para el usuario objetivo.
    * `reply_markup`: Opcional para botones o teclados interactivos in-chat.
  * **Comportamiento**: Realiza una petición POST al endpoint `sendMessage` de la API de Telegram con el payload JSON correspondiente.

* `download_file()`:
  * **Propósito**: Descargar un archivo (como audios) desde los servidores de Telegram.
  * **Parámetros**:
    * `file_path`: Ubicación del archivo objetivo.
  * **Comportamiento**: Construye la URL de descarga con el token del bot y realiza un GET para obtener el contenido binario del archivo.

* `send_telegram_pdf()`:
  * **Propósito**: Enviar un documento PDF generado al usuario.
  * **Parámetros**:
    * `chat_id`: Identificador del chat.
    * `pdf_bytes`: PDF en bytes.
    * `filename`: Nombre del archivo PDF.
    * `caption`: Descripción extra del archivo a enviar.
  * **Comportamiento**: Envía una petición `multipart/form-data` al endpoint `sendDocument` de Telegram adjuntando los bytes del PDF.

* `send_telegram_image()`:
  * **Propósito**: Enviar una imagen (como las tablas generadas) al usuario.
  * **Parámetros**:
    * `chat_id`: Identificador del chat.
    * `image_bytes`: Imagen en bytes.
    * `caption`: Descripción extra del archivo a enviar.
  * **Comportamiento**: Envía una petición al endpoint sendPhoto adjuntando la imagen en memoria.
 
##### API/telegram_chat.py

* `delete_chat_history_endpoint()`:
  * **Propósito**: Endpoint lógico para limpiar el historial de un usuario.
  * **Parámetros**:
    * `user_id`: Identificador del chat.
  * **Comportamiento**: Llama al método `clear_session_history` del agente y maneja excepciones HTTP.

* `load_whitelist()`:
  * **Propósito**: Cargar la lista de usuarios autorizados desde un archivo.
  * **Parámetros**:
    * `filepath`: Ubicación del archivo.
  * **Comportamiento**: Lee un archivo de texto línea por línea y retorna un conjunto de IDs de Telegram permitidos.

* `get_file_path()`:
  * **Propósito**: Obtener la ruta de descarga de un archivo dado su ID de Telegram.
  * **Parámetros**:
    * `file_id`: Identificador del audio.
  * **Comportamiento**: Consulta el método `getFile` de la API de Telegram para resolver la ruta del archivo en el servidor.
  
* `transcribe_audio()`:
  * **Propósito**: Convertir notas de voz en texto utilizando IA.
  * **Parámetros**:
    * `audio_bytes`: Audio en bytes.
    * `filename`: Nombre del audio.
  * **Comportamiento**: Envía el archivo de audio a la API de OpenAI (Whisper) y retorna el texto transcrito.

* `add_feedback()`:
  * **Propósito**: Almacenar feedback cualitativo en la base de conocimientos vectorial.
  * **Parámetros**:
    * `comment`: Comentario del usuario.
    * `metadata`: Incluye el identificador del mensaje en `message_backup_collection`, la pregunta, la respuesta, y si fue o no útil.
  * **Comportamiento**: Añade el comentario y sus metadatos al `feedback_vectorstore` y guarda el índice.

* `retrieve_feedback()`:
  * **Propósito**: Buscar retroalimentación previa relevante para la consulta actual.
  * **Parámetros**:
    * `user_question`: Consulta del usuario.
    * `k`: Número de resultados.
  * **Comportamiento**: Realiza una búsqueda de similitud en el vectorstore y formatea los resultados como una cadena de texto.

* `update_feedback()`:
  * **Propósito**: Actualizar el registro de una interacción con la evaluación del usuario.
  * **Parámetros**:
    * `backup_id`: Identificador del mensaje completo en el `message_backup_collection`.
    * `helpful`: Booleano, true si fue útil, false si no.
    * `reason`: Comentario extra de porqué sí o porqué no.
  * **Comportamiento**: Actualiza el documento en MongoDB marcando si fue útil y, si existe una razón, la indexa en el vectorstore para futuro aprendizaje.

* `handle_message()`:
  * **Propósito**: Coordinar la respuesta a un mensaje del usuario.
  * **Parámetros**:
    * `chat_id`: Identificador del chat.
    * `text`: Consulta del usuario.
    * `name`: Nombre del usuario.
  * **Comportamiento**: Recupera contexto de feedback, llama al agente para obtener respuesta, calcula tiempos, guarda el estado temporal y envía la respuesta final a Telegram con botones de feedback.

* `telegram_webhook()`:
  * **Propósito**: Punto de entrada principal para recibir actualizaciones de Telegram (Webhook).
  * **Parámetros**:
    * `request`: Petición del usuario.
    * `background_tasks`: Tareas que se deben ejecutar en segundo plano.
  * **Comportamiento**: Procesa el payload JSON, maneja callbacks de botones (feedback sí/no), verifica autorización (whitelist), gestiona mensajes de texto y voz, y delega el procesamiento pesado a tareas en segundo plano (handle_message).

##### API/telegram_main.py

* `telegram_webhook_handler()`:
  * **Propósito**: Ruta de FastAPI expuesta para recibir el webhook.
  * **Parámetros**:
    * `request`: Petición del usuario.
    * `background_tasks`: Tareas que se deben ejecutar en segundo plano.
  * **Comportamiento**: Envuelve la llamada a `telegram_webhook` en un bloque try-except para manejo de errores HTTP y registro de logs.

* `handle_delete_history()`:
  * **Propósito**: Ruta API DELETE para borrar historial.
  * **Parámetros**:
    * `user_id`: Identificador del chat.
  * **Comportamiento**: Invoca `delete_chat_history_endpoint` pasando el ID del usuario proporcionado en la URL.

### 3.2. Modelos LLM utilizados

El sistema de Salsas Castillo utiliza una combinación de modelos de lenguaje para diferentes propósitos:

* **Generación de respuestas y razonamiento (OpenAI - `gpt-5`)**:

    * **Función**: Es el LLM principal utilizado por AgentMultiTools para interpretar las consultas del usuario, decidir qué herramientas invocar (SQL, búsqueda de información, PDF) y generar las respuestas detalladas.

    * **Ventaja**: Ofrece alta capacidad de razonamiento y comprensión contextual para manejar consultas complejas sobre datos financieros y de ventas.

* **Transcripción de audio (OpenAI Whisper - `whisper-1`)**:

    * **Función**: Utilizado en telegram_chat.py para transcribir mensajes de voz de los usuarios de Telegram a texto, permitiendo que el chatbot procese entradas de audio.

    * **Ventaja**: Alta precisión en la transcripción de voz a texto.

* **Generación de análisis para PDF (OpenAI - `gpt-5`)**: 

    * **Función**: En pdf_tool.py, este modelo se utiliza para generar un párrafo de análisis conciso a partir de los datos tabulares que se incluirán en el reporte PDF.

    * **Ventaja**: Proporciona resúmenes inteligentes y profesionales de los datos.

:::

::: {style="text-align: justify"}
## 4. Guía de entrenamiento y mejora
Esta sección aborda cómo se mantiene y mejora la base de conocimientos del chatbot, así como recomendaciones para futuras optimizaciones.

### 4.1. Generación y actualización de la base de datos vectorial
La herramienta search_information se basa en un vector store FAISS. Este vector store almacena representaciones vectoriales de documentos internos (manuales, reglamentos, etc.) para permitir búsquedas semánticas.

Proceso de Creación: Los documentos internos se convierten en objetos langchain.schema.Document, se generan embeddings utilizando OpenAIEmbeddings, y luego se construye un índice FAISS que se guarda localmente.

Actualización: Para mantener la información actualizada, se debe ejecutar periódicamente el script que reconstruye o actualiza este vector store con cualquier nuevo documento o modificación.

### 4.2. Recomendaciones para mejora futura

1. **Monitoreo avanzado**: Implementar un monitoreo más detallado de las interacciones del chatbot, incluyendo el rendimiento de las consultas SQL, el tiempo de respuesta de las herramientas y la calidad de las respuestas generadas por el LLM. Esto puede hacerse analizando los datos en la colección `message_backup` de MongoDB.

2. **Optimización de prompts**: Continuar iterando y refinando los *prompts* (`prompts.py`) para mejorar la precisión y coherencia de las respuestas, especialmente en casos complejos o ambiguos.

3. **Manejo de errores robustos**: Mejorar el manejo de errores en las llamadas a APIs externas (OpenAI, Telegram) y a las bases de datos (PostgreSQL, MongoDB) para proporcionar mensajes más informativos al usuario y facilitar la depuración.

4. **Expansión de herramientas**: Considerar la adición de nuevas herramientas para el agente, como la capacidad de crear gráficos a partir de datos financieros, o interactuar con otros sistemas internos de Salsas Castillo.

5. **Evaluación cuantitativa**: Si es posible, definir métricas cuantitativas para evaluar la calidad de las respuestas del chatbot (ej., ROUGE, BLEU, o métricas basadas en la satisfacción del usuario) para complementar la evaluación cualitativa.

6. **Embeddings locales (Opcional)**: Investigar el uso de modelos de embeddings open-source (ej., a través de Ollama) para reducir la dependencia de OpenAI y potencialmente los costos, si la precisión es aceptable para los casos de uso de Salsas Castillo.

:::

::: {style="text-align: justify"}
## 5. Arquitectura

### 5.1. Componentes clave:

* **Usuario de Telegram**: El usuario final que interactúa con el chatbot a través de la aplicación de mensajería.
* **Backend del Chatbot (FastAPI)**: El servicio principal que procesa las consultas de los usuarios.
    * `telegram_main.py`: Punto de entrada de los webhooks de Telegram.
    * `telegram_chat.py`: Maneja la lógica de Telegram (transcripción de voz, envío de mensajes) y coordina preguntas y respuestas con el agente.
    * `agent_multitool.py`: Contiene el `AgentMultiTools` que orquesta el LLM y las herramientas.

* **Modelo agéntico**: El cerebro principal que utiliza un LLM para generar respuestas, razonar y decidir el uso de herramientas.
* **Base de Datos NoSQL (MongoDB)**: Almacena el historial de sesiones (`sessions`) y un respaldo completo de mensajes (`message_backup`) para análisis.
* **Base de Datos Relacional (PostgreSQL)**: Contiene los datos transaccionales de ventas (`historial_facturas`) y datos financieros consolidados (`financieroii`).
* **Base de Datos Vectorial (FAISS)**: Almacena los embeddings de documentos internos para búsquedas semánticas (utilizado por search_information).
* **Herramientas**: Funciones específicas que el LLM puede invocar:
    * `sql_db_query`, `sql_db_schema`, etc. (de `SQLDatabaseToolkit`): Para interactuar con PostgreSQL.
    * `search_information`: Para buscar en el vector store de documentos internos.
    * `pdf_report_tool`: Para generar y enviar reportes PDF.

### 5.2. Flujo de Interacción Principal:

1. El **Usuario de Telegram** envía un mensaje (texto o voz) al chatbot.
2. El mensaje es recibido por la **API** y enviado al *endpoint* /webhook del **Backend del Chatbot**.
3. `telegram_chat.py` procesa el mensaje. Si es voz, lo envía a **OpenAI Whisper API** para transcripción.
4. El texto del mensaje se pasa a `AgentMultiTools` (`agent_multitool.py`).
5. `AgentMultiTools` gestiona la **sesión en MongoDB** y consulta el historial.
6. El **LLM**, guiado por los *prompts* (`prompts.py`), analiza la consulta y decide qué **Herramientas** utilizar:
    
    * Si necesita datos de ventas, finanzas, facturas, u otras tablas, invoca herramientas SQL para consultar la base de datos de PostgreSQL.
    * Si necesita información de documentos internos, invoca search_information para buscar en la Base de Datos Vectorial (FAISS).
    * Si se solicita un reporte, invoca pdf_report_tool, que a su vez puede usar el LLM para análisis y luego envía el PDF a Telegram.
    * Si la consulta se trata sobre una visualización de datos, se invoca table_tool, toma los datos devueltos por la consulta SQL, los convierte a tabla, lo guarda temporalmente como imagen y lo envía al usuario.

7. La información recuperada por las herramientas se contextualiza y se envía de nuevo al **LLM** para generar la **respuesta final al usuario**.
8. La respuesta es enviada de vuelta al **Usuario de Telegram** a través de la **API**.
9. Todas las interacciones (consultas y respuestas) se registran en las colecciones `sessions` y `message_backup` en **MongoDB** para análisis y auditoría.

### 5.3. Diagrama de la Arquitectura

El siguiente diagrama ilustra la arquitectura general del sistema del chatbot para Salsas Castillo, mostrando los componentes principales y el flujo de datos.

![Arquitectura del sistema](./images/arquitectura.jpg){width=120%}
:::